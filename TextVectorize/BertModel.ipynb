{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jim/anaconda3/envs/forPttCrawler/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jieba\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import re\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "# set device to gpu\n",
    "device = (\n",
    "\"cuda\"\n",
    "if torch.cuda.is_available()\n",
    "else \"mps\"\n",
    "if torch.backends.mps.is_available()\n",
    "else \"cpu\"\n",
    ")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_to_half(s):\n",
    "    # 將字符串 s 中的全形字符和標點符號轉換為半形。\n",
    "    n = []\n",
    "    for char in s:\n",
    "        code = ord(char)\n",
    "        if code == 0x3000:  # 全形空格直接轉換\n",
    "            code = 32\n",
    "        elif 0xFF01 <= code <= 0xFF5E:  # 全形字符（除空格）轉換成半形\n",
    "            code -= 0xFEE0\n",
    "        n.append(chr(code))\n",
    "    return ''.join(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/stopwords_tc.txt', encoding='utf-8', mode='r') as f:\n",
    "    stop_words = []\n",
    "    for l in f:\n",
    "        stop_words.append(l.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptt_food_post_df = pd.read_csv('../Data/Ptt/ptt_food_post_list.csv', index_col='Pid')\n",
    "gpt_food_post_df = pd.read_csv('../Data/ChatGPT/chatgpt_generated_articles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls_and_phones(text):\n",
    "    \"\"\"\n",
    "    移除文字中的網址和電話號碼。\n",
    "    \"\"\"\n",
    "    # 正則表達式匹配網址\n",
    "    url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    text = re.sub(url_pattern, '', text)\n",
    "\n",
    "    # 正則表達式匹配電話號碼（適用於多種常見格式）\n",
    "    phone_pattern = r'(\\d{2,4}[-.\\s]??\\d{3,4}[-.\\s]??\\d{3,4}|\\(\\d{2,4}\\)\\s*\\d{3,4}[-.\\s]??\\d{3,4}|\\d{10,11})'\n",
    "    text = re.sub(phone_pattern, '', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_english(text):\n",
    "    \"\"\"\n",
    "    移除文字中的所有英文字符。\n",
    "    \"\"\"\n",
    "    # 正則表達式匹配所有英文字母和英文單詞\n",
    "    pattern = r'[A-Za-z]+'\n",
    "    cleaned_text = re.sub(pattern, '', text)\n",
    "\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emojis(text):\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\" \n",
    "        \"\\U0001F600-\\U0001F64F\"  # 表情符號\n",
    "        \"\\U0001F300-\\U0001F5FF\"  # 符號和圖案\n",
    "        \"\\U0001F680-\\U0001F6FF\"  # 交通和符號\n",
    "        \"\\U0001F700-\\U0001F77F\"  # 藝術符號\n",
    "        \"]+\",\n",
    "        flags=re.UNICODE,\n",
    "    )\n",
    "    return emoji_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dictionary(file_path):\n",
    "    with open(file_path, encoding='utf-8', mode='r') as f:\n",
    "        dictionary = [l.strip() for l in f]\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text, stopwords):\n",
    "    # 使用列表推導式過濾掉停用詞\n",
    "    filtered_words = remove_urls_and_phones(text)\n",
    "    filtered_words = remove_english(filtered_words)\n",
    "    filtered_words = remove_emojis(filtered_words)\n",
    "    filtered_words = \"\".join(c for c in filtered_words if c not in ('；','，','。','！','：','「','」','…','、','？','【','】','.',':','?',';','!','~','`','+','-','<','>','/','[',']','{','}',\"'\",'\"','\\\\', ' ', '‧','・','◢','◤','\\n','★','☆','◆','◇','◎','○','●','◐','◑','▲','▼','△','▽','◢','◣','◥','◤','▷','◁','▶','◀','♠','♣','♥','♦','♨','⊙','⊕','▨','▧','▦','▥','▤','▣','▢','□','■'))\n",
    "    filtered_words = \"\".join(word for word in filtered_words if word not in stopwords)\n",
    "    filtered_words = filtered_words.replace(u'\\u3000', u' ')\n",
    "    # 將過濾後的單詞列表重新組合成字符串\n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>remove_stopword_content</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>餐廳名稱片消費時間年月電話址台南市仁德區空路號營業時間日圖文版片位台南空眷村家低調披蕯店原平...</td>\n",
       "      <td>ptt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>餐廳名稱辰壽司割烹消費時間年月址台北市松山區敦化北路號營業時間平價位圖文月底結束前朋友揪局覺...</td>\n",
       "      <td>ptt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>鍋物前線金鋤壽喜燒烤鍋物新莊店午茶消費日期年月圖真相圖文茂版點新北市新莊區幸福路號電話價位動...</td>\n",
       "      <td>ptt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>餐廳名稱林口井放鬆心情吃港式點點心消費時間址新北市林口區文化路段號樓電話營業時間週週週週週日...</td>\n",
       "      <td>ptt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>餐廳名稱夯魯肉飯消費時間年月台北市信義區松山路號圖文網誌分數低評破位數裝潢實文青說真點詹記感...</td>\n",
       "      <td>ptt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>食記屏東潮州牛福屏東牛肉料理家次家分享屏東潮州區家美味牛肉料理餐廳牛福裡品嚐道美味牛肉料理回...</td>\n",
       "      <td>gpt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>食記評肉次夯餐廳名稱肉次消費時間址台北市安區復興南路段號電話營業時間週週日進入肉次空間刻溫暖...</td>\n",
       "      <td>gpt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>食記桃園龍潭糧園茶藝客家館餐廳名稱糧園茶藝客家館消費時間址桃園市龍潭區路號電話營業時間週週日...</td>\n",
       "      <td>gpt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>食記台北信義安吉頌丹麥專賣店消費時間年月址台北市信義區松仁路號電話營業時間週週日天台北信義區...</td>\n",
       "      <td>gpt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>食記高雄民早午餐墨漢堡建工店餐廳名稱墨漢堡建工店消費時間年月日址高雄市民區建工路號電話營業時...</td>\n",
       "      <td>gpt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2013 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                remove_stopword_content source\n",
       "0     餐廳名稱片消費時間年月電話址台南市仁德區空路號營業時間日圖文版片位台南空眷村家低調披蕯店原平...    ptt\n",
       "1     餐廳名稱辰壽司割烹消費時間年月址台北市松山區敦化北路號營業時間平價位圖文月底結束前朋友揪局覺...    ptt\n",
       "2     鍋物前線金鋤壽喜燒烤鍋物新莊店午茶消費日期年月圖真相圖文茂版點新北市新莊區幸福路號電話價位動...    ptt\n",
       "3     餐廳名稱林口井放鬆心情吃港式點點心消費時間址新北市林口區文化路段號樓電話營業時間週週週週週日...    ptt\n",
       "4     餐廳名稱夯魯肉飯消費時間年月台北市信義區松山路號圖文網誌分數低評破位數裝潢實文青說真點詹記感...    ptt\n",
       "...                                                 ...    ...\n",
       "2008  食記屏東潮州牛福屏東牛肉料理家次家分享屏東潮州區家美味牛肉料理餐廳牛福裡品嚐道美味牛肉料理回...    gpt\n",
       "2009  食記評肉次夯餐廳名稱肉次消費時間址台北市安區復興南路段號電話營業時間週週日進入肉次空間刻溫暖...    gpt\n",
       "2010  食記桃園龍潭糧園茶藝客家館餐廳名稱糧園茶藝客家館消費時間址桃園市龍潭區路號電話營業時間週週日...    gpt\n",
       "2011  食記台北信義安吉頌丹麥專賣店消費時間年月址台北市信義區松仁路號電話營業時間週週日天台北信義區...    gpt\n",
       "2012  食記高雄民早午餐墨漢堡建工店餐廳名稱墨漢堡建工店消費時間年月日址高雄市民區建工路號電話營業時...    gpt\n",
       "\n",
       "[2013 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptt_contents = ptt_food_post_df.loc[:, 'content']\n",
    "gpt_contents = gpt_food_post_df.loc[:, 'content']\n",
    "stop_words = load_dictionary('../Data/stopwords_tc.txt')\n",
    "ptt_remove_stopword_contents = []\n",
    "gpt_remove_stopword_contents = []\n",
    "for c in ptt_contents:\n",
    "    ptt_remove_stopword_contents.append(remove_stopwords(c, stop_words))\n",
    "\n",
    "for c in gpt_contents:\n",
    "    gpt_remove_stopword_contents.append(remove_stopwords(c, stop_words))\n",
    "\n",
    "# 添加標記並合併 DataFrame\n",
    "ptt_contents_df = pd.DataFrame(ptt_remove_stopword_contents, columns=['remove_stopword_content'])\n",
    "ptt_contents_df['source'] = 'ptt'\n",
    "\n",
    "gpt_contents_df = pd.DataFrame(gpt_remove_stopword_contents, columns=['remove_stopword_content'])\n",
    "gpt_contents_df['source'] = 'gpt'\n",
    "\n",
    "combined_df = pd.concat([ptt_contents_df, gpt_contents_df], ignore_index=True)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 Jieba 進行切詞\n",
    "def jieba_cut(text):\n",
    "    stop_words = {'食記', '網誌'}\n",
    "    words = jieba.lcut(text)\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/rh/7g0n3djn3wj8dlnjv7plmzcr0000gn/T/jieba.cache\n",
      "Loading model cost 0.144 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "combined_df['tokenized_text'] = combined_df['remove_stopword_content'].apply(jieba_cut)\n",
    "tokens = combined_df['tokenized_text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jim/anaconda3/envs/forPttCrawler/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/Users/jim/anaconda3/envs/forPttCrawler/lib/python3.10/site-packages/torch/amp/grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/Users/jim/anaconda3/envs/forPttCrawler/lib/python3.10/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Step: 0, Loss: 9.936542510986328\n",
      "Epoch: 0, Step: 1, Loss: 10.012861251831055\n",
      "Epoch: 0, Step: 2, Loss: 9.924552917480469\n",
      "Epoch: 0, Step: 3, Loss: 9.912943840026855\n",
      "Epoch: 0, Step: 4, Loss: 9.398380279541016\n",
      "Epoch: 0, Step: 5, Loss: 8.884424209594727\n",
      "Epoch: 0, Step: 6, Loss: 9.082435607910156\n",
      "Epoch: 0, Step: 7, Loss: 8.94564437866211\n",
      "Epoch: 0, Step: 8, Loss: 7.557916641235352\n",
      "Epoch: 0, Step: 9, Loss: 8.460612297058105\n",
      "Epoch: 0, Step: 10, Loss: 7.973822593688965\n",
      "Epoch: 0, Step: 11, Loss: 8.108795166015625\n",
      "Epoch: 0, Step: 12, Loss: 8.114551544189453\n",
      "Epoch: 0, Step: 13, Loss: 6.870382785797119\n",
      "Epoch: 0, Step: 14, Loss: 9.815645217895508\n",
      "Epoch: 0, Step: 15, Loss: 7.4393439292907715\n",
      "Epoch: 0, Step: 16, Loss: 7.413608551025391\n",
      "Epoch: 0, Step: 17, Loss: 8.73604965209961\n",
      "Epoch: 0, Step: 18, Loss: 5.902551651000977\n",
      "Epoch: 0, Step: 19, Loss: 5.912508964538574\n",
      "Epoch: 0, Step: 20, Loss: 7.631427764892578\n",
      "Epoch: 0, Step: 21, Loss: 4.874484062194824\n",
      "Epoch: 0, Step: 22, Loss: 6.0113043785095215\n",
      "Epoch: 0, Step: 23, Loss: 4.922175407409668\n",
      "Epoch: 0, Step: 24, Loss: 6.507826805114746\n",
      "Epoch: 0, Step: 25, Loss: 6.8173675537109375\n",
      "Epoch: 0, Step: 26, Loss: 5.3365583419799805\n",
      "Epoch: 0, Step: 27, Loss: 6.125300884246826\n",
      "Epoch: 0, Step: 28, Loss: 6.533148765563965\n",
      "Epoch: 0, Step: 29, Loss: 5.477152347564697\n",
      "Epoch: 0, Step: 30, Loss: 6.257389068603516\n",
      "Epoch: 0, Step: 31, Loss: 8.582874298095703\n",
      "Epoch: 0, Step: 32, Loss: 6.664695739746094\n",
      "Epoch: 0, Step: 33, Loss: 6.780338764190674\n",
      "Epoch: 0, Step: 34, Loss: 5.212418556213379\n",
      "Epoch: 0, Step: 35, Loss: 7.06863260269165\n",
      "Epoch: 0, Step: 36, Loss: 7.089463710784912\n",
      "Epoch: 0, Step: 37, Loss: 4.6664018630981445\n",
      "Epoch: 0, Step: 38, Loss: 5.589053153991699\n",
      "Epoch: 0, Step: 39, Loss: 6.174643039703369\n",
      "Epoch: 0, Step: 40, Loss: 6.105190277099609\n",
      "Epoch: 0, Step: 41, Loss: 6.590138912200928\n",
      "Epoch: 0, Step: 42, Loss: 5.415886878967285\n",
      "Epoch: 0, Step: 43, Loss: 5.035676956176758\n",
      "Epoch: 0, Step: 44, Loss: 5.771740913391113\n",
      "Epoch: 0, Step: 45, Loss: 6.976875305175781\n",
      "Epoch: 0, Step: 46, Loss: 6.819609642028809\n",
      "Epoch: 0, Step: 47, Loss: 6.0298542976379395\n",
      "Epoch: 0, Step: 48, Loss: 6.503542900085449\n",
      "Epoch: 0, Step: 49, Loss: 5.641419887542725\n",
      "Epoch: 0, Step: 50, Loss: 6.512519836425781\n",
      "Epoch: 0, Step: 51, Loss: 4.586523056030273\n",
      "Epoch: 0, Step: 52, Loss: 7.097877502441406\n",
      "Epoch: 0, Step: 53, Loss: 3.737527370452881\n",
      "Epoch: 0, Step: 54, Loss: 5.916436672210693\n",
      "Epoch: 0, Step: 55, Loss: 7.055599212646484\n",
      "Epoch: 0, Step: 56, Loss: 8.365260124206543\n",
      "Epoch: 0, Step: 57, Loss: 5.841464042663574\n",
      "Epoch: 0, Step: 58, Loss: 7.237110614776611\n",
      "Epoch: 0, Step: 59, Loss: 7.995438575744629\n",
      "Epoch: 0, Step: 60, Loss: 5.779346466064453\n",
      "Epoch: 0, Step: 61, Loss: 6.490955829620361\n",
      "Epoch: 0, Step: 62, Loss: 7.4098286628723145\n",
      "Epoch: 0, Step: 63, Loss: 5.24423885345459\n",
      "Epoch: 0, Step: 64, Loss: 6.588151454925537\n",
      "Epoch: 0, Step: 65, Loss: 4.6450066566467285\n",
      "Epoch: 0, Step: 66, Loss: 6.848276138305664\n",
      "Epoch: 0, Step: 67, Loss: 7.038339138031006\n",
      "Epoch: 0, Step: 68, Loss: 6.9085869789123535\n",
      "Epoch: 0, Step: 69, Loss: 7.4031291007995605\n",
      "Epoch: 0, Step: 70, Loss: 5.732944488525391\n",
      "Epoch: 0, Step: 71, Loss: 5.501338958740234\n",
      "Epoch: 0, Step: 72, Loss: 4.6099934577941895\n",
      "Epoch: 0, Step: 73, Loss: 4.410216331481934\n",
      "Epoch: 0, Step: 74, Loss: 5.837594509124756\n",
      "Epoch: 0, Step: 75, Loss: 5.917901515960693\n",
      "Epoch: 0, Step: 76, Loss: 4.407236099243164\n",
      "Epoch: 0, Step: 77, Loss: 4.931149482727051\n",
      "Epoch: 0, Step: 78, Loss: 7.392340660095215\n",
      "Epoch: 0, Step: 79, Loss: 4.832094192504883\n",
      "Epoch: 0, Step: 80, Loss: 5.37571382522583\n",
      "Epoch: 0, Step: 81, Loss: 5.072943210601807\n",
      "Epoch: 0, Step: 82, Loss: 4.642159461975098\n",
      "Epoch: 0, Step: 83, Loss: 5.6170735359191895\n",
      "Epoch: 0, Step: 84, Loss: 5.446681022644043\n",
      "Epoch: 0, Step: 85, Loss: 5.966366767883301\n",
      "Epoch: 0, Step: 86, Loss: 3.847881555557251\n",
      "Epoch: 0, Step: 87, Loss: 5.467185020446777\n",
      "Epoch: 0, Step: 88, Loss: 6.249492645263672\n",
      "Epoch: 0, Step: 89, Loss: 3.929332733154297\n",
      "Epoch: 0, Step: 90, Loss: 4.709005355834961\n",
      "Epoch: 0, Step: 91, Loss: 4.52516508102417\n",
      "Epoch: 0, Step: 92, Loss: 7.109994888305664\n",
      "Epoch: 0, Step: 93, Loss: 5.692333698272705\n",
      "Epoch: 0, Step: 94, Loss: 4.310238838195801\n",
      "Epoch: 0, Step: 95, Loss: 4.40354061126709\n",
      "Epoch: 0, Step: 96, Loss: 5.043057441711426\n",
      "Epoch: 0, Step: 97, Loss: 5.858799457550049\n",
      "Epoch: 0, Step: 98, Loss: 5.914149761199951\n",
      "Epoch: 0, Step: 99, Loss: 4.700631618499756\n",
      "Epoch: 0, Step: 100, Loss: 5.749904632568359\n",
      "Epoch: 0, Step: 101, Loss: 6.312509536743164\n",
      "Epoch: 0, Step: 102, Loss: 7.7831549644470215\n",
      "Epoch: 0, Step: 103, Loss: 6.046781539916992\n",
      "Epoch: 0, Step: 104, Loss: 4.132036209106445\n",
      "Epoch: 0, Step: 105, Loss: 6.445023536682129\n",
      "Epoch: 0, Step: 106, Loss: 3.6360397338867188\n",
      "Epoch: 0, Step: 107, Loss: 4.167893886566162\n",
      "Epoch: 0, Step: 108, Loss: 4.728943347930908\n",
      "Epoch: 0, Step: 109, Loss: 5.415939807891846\n",
      "Epoch: 0, Step: 110, Loss: 8.7213134765625\n",
      "Epoch: 0, Step: 111, Loss: 3.3578832149505615\n",
      "Epoch: 0, Step: 112, Loss: 5.690720081329346\n",
      "Epoch: 0, Step: 113, Loss: 4.801393032073975\n",
      "Epoch: 0, Step: 114, Loss: 6.3599419593811035\n",
      "Epoch: 0, Step: 115, Loss: 6.843870162963867\n",
      "Epoch: 0, Step: 116, Loss: 3.287989854812622\n",
      "Epoch: 0, Step: 117, Loss: 5.582880020141602\n",
      "Epoch: 0, Step: 118, Loss: 4.302727699279785\n",
      "Epoch: 0, Step: 119, Loss: 4.879701614379883\n",
      "Epoch: 0, Step: 120, Loss: 5.616909980773926\n",
      "Epoch: 0, Step: 121, Loss: 5.830697059631348\n",
      "Epoch: 0, Step: 122, Loss: 5.367926597595215\n",
      "Epoch: 0, Step: 123, Loss: 5.523662567138672\n",
      "Epoch: 0, Step: 124, Loss: 5.711178779602051\n",
      "Epoch: 0, Step: 125, Loss: 5.376817226409912\n",
      "Epoch: 0, Step: 126, Loss: 4.770598411560059\n",
      "Epoch: 0, Step: 127, Loss: 6.92719030380249\n",
      "Epoch: 0, Step: 128, Loss: 3.2690584659576416\n",
      "Epoch: 0, Step: 129, Loss: 5.184352874755859\n",
      "Epoch: 0, Step: 130, Loss: 5.3994245529174805\n",
      "Epoch: 0, Step: 131, Loss: 5.642014026641846\n",
      "Epoch: 0, Step: 132, Loss: 5.773065567016602\n",
      "Epoch: 0, Step: 133, Loss: 6.052756309509277\n",
      "Epoch: 0, Step: 134, Loss: 4.39530086517334\n",
      "Epoch: 0, Step: 135, Loss: 5.078601837158203\n",
      "Epoch: 0, Step: 136, Loss: 6.221287727355957\n",
      "Epoch: 0, Step: 137, Loss: 4.722301959991455\n",
      "Epoch: 0, Step: 138, Loss: 6.919759750366211\n",
      "Epoch: 0, Step: 139, Loss: 4.279857635498047\n",
      "Epoch: 0, Step: 140, Loss: 4.245754718780518\n",
      "Epoch: 0, Step: 141, Loss: 4.0547285079956055\n",
      "Epoch: 0, Step: 142, Loss: 4.642420768737793\n",
      "Epoch: 0, Step: 143, Loss: 5.94437313079834\n",
      "Epoch: 0, Step: 144, Loss: 4.688543319702148\n",
      "Epoch: 0, Step: 145, Loss: 5.267873764038086\n",
      "Epoch: 0, Step: 146, Loss: 5.350874900817871\n",
      "Epoch: 0, Step: 147, Loss: 5.90926456451416\n",
      "Epoch: 0, Step: 148, Loss: 4.861675262451172\n",
      "Epoch: 0, Step: 149, Loss: 4.401813507080078\n",
      "Epoch: 0, Step: 150, Loss: 4.054384708404541\n",
      "Epoch: 0, Step: 151, Loss: 3.3285017013549805\n",
      "Epoch: 0, Step: 152, Loss: 5.262034893035889\n",
      "Epoch: 0, Step: 153, Loss: 4.608668804168701\n",
      "Epoch: 0, Step: 154, Loss: 4.575192451477051\n",
      "Epoch: 0, Step: 155, Loss: 4.075458526611328\n",
      "Epoch: 0, Step: 156, Loss: 4.453728199005127\n",
      "Epoch: 0, Step: 157, Loss: 4.93372917175293\n",
      "Epoch: 0, Step: 158, Loss: 4.089460372924805\n",
      "Epoch: 0, Step: 159, Loss: 4.674015045166016\n",
      "Epoch: 0, Step: 160, Loss: 4.051570892333984\n",
      "Epoch: 0, Step: 161, Loss: 5.776292324066162\n",
      "Epoch: 0, Step: 162, Loss: 3.7607414722442627\n",
      "Epoch: 0, Step: 163, Loss: 4.851975917816162\n",
      "Epoch: 0, Step: 164, Loss: 4.738821029663086\n",
      "Epoch: 0, Step: 165, Loss: 4.1111345291137695\n",
      "Epoch: 0, Step: 166, Loss: 4.588268280029297\n",
      "Epoch: 0, Step: 167, Loss: 4.306722640991211\n",
      "Epoch: 0, Step: 168, Loss: 4.63826847076416\n",
      "Epoch: 0, Step: 169, Loss: 5.615358352661133\n",
      "Epoch: 0, Step: 170, Loss: 4.742230415344238\n",
      "Epoch: 0, Step: 171, Loss: 3.4472529888153076\n",
      "Epoch: 0, Step: 172, Loss: 4.462347984313965\n",
      "Epoch: 0, Step: 173, Loss: 5.414602756500244\n",
      "Epoch: 0, Step: 174, Loss: 3.5754036903381348\n",
      "Epoch: 0, Step: 175, Loss: 2.94522762298584\n",
      "Epoch: 0, Step: 176, Loss: 5.9280900955200195\n",
      "Epoch: 0, Step: 177, Loss: 3.4228291511535645\n",
      "Epoch: 0, Step: 178, Loss: 5.024391174316406\n",
      "Epoch: 0, Step: 179, Loss: 5.0616350173950195\n",
      "Epoch: 0, Step: 180, Loss: 4.980681419372559\n",
      "Epoch: 0, Step: 181, Loss: 3.9690868854522705\n",
      "Epoch: 0, Step: 182, Loss: 4.816433429718018\n",
      "Epoch: 0, Step: 183, Loss: 3.769804000854492\n",
      "Epoch: 0, Step: 184, Loss: 4.09058141708374\n",
      "Epoch: 0, Step: 185, Loss: 6.049307346343994\n",
      "Epoch: 0, Step: 186, Loss: 3.3661813735961914\n",
      "Epoch: 0, Step: 187, Loss: 3.4449877738952637\n",
      "Epoch: 0, Step: 188, Loss: 3.778657913208008\n",
      "Epoch: 0, Step: 189, Loss: 3.448275089263916\n",
      "Epoch: 0, Step: 190, Loss: 3.9314093589782715\n",
      "Epoch: 0, Step: 191, Loss: 4.116785049438477\n",
      "Epoch: 0, Step: 192, Loss: 5.344583988189697\n",
      "Epoch: 0, Step: 193, Loss: 4.834219932556152\n",
      "Epoch: 0, Step: 194, Loss: 5.442479133605957\n",
      "Epoch: 0, Step: 195, Loss: 3.8014097213745117\n",
      "Epoch: 0, Step: 196, Loss: 3.4343128204345703\n",
      "Epoch: 0, Step: 197, Loss: 3.559720039367676\n",
      "Epoch: 0, Step: 198, Loss: 2.9841887950897217\n",
      "Epoch: 0, Step: 199, Loss: 3.6116867065429688\n",
      "Epoch: 0, Step: 200, Loss: 3.6645631790161133\n",
      "Epoch: 0, Step: 201, Loss: 5.71675443649292\n",
      "Epoch: 0, Step: 202, Loss: 6.13944149017334\n",
      "Epoch: 0, Step: 203, Loss: 4.134265899658203\n",
      "Epoch: 0, Step: 204, Loss: 2.741053581237793\n",
      "Epoch: 0, Step: 205, Loss: 3.9126501083374023\n",
      "Epoch: 0, Step: 206, Loss: 3.0428333282470703\n",
      "Epoch: 0, Step: 207, Loss: 3.9433434009552\n",
      "Epoch: 0, Step: 208, Loss: 3.8136446475982666\n",
      "Epoch: 0, Step: 209, Loss: 3.0596680641174316\n",
      "Epoch: 0, Step: 210, Loss: 4.934503555297852\n",
      "Epoch: 0, Step: 211, Loss: 4.5352020263671875\n",
      "Epoch: 0, Step: 212, Loss: 4.266454696655273\n",
      "Epoch: 0, Step: 213, Loss: 3.6234865188598633\n",
      "Epoch: 0, Step: 214, Loss: 3.9541573524475098\n",
      "Epoch: 0, Step: 215, Loss: 3.6421940326690674\n",
      "Epoch: 0, Step: 216, Loss: 4.1852617263793945\n",
      "Epoch: 0, Step: 217, Loss: 3.525969982147217\n",
      "Epoch: 0, Step: 218, Loss: 4.33016300201416\n",
      "Epoch: 0, Step: 219, Loss: 3.1265602111816406\n",
      "Epoch: 0, Step: 220, Loss: 4.654955863952637\n",
      "Epoch: 0, Step: 221, Loss: 3.2473552227020264\n",
      "Epoch: 0, Step: 222, Loss: 4.658033847808838\n",
      "Epoch: 0, Step: 223, Loss: 3.3886756896972656\n",
      "Epoch: 0, Step: 224, Loss: 3.2314672470092773\n",
      "Epoch: 0, Step: 225, Loss: 3.0178327560424805\n",
      "Epoch: 0, Step: 226, Loss: 3.342072010040283\n",
      "Epoch: 0, Step: 227, Loss: 2.8680806159973145\n",
      "Epoch: 0, Step: 228, Loss: 3.592452049255371\n",
      "Epoch: 0, Step: 229, Loss: 3.4659438133239746\n",
      "Epoch: 0, Step: 230, Loss: 3.6106979846954346\n",
      "Epoch: 0, Step: 231, Loss: 3.3638603687286377\n",
      "Epoch: 0, Step: 232, Loss: 3.9616379737854004\n",
      "Epoch: 0, Step: 233, Loss: 2.807748556137085\n",
      "Epoch: 0, Step: 234, Loss: 4.274808406829834\n",
      "Epoch: 0, Step: 235, Loss: 4.091405391693115\n",
      "Epoch: 0, Step: 236, Loss: 3.1215529441833496\n",
      "Epoch: 0, Step: 237, Loss: 3.265089511871338\n",
      "Epoch: 0, Step: 238, Loss: 3.812152862548828\n",
      "Epoch: 0, Step: 239, Loss: 2.552903175354004\n",
      "Epoch: 0, Step: 240, Loss: 3.8936643600463867\n",
      "Epoch: 0, Step: 241, Loss: 2.1963610649108887\n",
      "Epoch: 0, Step: 242, Loss: 3.751046657562256\n",
      "Epoch: 0, Step: 243, Loss: 2.8037638664245605\n",
      "Epoch: 0, Step: 244, Loss: 3.6745216846466064\n",
      "Epoch: 0, Step: 245, Loss: 3.2000160217285156\n",
      "Epoch: 0, Step: 246, Loss: 2.872227191925049\n",
      "Epoch: 0, Step: 247, Loss: 2.9390578269958496\n",
      "Epoch: 0, Step: 248, Loss: 2.781970500946045\n",
      "Epoch: 0, Step: 249, Loss: 4.40106201171875\n",
      "Epoch: 0, Step: 250, Loss: 4.089041233062744\n",
      "Epoch: 0, Step: 251, Loss: 3.6883602142333984\n",
      "Epoch: 0, Step: 252, Loss: 3.0485856533050537\n",
      "Epoch: 0, Step: 253, Loss: 4.17784309387207\n",
      "Epoch: 0, Step: 254, Loss: 2.898524761199951\n",
      "Epoch: 0, Step: 255, Loss: 3.2421538829803467\n",
      "Epoch: 0, Step: 256, Loss: 3.127425193786621\n",
      "Epoch: 0, Step: 257, Loss: 2.7117576599121094\n",
      "Epoch: 0, Step: 258, Loss: 3.179978370666504\n",
      "Epoch: 0, Step: 259, Loss: 2.9246768951416016\n",
      "Epoch: 0, Step: 260, Loss: 3.2153711318969727\n",
      "Epoch: 0, Step: 261, Loss: 3.302337646484375\n",
      "Epoch: 0, Step: 262, Loss: 3.7346372604370117\n",
      "Epoch: 0, Step: 263, Loss: 2.6949501037597656\n",
      "Epoch: 0, Step: 264, Loss: 3.2317581176757812\n",
      "Epoch: 0, Step: 265, Loss: 2.8268046379089355\n",
      "Epoch: 0, Step: 266, Loss: 2.8124032020568848\n",
      "Epoch: 0, Step: 267, Loss: 2.271347999572754\n",
      "Epoch: 0, Step: 268, Loss: 2.2112059593200684\n",
      "Epoch: 0, Step: 269, Loss: 2.141807794570923\n",
      "Epoch: 0, Step: 270, Loss: 4.179795742034912\n",
      "Epoch: 0, Step: 271, Loss: 3.428687334060669\n",
      "Epoch: 0, Step: 272, Loss: 3.090864658355713\n",
      "Epoch: 0, Step: 273, Loss: 2.8227081298828125\n",
      "Epoch: 0, Step: 274, Loss: 3.468313455581665\n",
      "Epoch: 0, Step: 275, Loss: 3.0985918045043945\n",
      "Epoch: 0, Step: 276, Loss: 2.345773220062256\n",
      "Epoch: 0, Step: 277, Loss: 2.8580403327941895\n",
      "Epoch: 0, Step: 278, Loss: 2.837397575378418\n",
      "Epoch: 0, Step: 279, Loss: 3.6383328437805176\n",
      "Epoch: 0, Step: 280, Loss: 1.908344030380249\n",
      "Epoch: 0, Step: 281, Loss: 3.3223776817321777\n",
      "Epoch: 0, Step: 282, Loss: 2.3050453662872314\n",
      "Epoch: 0, Step: 283, Loss: 2.143364429473877\n",
      "Epoch: 0, Step: 284, Loss: 3.081481456756592\n",
      "Epoch: 0, Step: 285, Loss: 2.447136402130127\n",
      "Epoch: 0, Step: 286, Loss: 2.746849536895752\n",
      "Epoch: 0, Step: 287, Loss: 2.206270217895508\n",
      "Epoch: 0, Step: 288, Loss: 2.1869800090789795\n",
      "Epoch: 0, Step: 289, Loss: 2.716120719909668\n",
      "Epoch: 0, Step: 290, Loss: 4.330080986022949\n",
      "Epoch: 0, Step: 291, Loss: 2.316819190979004\n",
      "Epoch: 0, Step: 292, Loss: 2.397671699523926\n",
      "Epoch: 0, Step: 293, Loss: 4.284032821655273\n",
      "Epoch: 0, Step: 294, Loss: 2.844092845916748\n",
      "Epoch: 0, Step: 295, Loss: 1.8239233493804932\n",
      "Epoch: 0, Step: 296, Loss: 2.741852283477783\n",
      "Epoch: 0, Step: 297, Loss: 1.8594005107879639\n",
      "Epoch: 0, Step: 298, Loss: 2.494462013244629\n",
      "Epoch: 0, Step: 299, Loss: 2.522494077682495\n",
      "Epoch: 0, Step: 300, Loss: 2.5990853309631348\n",
      "Epoch: 0, Step: 301, Loss: 3.1172070503234863\n",
      "Epoch: 0, Step: 302, Loss: 2.272808790206909\n",
      "Epoch: 0, Step: 303, Loss: 2.2472596168518066\n",
      "Epoch: 0, Step: 304, Loss: 2.112344741821289\n",
      "Epoch: 0, Step: 305, Loss: 3.390413284301758\n",
      "Epoch: 0, Step: 306, Loss: 2.7192063331604004\n",
      "Epoch: 0, Step: 307, Loss: 2.4036648273468018\n",
      "Epoch: 0, Step: 308, Loss: 3.2309017181396484\n",
      "Epoch: 0, Step: 309, Loss: 2.4560062885284424\n",
      "Epoch: 0, Step: 310, Loss: 2.541944742202759\n",
      "Epoch: 0, Step: 311, Loss: 2.0170462131500244\n",
      "Epoch: 0, Step: 312, Loss: 2.7726712226867676\n",
      "Epoch: 0, Step: 313, Loss: 3.0551180839538574\n",
      "Epoch: 0, Step: 314, Loss: 1.7396385669708252\n",
      "Epoch: 0, Step: 315, Loss: 1.5827631950378418\n",
      "Epoch: 0, Step: 316, Loss: 3.0734424591064453\n",
      "Epoch: 0, Step: 317, Loss: 2.524683952331543\n",
      "Epoch: 0, Step: 318, Loss: 3.2741761207580566\n",
      "Epoch: 0, Step: 319, Loss: 2.957113265991211\n",
      "Epoch: 0, Step: 320, Loss: 3.177466630935669\n",
      "Epoch: 0, Step: 321, Loss: 2.2117791175842285\n",
      "Epoch: 0, Step: 322, Loss: 2.2644147872924805\n",
      "Epoch: 0, Step: 323, Loss: 1.5859973430633545\n",
      "Epoch: 0, Step: 324, Loss: 3.3029212951660156\n",
      "Epoch: 0, Step: 325, Loss: 2.062852382659912\n",
      "Epoch: 0, Step: 326, Loss: 2.4184763431549072\n",
      "Epoch: 0, Step: 327, Loss: 2.143012523651123\n",
      "Epoch: 0, Step: 328, Loss: 1.548382043838501\n",
      "Epoch: 0, Step: 329, Loss: 1.7000036239624023\n",
      "Epoch: 0, Step: 330, Loss: 2.3345553874969482\n",
      "Epoch: 0, Step: 331, Loss: 2.84745717048645\n",
      "Epoch: 0, Step: 332, Loss: 2.8670051097869873\n",
      "Epoch: 0, Step: 333, Loss: 1.6097102165222168\n",
      "Epoch: 0, Step: 334, Loss: 2.162130355834961\n",
      "Epoch: 0, Step: 335, Loss: 1.9061373472213745\n",
      "Epoch: 0, Step: 336, Loss: 1.804652214050293\n",
      "Epoch: 0, Step: 337, Loss: 2.4805331230163574\n",
      "Epoch: 0, Step: 338, Loss: 1.5333166122436523\n",
      "Epoch: 0, Step: 339, Loss: 2.089407444000244\n",
      "Epoch: 0, Step: 340, Loss: 3.2194952964782715\n",
      "Epoch: 0, Step: 341, Loss: 1.7560210227966309\n",
      "Epoch: 0, Step: 342, Loss: 1.8599541187286377\n",
      "Epoch: 0, Step: 343, Loss: 2.4969332218170166\n",
      "Epoch: 0, Step: 344, Loss: 2.554795265197754\n",
      "Epoch: 0, Step: 345, Loss: 2.2665112018585205\n",
      "Epoch: 0, Step: 346, Loss: 2.2033655643463135\n",
      "Epoch: 0, Step: 347, Loss: 1.9115842580795288\n",
      "Epoch: 0, Step: 348, Loss: 1.0841010808944702\n",
      "Epoch: 0, Step: 349, Loss: 2.3538818359375\n",
      "Epoch: 0, Step: 350, Loss: 2.5330653190612793\n",
      "Epoch: 0, Step: 351, Loss: 2.214876890182495\n",
      "Epoch: 0, Step: 352, Loss: 2.2185487747192383\n",
      "Epoch: 0, Step: 353, Loss: 1.6252751350402832\n",
      "Epoch: 0, Step: 354, Loss: 2.3701584339141846\n",
      "Epoch: 0, Step: 355, Loss: 2.1997883319854736\n",
      "Epoch: 0, Step: 356, Loss: 2.881452798843384\n",
      "Epoch: 0, Step: 357, Loss: 1.8220794200897217\n",
      "Epoch: 0, Step: 358, Loss: 2.159850597381592\n",
      "Epoch: 0, Step: 359, Loss: 2.4915223121643066\n",
      "Epoch: 0, Step: 360, Loss: 2.244676113128662\n",
      "Epoch: 0, Step: 361, Loss: 2.51370906829834\n",
      "Epoch: 0, Step: 362, Loss: 2.0983164310455322\n",
      "Epoch: 0, Step: 363, Loss: 2.7440738677978516\n",
      "Epoch: 0, Step: 364, Loss: 1.4980933666229248\n",
      "Epoch: 0, Step: 365, Loss: 2.420720100402832\n",
      "Epoch: 0, Step: 366, Loss: 1.5733613967895508\n",
      "Epoch: 0, Step: 367, Loss: 1.9860122203826904\n",
      "Epoch: 0, Step: 368, Loss: 1.4588733911514282\n",
      "Epoch: 0, Step: 369, Loss: 2.1251678466796875\n",
      "Epoch: 0, Step: 370, Loss: 2.240900993347168\n",
      "Epoch: 0, Step: 371, Loss: 1.705334186553955\n",
      "Epoch: 0, Step: 372, Loss: 1.8033405542373657\n",
      "Epoch: 0, Step: 373, Loss: 1.6907322406768799\n",
      "Epoch: 0, Step: 374, Loss: 2.6870598793029785\n",
      "Epoch: 0, Step: 375, Loss: 1.7207484245300293\n",
      "Epoch: 0, Step: 376, Loss: 1.5134060382843018\n",
      "Epoch: 0, Step: 377, Loss: 1.4525396823883057\n",
      "Epoch: 0, Step: 378, Loss: 1.353684425354004\n",
      "Epoch: 0, Step: 379, Loss: 1.1989169120788574\n",
      "Epoch: 0, Step: 380, Loss: 1.6266543865203857\n",
      "Epoch: 0, Step: 381, Loss: 1.4127620458602905\n",
      "Epoch: 0, Step: 382, Loss: 1.4876731634140015\n",
      "Epoch: 0, Step: 383, Loss: 2.000803232192993\n",
      "Epoch: 0, Step: 384, Loss: 1.5807664394378662\n",
      "Epoch: 0, Step: 385, Loss: 2.261542797088623\n",
      "Epoch: 0, Step: 386, Loss: 1.9045500755310059\n",
      "Epoch: 0, Step: 387, Loss: 2.228048324584961\n",
      "Epoch: 0, Step: 388, Loss: 1.9208446741104126\n",
      "Epoch: 0, Step: 389, Loss: 1.890160322189331\n",
      "Epoch: 0, Step: 390, Loss: 1.9280822277069092\n",
      "Epoch: 0, Step: 391, Loss: 2.1297690868377686\n",
      "Epoch: 0, Step: 392, Loss: 1.4679985046386719\n",
      "Epoch: 0, Step: 393, Loss: 1.1746995449066162\n",
      "Epoch: 0, Step: 394, Loss: 1.804208755493164\n",
      "Epoch: 0, Step: 395, Loss: 1.596604585647583\n",
      "Epoch: 0, Step: 396, Loss: 2.21531343460083\n",
      "Epoch: 0, Step: 397, Loss: 1.903218150138855\n",
      "Epoch: 0, Step: 398, Loss: 2.1221985816955566\n",
      "Epoch: 0, Step: 399, Loss: 1.4012287855148315\n",
      "Epoch: 0, Step: 400, Loss: 1.3997514247894287\n",
      "Epoch: 0, Step: 401, Loss: 1.9135804176330566\n",
      "Epoch: 0, Step: 402, Loss: 1.4888954162597656\n",
      "Epoch: 0, Step: 403, Loss: 1.4895761013031006\n",
      "Epoch: 0, Step: 404, Loss: 1.9962494373321533\n",
      "Epoch: 0, Step: 405, Loss: 1.6773654222488403\n",
      "Epoch: 0, Step: 406, Loss: 1.3684954643249512\n",
      "Epoch: 0, Step: 407, Loss: 1.8320035934448242\n",
      "Epoch: 0, Step: 408, Loss: 1.306611180305481\n",
      "Epoch: 0, Step: 409, Loss: 1.5606770515441895\n",
      "Epoch: 0, Step: 410, Loss: 2.498283863067627\n",
      "Epoch: 0, Step: 411, Loss: 1.2432913780212402\n",
      "Epoch: 0, Step: 412, Loss: 2.0633230209350586\n",
      "Epoch: 0, Step: 413, Loss: 1.9303712844848633\n",
      "Epoch: 0, Step: 414, Loss: 1.9030721187591553\n",
      "Epoch: 0, Step: 415, Loss: 2.26663875579834\n",
      "Epoch: 0, Step: 416, Loss: 2.4180455207824707\n",
      "Epoch: 0, Step: 417, Loss: 1.2102172374725342\n",
      "Epoch: 0, Step: 418, Loss: 1.8021132946014404\n",
      "Epoch: 0, Step: 419, Loss: 1.2030351161956787\n",
      "Epoch: 0, Step: 420, Loss: 1.3113069534301758\n",
      "Epoch: 0, Step: 421, Loss: 1.1947486400604248\n",
      "Epoch: 0, Step: 422, Loss: 1.884047269821167\n",
      "Epoch: 0, Step: 423, Loss: 1.7316815853118896\n",
      "Epoch: 0, Step: 424, Loss: 1.062854290008545\n",
      "Epoch: 0, Step: 425, Loss: 1.8677445650100708\n",
      "Epoch: 0, Step: 426, Loss: 1.3589820861816406\n",
      "Epoch: 0, Step: 427, Loss: 1.5635193586349487\n",
      "Epoch: 0, Step: 428, Loss: 2.137946128845215\n",
      "Epoch: 0, Step: 429, Loss: 1.0237483978271484\n",
      "Epoch: 0, Step: 430, Loss: 2.0012407302856445\n",
      "Epoch: 0, Step: 431, Loss: 1.0863981246948242\n",
      "Epoch: 0, Step: 432, Loss: 1.6137256622314453\n",
      "Epoch: 0, Step: 433, Loss: 0.9020843505859375\n",
      "Epoch: 0, Step: 434, Loss: 1.2284557819366455\n",
      "Epoch: 0, Step: 435, Loss: 1.7569284439086914\n",
      "Epoch: 0, Step: 436, Loss: 1.27632474899292\n",
      "Epoch: 0, Step: 437, Loss: 1.9231936931610107\n",
      "Epoch: 0, Step: 438, Loss: 1.5342841148376465\n",
      "Epoch: 0, Step: 439, Loss: 2.2081117630004883\n",
      "Epoch: 0, Step: 440, Loss: 1.4135799407958984\n",
      "Epoch: 0, Step: 441, Loss: 1.012715458869934\n",
      "Epoch: 0, Step: 442, Loss: 1.8319679498672485\n",
      "Epoch: 0, Step: 443, Loss: 1.1293830871582031\n",
      "Epoch: 0, Step: 444, Loss: 1.65101957321167\n",
      "Epoch: 0, Step: 445, Loss: 0.8621137142181396\n",
      "Epoch: 0, Step: 446, Loss: 1.2095258235931396\n",
      "Epoch: 0, Step: 447, Loss: 1.5752599239349365\n",
      "Epoch: 0, Step: 448, Loss: 1.4068790674209595\n",
      "Epoch: 0, Step: 449, Loss: 1.4601794481277466\n",
      "Epoch: 0, Step: 450, Loss: 2.0336034297943115\n",
      "Epoch: 0, Step: 451, Loss: 1.5335441827774048\n",
      "Epoch: 0, Step: 452, Loss: 0.8713232278823853\n",
      "Epoch: 0, Step: 453, Loss: 1.365872859954834\n",
      "Epoch: 0, Step: 454, Loss: 1.9679847955703735\n",
      "Epoch: 0, Step: 455, Loss: 1.3628638982772827\n",
      "Epoch: 0, Step: 456, Loss: 2.460165023803711\n",
      "Epoch: 0, Step: 457, Loss: 1.6995666027069092\n",
      "Epoch: 0, Step: 458, Loss: 1.5588817596435547\n",
      "Epoch: 0, Step: 459, Loss: 1.1490002870559692\n",
      "Epoch: 0, Step: 460, Loss: 1.2888450622558594\n",
      "Epoch: 0, Step: 461, Loss: 1.6478259563446045\n",
      "Epoch: 0, Step: 462, Loss: 2.0229904651641846\n",
      "Epoch: 0, Step: 463, Loss: 1.074097752571106\n",
      "Epoch: 0, Step: 464, Loss: 0.9488813877105713\n",
      "Epoch: 0, Step: 465, Loss: 1.3851877450942993\n",
      "Epoch: 0, Step: 466, Loss: 1.306617259979248\n",
      "Epoch: 0, Step: 467, Loss: 1.04026460647583\n",
      "Epoch: 0, Step: 468, Loss: 1.3696017265319824\n",
      "Epoch: 0, Step: 469, Loss: 1.5941542387008667\n",
      "Epoch: 0, Step: 470, Loss: 1.6276624202728271\n",
      "Epoch: 0, Step: 471, Loss: 2.147265672683716\n",
      "Epoch: 0, Step: 472, Loss: 1.3906528949737549\n",
      "Epoch: 0, Step: 473, Loss: 1.7269809246063232\n",
      "Epoch: 0, Step: 474, Loss: 0.9874416589736938\n",
      "Epoch: 0, Step: 475, Loss: 1.4321390390396118\n",
      "Epoch: 0, Step: 476, Loss: 1.0724800825119019\n",
      "Epoch: 0, Step: 477, Loss: 1.7856640815734863\n",
      "Epoch: 0, Step: 478, Loss: 1.7947251796722412\n",
      "Epoch: 0, Step: 479, Loss: 1.146592617034912\n",
      "Epoch: 0, Step: 480, Loss: 1.5773725509643555\n",
      "Epoch: 0, Step: 481, Loss: 1.372896432876587\n",
      "Epoch: 0, Step: 482, Loss: 1.6153935194015503\n",
      "Epoch: 0, Step: 483, Loss: 1.0001144409179688\n",
      "Epoch: 0, Step: 484, Loss: 1.2458513975143433\n",
      "Epoch: 0, Step: 485, Loss: 0.9743237495422363\n",
      "Epoch: 0, Step: 486, Loss: 1.0652565956115723\n",
      "Epoch: 0, Step: 487, Loss: 0.9466397166252136\n",
      "Epoch: 0, Step: 488, Loss: 1.816847324371338\n",
      "Epoch: 0, Step: 489, Loss: 0.8500707149505615\n",
      "Epoch: 0, Step: 490, Loss: 1.1150099039077759\n",
      "Epoch: 0, Step: 491, Loss: 1.92128586769104\n",
      "Epoch: 0, Step: 492, Loss: 1.6411192417144775\n",
      "Epoch: 0, Step: 493, Loss: 1.5691924095153809\n",
      "Epoch: 0, Step: 494, Loss: 0.9654288291931152\n",
      "Epoch: 0, Step: 495, Loss: 1.0749934911727905\n",
      "Epoch: 0, Step: 496, Loss: 1.3190008401870728\n",
      "Epoch: 0, Step: 497, Loss: 0.8011025786399841\n",
      "Epoch: 0, Step: 498, Loss: 1.827455997467041\n",
      "Epoch: 0, Step: 499, Loss: 1.255834698677063\n",
      "Epoch: 0, Step: 500, Loss: 0.9081171751022339\n",
      "Epoch: 0, Step: 501, Loss: 0.8251775503158569\n",
      "Epoch: 0, Step: 502, Loss: 1.259855031967163\n",
      "Epoch: 0, Step: 503, Loss: 0.8269009590148926\n",
      "Epoch: 1, Step: 0, Loss: 1.0417661666870117\n",
      "Epoch: 1, Step: 1, Loss: 1.242560625076294\n",
      "Epoch: 1, Step: 2, Loss: 1.0916821956634521\n",
      "Epoch: 1, Step: 3, Loss: 1.9770591259002686\n",
      "Epoch: 1, Step: 4, Loss: 0.8293759822845459\n",
      "Epoch: 1, Step: 5, Loss: 1.089514970779419\n",
      "Epoch: 1, Step: 6, Loss: 2.0932235717773438\n",
      "Epoch: 1, Step: 7, Loss: 1.4460779428482056\n",
      "Epoch: 1, Step: 8, Loss: 1.1603161096572876\n",
      "Epoch: 1, Step: 9, Loss: 1.1217248439788818\n",
      "Epoch: 1, Step: 10, Loss: 1.0822784900665283\n",
      "Epoch: 1, Step: 11, Loss: 1.0364396572113037\n",
      "Epoch: 1, Step: 12, Loss: 1.563476324081421\n",
      "Epoch: 1, Step: 13, Loss: 0.6245384216308594\n",
      "Epoch: 1, Step: 14, Loss: 1.5628080368041992\n",
      "Epoch: 1, Step: 15, Loss: 0.9741395115852356\n",
      "Epoch: 1, Step: 16, Loss: 0.7182736396789551\n",
      "Epoch: 1, Step: 17, Loss: 1.2519232034683228\n",
      "Epoch: 1, Step: 18, Loss: 1.5359408855438232\n",
      "Epoch: 1, Step: 19, Loss: 0.7902181148529053\n",
      "Epoch: 1, Step: 20, Loss: 1.3557841777801514\n",
      "Epoch: 1, Step: 21, Loss: 1.2580291032791138\n",
      "Epoch: 1, Step: 22, Loss: 1.1966406106948853\n",
      "Epoch: 1, Step: 23, Loss: 0.5566994547843933\n",
      "Epoch: 1, Step: 24, Loss: 0.6780784130096436\n",
      "Epoch: 1, Step: 25, Loss: 0.8072566986083984\n",
      "Epoch: 1, Step: 26, Loss: 0.8493468761444092\n",
      "Epoch: 1, Step: 27, Loss: 0.6926363110542297\n",
      "Epoch: 1, Step: 28, Loss: 0.952012300491333\n",
      "Epoch: 1, Step: 29, Loss: 0.6678931713104248\n",
      "Epoch: 1, Step: 30, Loss: 0.9562128186225891\n",
      "Epoch: 1, Step: 31, Loss: 1.3107348680496216\n",
      "Epoch: 1, Step: 32, Loss: 1.329308032989502\n",
      "Epoch: 1, Step: 33, Loss: 0.9901319742202759\n",
      "Epoch: 1, Step: 34, Loss: 1.1415847539901733\n",
      "Epoch: 1, Step: 35, Loss: 1.0565698146820068\n",
      "Epoch: 1, Step: 36, Loss: 1.128854751586914\n",
      "Epoch: 1, Step: 37, Loss: 0.8843246698379517\n",
      "Epoch: 1, Step: 38, Loss: 1.0166423320770264\n",
      "Epoch: 1, Step: 39, Loss: 1.292838215827942\n",
      "Epoch: 1, Step: 40, Loss: 1.4516065120697021\n",
      "Epoch: 1, Step: 41, Loss: 0.933300256729126\n",
      "Epoch: 1, Step: 42, Loss: 1.114024043083191\n",
      "Epoch: 1, Step: 43, Loss: 0.9798576831817627\n",
      "Epoch: 1, Step: 44, Loss: 0.6898000240325928\n",
      "Epoch: 1, Step: 45, Loss: 1.0666520595550537\n",
      "Epoch: 1, Step: 46, Loss: 0.7394589781761169\n",
      "Epoch: 1, Step: 47, Loss: 0.820305585861206\n",
      "Epoch: 1, Step: 48, Loss: 0.6464377641677856\n",
      "Epoch: 1, Step: 49, Loss: 1.8654513359069824\n",
      "Epoch: 1, Step: 50, Loss: 0.831933319568634\n",
      "Epoch: 1, Step: 51, Loss: 0.8643422722816467\n",
      "Epoch: 1, Step: 52, Loss: 0.6763174533843994\n",
      "Epoch: 1, Step: 53, Loss: 1.5283514261245728\n",
      "Epoch: 1, Step: 54, Loss: 1.2053353786468506\n",
      "Epoch: 1, Step: 55, Loss: 0.6180282235145569\n",
      "Epoch: 1, Step: 56, Loss: 0.9399582147598267\n",
      "Epoch: 1, Step: 57, Loss: 0.9595595002174377\n",
      "Epoch: 1, Step: 58, Loss: 1.1489636898040771\n",
      "Epoch: 1, Step: 59, Loss: 1.0448814630508423\n",
      "Epoch: 1, Step: 60, Loss: 0.8239450454711914\n",
      "Epoch: 1, Step: 61, Loss: 0.6132959127426147\n",
      "Epoch: 1, Step: 62, Loss: 1.0473829507827759\n",
      "Epoch: 1, Step: 63, Loss: 1.4264302253723145\n",
      "Epoch: 1, Step: 64, Loss: 1.3789846897125244\n",
      "Epoch: 1, Step: 65, Loss: 0.9909911751747131\n",
      "Epoch: 1, Step: 66, Loss: 0.8379492163658142\n",
      "Epoch: 1, Step: 67, Loss: 1.5368635654449463\n",
      "Epoch: 1, Step: 68, Loss: 1.3192901611328125\n",
      "Epoch: 1, Step: 69, Loss: 1.5210702419281006\n",
      "Epoch: 1, Step: 70, Loss: 1.0898516178131104\n",
      "Epoch: 1, Step: 71, Loss: 1.0974688529968262\n",
      "Epoch: 1, Step: 72, Loss: 1.4014346599578857\n",
      "Epoch: 1, Step: 73, Loss: 1.1334643363952637\n",
      "Epoch: 1, Step: 74, Loss: 0.6028705835342407\n",
      "Epoch: 1, Step: 75, Loss: 0.8639126420021057\n",
      "Epoch: 1, Step: 76, Loss: 0.848351001739502\n",
      "Epoch: 1, Step: 77, Loss: 0.7671610116958618\n",
      "Epoch: 1, Step: 78, Loss: 0.7414596676826477\n",
      "Epoch: 1, Step: 79, Loss: 0.7676196694374084\n",
      "Epoch: 1, Step: 80, Loss: 1.0419821739196777\n",
      "Epoch: 1, Step: 81, Loss: 1.2408366203308105\n",
      "Epoch: 1, Step: 82, Loss: 0.764841616153717\n",
      "Epoch: 1, Step: 83, Loss: 1.238649845123291\n",
      "Epoch: 1, Step: 84, Loss: 1.5459030866622925\n",
      "Epoch: 1, Step: 85, Loss: 0.7517251968383789\n",
      "Epoch: 1, Step: 86, Loss: 1.2867956161499023\n",
      "Epoch: 1, Step: 87, Loss: 1.0319873094558716\n",
      "Epoch: 1, Step: 88, Loss: 1.030462622642517\n",
      "Epoch: 1, Step: 89, Loss: 0.3792451322078705\n",
      "Epoch: 1, Step: 90, Loss: 1.408592939376831\n",
      "Epoch: 1, Step: 91, Loss: 0.9684346914291382\n",
      "Epoch: 1, Step: 92, Loss: 1.2803453207015991\n",
      "Epoch: 1, Step: 93, Loss: 0.7687650918960571\n",
      "Epoch: 1, Step: 94, Loss: 0.6446165442466736\n",
      "Epoch: 1, Step: 95, Loss: 1.2151329517364502\n",
      "Epoch: 1, Step: 96, Loss: 0.5573888421058655\n",
      "Epoch: 1, Step: 97, Loss: 0.9405566453933716\n",
      "Epoch: 1, Step: 98, Loss: 0.7037412524223328\n",
      "Epoch: 1, Step: 99, Loss: 1.2705485820770264\n",
      "Epoch: 1, Step: 100, Loss: 1.2744202613830566\n",
      "Epoch: 1, Step: 101, Loss: 0.7041469812393188\n",
      "Epoch: 1, Step: 102, Loss: 0.8707330822944641\n",
      "Epoch: 1, Step: 103, Loss: 0.6903603076934814\n",
      "Epoch: 1, Step: 104, Loss: 0.8706382513046265\n",
      "Epoch: 1, Step: 105, Loss: 0.8957012891769409\n",
      "Epoch: 1, Step: 106, Loss: 1.138346552848816\n",
      "Epoch: 1, Step: 107, Loss: 0.563672661781311\n",
      "Epoch: 1, Step: 108, Loss: 0.9628429412841797\n",
      "Epoch: 1, Step: 109, Loss: 0.7552628517150879\n",
      "Epoch: 1, Step: 110, Loss: 0.48450297117233276\n",
      "Epoch: 1, Step: 111, Loss: 0.8582383394241333\n",
      "Epoch: 1, Step: 112, Loss: 0.8499062061309814\n",
      "Epoch: 1, Step: 113, Loss: 0.8753127455711365\n",
      "Epoch: 1, Step: 114, Loss: 0.4826153516769409\n",
      "Epoch: 1, Step: 115, Loss: 0.6999010443687439\n",
      "Epoch: 1, Step: 116, Loss: 1.2846730947494507\n",
      "Epoch: 1, Step: 117, Loss: 1.0805193185806274\n",
      "Epoch: 1, Step: 118, Loss: 0.6164185404777527\n",
      "Epoch: 1, Step: 119, Loss: 0.5468645095825195\n",
      "Epoch: 1, Step: 120, Loss: 0.4695579409599304\n",
      "Epoch: 1, Step: 121, Loss: 0.9234684705734253\n",
      "Epoch: 1, Step: 122, Loss: 0.6913506984710693\n",
      "Epoch: 1, Step: 123, Loss: 0.5983752012252808\n",
      "Epoch: 1, Step: 124, Loss: 0.7951223254203796\n",
      "Epoch: 1, Step: 125, Loss: 0.5847930908203125\n",
      "Epoch: 1, Step: 126, Loss: 0.8846967220306396\n",
      "Epoch: 1, Step: 127, Loss: 0.831022322177887\n",
      "Epoch: 1, Step: 128, Loss: 0.9834260940551758\n",
      "Epoch: 1, Step: 129, Loss: 1.2198177576065063\n",
      "Epoch: 1, Step: 130, Loss: 0.6180474758148193\n",
      "Epoch: 1, Step: 131, Loss: 0.6107083559036255\n",
      "Epoch: 1, Step: 132, Loss: 0.7237486839294434\n",
      "Epoch: 1, Step: 133, Loss: 0.7025315761566162\n",
      "Epoch: 1, Step: 134, Loss: 0.9445394277572632\n",
      "Epoch: 1, Step: 135, Loss: 1.2252271175384521\n",
      "Epoch: 1, Step: 136, Loss: 0.7775213122367859\n",
      "Epoch: 1, Step: 137, Loss: 0.7248098850250244\n",
      "Epoch: 1, Step: 138, Loss: 0.6864624619483948\n",
      "Epoch: 1, Step: 139, Loss: 0.5946301221847534\n",
      "Epoch: 1, Step: 140, Loss: 1.1719111204147339\n",
      "Epoch: 1, Step: 141, Loss: 0.6448621153831482\n",
      "Epoch: 1, Step: 142, Loss: 1.116384744644165\n",
      "Epoch: 1, Step: 143, Loss: 0.5986323952674866\n",
      "Epoch: 1, Step: 144, Loss: 0.914269208908081\n",
      "Epoch: 1, Step: 145, Loss: 1.1123466491699219\n",
      "Epoch: 1, Step: 146, Loss: 0.6525874733924866\n",
      "Epoch: 1, Step: 147, Loss: 0.599251389503479\n",
      "Epoch: 1, Step: 148, Loss: 0.7627675533294678\n",
      "Epoch: 1, Step: 149, Loss: 0.664026141166687\n",
      "Epoch: 1, Step: 150, Loss: 0.6501035690307617\n",
      "Epoch: 1, Step: 151, Loss: 0.8857496380805969\n",
      "Epoch: 1, Step: 152, Loss: 0.4952157139778137\n",
      "Epoch: 1, Step: 153, Loss: 0.6513778567314148\n",
      "Epoch: 1, Step: 154, Loss: 1.0866713523864746\n",
      "Epoch: 1, Step: 155, Loss: 0.4821087121963501\n",
      "Epoch: 1, Step: 156, Loss: 0.8310770988464355\n",
      "Epoch: 1, Step: 157, Loss: 0.684289813041687\n",
      "Epoch: 1, Step: 158, Loss: 0.8854940533638\n",
      "Epoch: 1, Step: 159, Loss: 0.5430638790130615\n",
      "Epoch: 1, Step: 160, Loss: 0.8007458448410034\n",
      "Epoch: 1, Step: 161, Loss: 0.676075279712677\n",
      "Epoch: 1, Step: 162, Loss: 0.5582074522972107\n",
      "Epoch: 1, Step: 163, Loss: 0.4434479773044586\n",
      "Epoch: 1, Step: 164, Loss: 0.8363770246505737\n",
      "Epoch: 1, Step: 165, Loss: 0.8939065933227539\n",
      "Epoch: 1, Step: 166, Loss: 0.5724799036979675\n",
      "Epoch: 1, Step: 167, Loss: 0.5176820158958435\n",
      "Epoch: 1, Step: 168, Loss: 0.5971237421035767\n",
      "Epoch: 1, Step: 169, Loss: 1.0484132766723633\n",
      "Epoch: 1, Step: 170, Loss: 0.6862862706184387\n",
      "Epoch: 1, Step: 171, Loss: 0.7295882701873779\n",
      "Epoch: 1, Step: 172, Loss: 0.7811028957366943\n",
      "Epoch: 1, Step: 173, Loss: 1.1902058124542236\n",
      "Epoch: 1, Step: 174, Loss: 0.7394634485244751\n",
      "Epoch: 1, Step: 175, Loss: 0.9541648030281067\n",
      "Epoch: 1, Step: 176, Loss: 1.045158863067627\n",
      "Epoch: 1, Step: 177, Loss: 1.1364258527755737\n",
      "Epoch: 1, Step: 178, Loss: 0.6782324314117432\n",
      "Epoch: 1, Step: 179, Loss: 0.6258950233459473\n",
      "Epoch: 1, Step: 180, Loss: 0.5849066972732544\n",
      "Epoch: 1, Step: 181, Loss: 0.40156838297843933\n",
      "Epoch: 1, Step: 182, Loss: 0.4766708016395569\n",
      "Epoch: 1, Step: 183, Loss: 0.6478707790374756\n",
      "Epoch: 1, Step: 184, Loss: 0.38665443658828735\n",
      "Epoch: 1, Step: 185, Loss: 1.0219697952270508\n",
      "Epoch: 1, Step: 186, Loss: 0.9509540796279907\n",
      "Epoch: 1, Step: 187, Loss: 0.8192115426063538\n",
      "Epoch: 1, Step: 188, Loss: 0.5637969970703125\n",
      "Epoch: 1, Step: 189, Loss: 1.071850299835205\n",
      "Epoch: 1, Step: 190, Loss: 0.8307274580001831\n",
      "Epoch: 1, Step: 191, Loss: 0.687035322189331\n",
      "Epoch: 1, Step: 192, Loss: 0.9720437526702881\n",
      "Epoch: 1, Step: 193, Loss: 0.7218130826950073\n",
      "Epoch: 1, Step: 194, Loss: 0.4656253457069397\n",
      "Epoch: 1, Step: 195, Loss: 0.39881399273872375\n",
      "Epoch: 1, Step: 196, Loss: 0.567052960395813\n",
      "Epoch: 1, Step: 197, Loss: 0.5386562943458557\n",
      "Epoch: 1, Step: 198, Loss: 0.5662791728973389\n",
      "Epoch: 1, Step: 199, Loss: 0.9076463580131531\n",
      "Epoch: 1, Step: 200, Loss: 0.7138673663139343\n",
      "Epoch: 1, Step: 201, Loss: 0.8517880439758301\n",
      "Epoch: 1, Step: 202, Loss: 0.5822251439094543\n",
      "Epoch: 1, Step: 203, Loss: 0.7440626621246338\n",
      "Epoch: 1, Step: 204, Loss: 0.4793919324874878\n",
      "Epoch: 1, Step: 205, Loss: 0.7611879110336304\n",
      "Epoch: 1, Step: 206, Loss: 0.6457821726799011\n",
      "Epoch: 1, Step: 207, Loss: 0.8563896417617798\n",
      "Epoch: 1, Step: 208, Loss: 0.5961434245109558\n",
      "Epoch: 1, Step: 209, Loss: 0.46398288011550903\n",
      "Epoch: 1, Step: 210, Loss: 0.6561734676361084\n",
      "Epoch: 1, Step: 211, Loss: 0.6104192733764648\n",
      "Epoch: 1, Step: 212, Loss: 0.651875376701355\n",
      "Epoch: 1, Step: 213, Loss: 0.4822250306606293\n",
      "Epoch: 1, Step: 214, Loss: 0.7463761568069458\n",
      "Epoch: 1, Step: 215, Loss: 0.5049840807914734\n",
      "Epoch: 1, Step: 216, Loss: 0.7692848443984985\n",
      "Epoch: 1, Step: 217, Loss: 0.5834757685661316\n",
      "Epoch: 1, Step: 218, Loss: 1.003669023513794\n",
      "Epoch: 1, Step: 219, Loss: 0.7111049294471741\n",
      "Epoch: 1, Step: 220, Loss: 0.8993251323699951\n",
      "Epoch: 1, Step: 221, Loss: 0.39019760489463806\n",
      "Epoch: 1, Step: 222, Loss: 0.4190502166748047\n",
      "Epoch: 1, Step: 223, Loss: 0.7671278715133667\n",
      "Epoch: 1, Step: 224, Loss: 0.7179083228111267\n",
      "Epoch: 1, Step: 225, Loss: 0.5056814551353455\n",
      "Epoch: 1, Step: 226, Loss: 0.6316143274307251\n",
      "Epoch: 1, Step: 227, Loss: 0.8441236615180969\n",
      "Epoch: 1, Step: 228, Loss: 1.3042941093444824\n",
      "Epoch: 1, Step: 229, Loss: 0.46143782138824463\n",
      "Epoch: 1, Step: 230, Loss: 0.5966192483901978\n",
      "Epoch: 1, Step: 231, Loss: 0.5198664665222168\n",
      "Epoch: 1, Step: 232, Loss: 0.7014857530593872\n",
      "Epoch: 1, Step: 233, Loss: 0.5032342672348022\n",
      "Epoch: 1, Step: 234, Loss: 1.2353744506835938\n",
      "Epoch: 1, Step: 235, Loss: 0.6616767048835754\n",
      "Epoch: 1, Step: 236, Loss: 0.6516580581665039\n",
      "Epoch: 1, Step: 237, Loss: 1.0562160015106201\n",
      "Epoch: 1, Step: 238, Loss: 0.80049729347229\n",
      "Epoch: 1, Step: 239, Loss: 0.9153317213058472\n",
      "Epoch: 1, Step: 240, Loss: 0.6598409414291382\n",
      "Epoch: 1, Step: 241, Loss: 0.5455020666122437\n",
      "Epoch: 1, Step: 242, Loss: 0.6617359519004822\n",
      "Epoch: 1, Step: 243, Loss: 0.7265490889549255\n",
      "Epoch: 1, Step: 244, Loss: 0.6847953200340271\n",
      "Epoch: 1, Step: 245, Loss: 0.449116587638855\n",
      "Epoch: 1, Step: 246, Loss: 0.5657292604446411\n",
      "Epoch: 1, Step: 247, Loss: 1.0617411136627197\n",
      "Epoch: 1, Step: 248, Loss: 0.5514169335365295\n",
      "Epoch: 1, Step: 249, Loss: 0.9694738388061523\n",
      "Epoch: 1, Step: 250, Loss: 0.25161153078079224\n",
      "Epoch: 1, Step: 251, Loss: 0.31072258949279785\n",
      "Epoch: 1, Step: 252, Loss: 0.5960433483123779\n",
      "Epoch: 1, Step: 253, Loss: 0.6193469166755676\n",
      "Epoch: 1, Step: 254, Loss: 0.5181236267089844\n",
      "Epoch: 1, Step: 255, Loss: 0.9376963973045349\n",
      "Epoch: 1, Step: 256, Loss: 0.4579252600669861\n",
      "Epoch: 1, Step: 257, Loss: 0.6257525086402893\n",
      "Epoch: 1, Step: 258, Loss: 0.566563606262207\n",
      "Epoch: 1, Step: 259, Loss: 0.6498689651489258\n",
      "Epoch: 1, Step: 260, Loss: 0.8053774833679199\n",
      "Epoch: 1, Step: 261, Loss: 0.5883243083953857\n",
      "Epoch: 1, Step: 262, Loss: 0.9387111663818359\n",
      "Epoch: 1, Step: 263, Loss: 0.5003399848937988\n",
      "Epoch: 1, Step: 264, Loss: 0.7834621667861938\n",
      "Epoch: 1, Step: 265, Loss: 0.5068106651306152\n",
      "Epoch: 1, Step: 266, Loss: 1.266390323638916\n",
      "Epoch: 1, Step: 267, Loss: 0.40761327743530273\n",
      "Epoch: 1, Step: 268, Loss: 0.6844948530197144\n",
      "Epoch: 1, Step: 269, Loss: 0.5872674584388733\n",
      "Epoch: 1, Step: 270, Loss: 0.8092941641807556\n",
      "Epoch: 1, Step: 271, Loss: 0.44782114028930664\n",
      "Epoch: 1, Step: 272, Loss: 0.5763736963272095\n",
      "Epoch: 1, Step: 273, Loss: 0.4732503294944763\n",
      "Epoch: 1, Step: 274, Loss: 0.48251137137413025\n",
      "Epoch: 1, Step: 275, Loss: 0.5255836248397827\n",
      "Epoch: 1, Step: 276, Loss: 0.5435804128646851\n",
      "Epoch: 1, Step: 277, Loss: 0.5772432684898376\n",
      "Epoch: 1, Step: 278, Loss: 0.37705013155937195\n",
      "Epoch: 1, Step: 279, Loss: 0.4226093888282776\n",
      "Epoch: 1, Step: 280, Loss: 0.6601110100746155\n",
      "Epoch: 1, Step: 281, Loss: 0.6269940733909607\n",
      "Epoch: 1, Step: 282, Loss: 0.5559194087982178\n",
      "Epoch: 1, Step: 283, Loss: 0.33652380108833313\n",
      "Epoch: 1, Step: 284, Loss: 0.7409982681274414\n",
      "Epoch: 1, Step: 285, Loss: 0.4836907982826233\n",
      "Epoch: 1, Step: 286, Loss: 0.7831628322601318\n",
      "Epoch: 1, Step: 287, Loss: 0.7411584854125977\n",
      "Epoch: 1, Step: 288, Loss: 0.8353873491287231\n",
      "Epoch: 1, Step: 289, Loss: 0.6384339332580566\n",
      "Epoch: 1, Step: 290, Loss: 0.5698639154434204\n",
      "Epoch: 1, Step: 291, Loss: 0.4047001898288727\n",
      "Epoch: 1, Step: 292, Loss: 0.5045239329338074\n",
      "Epoch: 1, Step: 293, Loss: 0.513476550579071\n",
      "Epoch: 1, Step: 294, Loss: 0.47020888328552246\n",
      "Epoch: 1, Step: 295, Loss: 0.8164187669754028\n",
      "Epoch: 1, Step: 296, Loss: 0.6480144262313843\n",
      "Epoch: 1, Step: 297, Loss: 0.6066479086875916\n",
      "Epoch: 1, Step: 298, Loss: 0.29243287444114685\n",
      "Epoch: 1, Step: 299, Loss: 0.5343739986419678\n",
      "Epoch: 1, Step: 300, Loss: 0.39932945370674133\n",
      "Epoch: 1, Step: 301, Loss: 0.46186333894729614\n",
      "Epoch: 1, Step: 302, Loss: 0.41598978638648987\n",
      "Epoch: 1, Step: 303, Loss: 0.2986803650856018\n",
      "Epoch: 1, Step: 304, Loss: 0.574022650718689\n",
      "Epoch: 1, Step: 305, Loss: 0.5577284097671509\n",
      "Epoch: 1, Step: 306, Loss: 0.8006380200386047\n",
      "Epoch: 1, Step: 307, Loss: 0.7161019444465637\n",
      "Epoch: 1, Step: 308, Loss: 0.3538767099380493\n",
      "Epoch: 1, Step: 309, Loss: 0.6351283192634583\n",
      "Epoch: 1, Step: 310, Loss: 0.35171109437942505\n",
      "Epoch: 1, Step: 311, Loss: 0.6633630990982056\n",
      "Epoch: 1, Step: 312, Loss: 0.5297799110412598\n",
      "Epoch: 1, Step: 313, Loss: 0.5495880246162415\n",
      "Epoch: 1, Step: 314, Loss: 0.5146303176879883\n",
      "Epoch: 1, Step: 315, Loss: 0.6121374368667603\n",
      "Epoch: 1, Step: 316, Loss: 0.4533730447292328\n",
      "Epoch: 1, Step: 317, Loss: 0.4023647904396057\n",
      "Epoch: 1, Step: 318, Loss: 0.5475589036941528\n",
      "Epoch: 1, Step: 319, Loss: 0.5434104800224304\n",
      "Epoch: 1, Step: 320, Loss: 0.6462306976318359\n",
      "Epoch: 1, Step: 321, Loss: 0.30861014127731323\n",
      "Epoch: 1, Step: 322, Loss: 0.5776916742324829\n",
      "Epoch: 1, Step: 323, Loss: 0.49503397941589355\n",
      "Epoch: 1, Step: 324, Loss: 0.3722715377807617\n",
      "Epoch: 1, Step: 325, Loss: 0.4440528154373169\n",
      "Epoch: 1, Step: 326, Loss: 0.685569167137146\n",
      "Epoch: 1, Step: 327, Loss: 0.3068884611129761\n",
      "Epoch: 1, Step: 328, Loss: 0.4798439145088196\n",
      "Epoch: 1, Step: 329, Loss: 0.649638831615448\n",
      "Epoch: 1, Step: 330, Loss: 0.3626065254211426\n",
      "Epoch: 1, Step: 331, Loss: 0.3360599875450134\n",
      "Epoch: 1, Step: 332, Loss: 0.4629993438720703\n",
      "Epoch: 1, Step: 333, Loss: 0.564624547958374\n",
      "Epoch: 1, Step: 334, Loss: 0.485166072845459\n",
      "Epoch: 1, Step: 335, Loss: 0.44436100125312805\n",
      "Epoch: 1, Step: 336, Loss: 0.6672626733779907\n",
      "Epoch: 1, Step: 337, Loss: 0.9399478435516357\n",
      "Epoch: 1, Step: 338, Loss: 0.5979318022727966\n",
      "Epoch: 1, Step: 339, Loss: 0.45287302136421204\n",
      "Epoch: 1, Step: 340, Loss: 0.6557931303977966\n",
      "Epoch: 1, Step: 341, Loss: 0.707749605178833\n",
      "Epoch: 1, Step: 342, Loss: 0.2885318100452423\n",
      "Epoch: 1, Step: 343, Loss: 0.47826439142227173\n",
      "Epoch: 1, Step: 344, Loss: 0.4019413888454437\n",
      "Epoch: 1, Step: 345, Loss: 0.6241898536682129\n",
      "Epoch: 1, Step: 346, Loss: 0.5221506953239441\n",
      "Epoch: 1, Step: 347, Loss: 0.6797184348106384\n",
      "Epoch: 1, Step: 348, Loss: 0.2652781903743744\n",
      "Epoch: 1, Step: 349, Loss: 0.501406192779541\n",
      "Epoch: 1, Step: 350, Loss: 0.43932387232780457\n",
      "Epoch: 1, Step: 351, Loss: 0.2978478670120239\n",
      "Epoch: 1, Step: 352, Loss: 0.36768412590026855\n",
      "Epoch: 1, Step: 353, Loss: 0.3481849730014801\n",
      "Epoch: 1, Step: 354, Loss: 0.7128803730010986\n",
      "Epoch: 1, Step: 355, Loss: 0.671241044998169\n",
      "Epoch: 1, Step: 356, Loss: 0.31193220615386963\n",
      "Epoch: 1, Step: 357, Loss: 0.3260897994041443\n",
      "Epoch: 1, Step: 358, Loss: 0.6536141633987427\n",
      "Epoch: 1, Step: 359, Loss: 0.5995404720306396\n",
      "Epoch: 1, Step: 360, Loss: 0.40435469150543213\n",
      "Epoch: 1, Step: 361, Loss: 0.578180193901062\n",
      "Epoch: 1, Step: 362, Loss: 0.33306941390037537\n",
      "Epoch: 1, Step: 363, Loss: 0.22750407457351685\n",
      "Epoch: 1, Step: 364, Loss: 0.5585870146751404\n",
      "Epoch: 1, Step: 365, Loss: 0.719254732131958\n",
      "Epoch: 1, Step: 366, Loss: 0.2861921787261963\n",
      "Epoch: 1, Step: 367, Loss: 0.6022733449935913\n",
      "Epoch: 1, Step: 368, Loss: 0.7618554830551147\n",
      "Epoch: 1, Step: 369, Loss: 0.24804966151714325\n",
      "Epoch: 1, Step: 370, Loss: 0.5949926376342773\n",
      "Epoch: 1, Step: 371, Loss: 0.2593836188316345\n",
      "Epoch: 1, Step: 372, Loss: 0.36956945061683655\n",
      "Epoch: 1, Step: 373, Loss: 0.49286362528800964\n",
      "Epoch: 1, Step: 374, Loss: 0.3646579086780548\n",
      "Epoch: 1, Step: 375, Loss: 0.655148983001709\n",
      "Epoch: 1, Step: 376, Loss: 0.25997239351272583\n",
      "Epoch: 1, Step: 377, Loss: 0.4294675290584564\n",
      "Epoch: 1, Step: 378, Loss: 0.4079134464263916\n",
      "Epoch: 1, Step: 379, Loss: 0.33520227670669556\n",
      "Epoch: 1, Step: 380, Loss: 0.39637434482574463\n",
      "Epoch: 1, Step: 381, Loss: 0.541163980960846\n",
      "Epoch: 1, Step: 382, Loss: 0.3464964032173157\n",
      "Epoch: 1, Step: 383, Loss: 0.6353663802146912\n",
      "Epoch: 1, Step: 384, Loss: 0.2933441996574402\n",
      "Epoch: 1, Step: 385, Loss: 0.3734739422798157\n",
      "Epoch: 1, Step: 386, Loss: 0.5739573836326599\n",
      "Epoch: 1, Step: 387, Loss: 0.6001399755477905\n",
      "Epoch: 1, Step: 388, Loss: 0.5027904510498047\n",
      "Epoch: 1, Step: 389, Loss: 0.6973694562911987\n",
      "Epoch: 1, Step: 390, Loss: 0.23391786217689514\n",
      "Epoch: 1, Step: 391, Loss: 0.5781470537185669\n",
      "Epoch: 1, Step: 392, Loss: 0.4084893465042114\n",
      "Epoch: 1, Step: 393, Loss: 0.39045342803001404\n",
      "Epoch: 1, Step: 394, Loss: 0.29294514656066895\n",
      "Epoch: 1, Step: 395, Loss: 0.4123690128326416\n",
      "Epoch: 1, Step: 396, Loss: 0.5468224883079529\n",
      "Epoch: 1, Step: 397, Loss: 0.23298421502113342\n",
      "Epoch: 1, Step: 398, Loss: 0.4653858542442322\n",
      "Epoch: 1, Step: 399, Loss: 0.3828968107700348\n",
      "Epoch: 1, Step: 400, Loss: 0.39273208379745483\n",
      "Epoch: 1, Step: 401, Loss: 0.7048430442810059\n",
      "Epoch: 1, Step: 402, Loss: 0.5035706758499146\n",
      "Epoch: 1, Step: 403, Loss: 0.6516104340553284\n",
      "Epoch: 1, Step: 404, Loss: 0.5531817078590393\n",
      "Epoch: 1, Step: 405, Loss: 0.2747587263584137\n",
      "Epoch: 1, Step: 406, Loss: 0.6449321508407593\n",
      "Epoch: 1, Step: 407, Loss: 0.3111143112182617\n",
      "Epoch: 1, Step: 408, Loss: 0.45759910345077515\n",
      "Epoch: 1, Step: 409, Loss: 0.3647725582122803\n",
      "Epoch: 1, Step: 410, Loss: 0.48913487792015076\n",
      "Epoch: 1, Step: 411, Loss: 0.49477654695510864\n",
      "Epoch: 1, Step: 412, Loss: 0.3159673810005188\n",
      "Epoch: 1, Step: 413, Loss: 0.38011634349823\n",
      "Epoch: 1, Step: 414, Loss: 0.5205199718475342\n",
      "Epoch: 1, Step: 415, Loss: 0.27641788125038147\n",
      "Epoch: 1, Step: 416, Loss: 0.4747178554534912\n",
      "Epoch: 1, Step: 417, Loss: 0.48405084013938904\n",
      "Epoch: 1, Step: 418, Loss: 0.6342638731002808\n",
      "Epoch: 1, Step: 419, Loss: 0.5284587144851685\n",
      "Epoch: 1, Step: 420, Loss: 0.2967255711555481\n",
      "Epoch: 1, Step: 421, Loss: 0.29357847571372986\n",
      "Epoch: 1, Step: 422, Loss: 0.6986286640167236\n",
      "Epoch: 1, Step: 423, Loss: 0.5409589409828186\n",
      "Epoch: 1, Step: 424, Loss: 0.5030274391174316\n",
      "Epoch: 1, Step: 425, Loss: 0.526050865650177\n",
      "Epoch: 1, Step: 426, Loss: 0.5066406726837158\n",
      "Epoch: 1, Step: 427, Loss: 0.3068004846572876\n",
      "Epoch: 1, Step: 428, Loss: 0.2646980881690979\n",
      "Epoch: 1, Step: 429, Loss: 0.37573128938674927\n",
      "Epoch: 1, Step: 430, Loss: 0.5568596720695496\n",
      "Epoch: 1, Step: 431, Loss: 0.5627480745315552\n",
      "Epoch: 1, Step: 432, Loss: 0.5111566781997681\n",
      "Epoch: 1, Step: 433, Loss: 0.4974105656147003\n",
      "Epoch: 1, Step: 434, Loss: 0.45265108346939087\n",
      "Epoch: 1, Step: 435, Loss: 0.3450424075126648\n",
      "Epoch: 1, Step: 436, Loss: 0.340378999710083\n",
      "Epoch: 1, Step: 437, Loss: 0.39812758564949036\n",
      "Epoch: 1, Step: 438, Loss: 0.3650583028793335\n",
      "Epoch: 1, Step: 439, Loss: 0.5248328447341919\n",
      "Epoch: 1, Step: 440, Loss: 0.4576941728591919\n",
      "Epoch: 1, Step: 441, Loss: 0.5482252836227417\n",
      "Epoch: 1, Step: 442, Loss: 0.2938459515571594\n",
      "Epoch: 1, Step: 443, Loss: 0.38286906480789185\n",
      "Epoch: 1, Step: 444, Loss: 0.5043180584907532\n",
      "Epoch: 1, Step: 445, Loss: 0.6496707201004028\n",
      "Epoch: 1, Step: 446, Loss: 0.4149453043937683\n",
      "Epoch: 1, Step: 447, Loss: 0.35352420806884766\n",
      "Epoch: 1, Step: 448, Loss: 0.6639405488967896\n",
      "Epoch: 1, Step: 449, Loss: 0.4276387095451355\n",
      "Epoch: 1, Step: 450, Loss: 0.24688777327537537\n",
      "Epoch: 1, Step: 451, Loss: 0.34936219453811646\n",
      "Epoch: 1, Step: 452, Loss: 0.5876162052154541\n",
      "Epoch: 1, Step: 453, Loss: 0.4801366925239563\n",
      "Epoch: 1, Step: 454, Loss: 0.2783583700656891\n",
      "Epoch: 1, Step: 455, Loss: 0.4235331416130066\n",
      "Epoch: 1, Step: 456, Loss: 0.2599070966243744\n",
      "Epoch: 1, Step: 457, Loss: 0.38924896717071533\n",
      "Epoch: 1, Step: 458, Loss: 0.23056930303573608\n",
      "Epoch: 1, Step: 459, Loss: 0.5261620879173279\n",
      "Epoch: 1, Step: 460, Loss: 0.2775653302669525\n",
      "Epoch: 1, Step: 461, Loss: 0.5729720592498779\n",
      "Epoch: 1, Step: 462, Loss: 0.6064947843551636\n",
      "Epoch: 1, Step: 463, Loss: 0.2681077718734741\n",
      "Epoch: 1, Step: 464, Loss: 0.3975875973701477\n",
      "Epoch: 1, Step: 465, Loss: 0.46073710918426514\n",
      "Epoch: 1, Step: 466, Loss: 0.545121431350708\n",
      "Epoch: 1, Step: 467, Loss: 0.20398999750614166\n",
      "Epoch: 1, Step: 468, Loss: 0.40781041979789734\n",
      "Epoch: 1, Step: 469, Loss: 0.533145546913147\n",
      "Epoch: 1, Step: 470, Loss: 0.6162033081054688\n",
      "Epoch: 1, Step: 471, Loss: 0.2824023962020874\n",
      "Epoch: 1, Step: 472, Loss: 0.6672463417053223\n",
      "Epoch: 1, Step: 473, Loss: 0.3706003725528717\n",
      "Epoch: 1, Step: 474, Loss: 0.44619500637054443\n",
      "Epoch: 1, Step: 475, Loss: 0.4785918593406677\n",
      "Epoch: 1, Step: 476, Loss: 0.27325689792633057\n",
      "Epoch: 1, Step: 477, Loss: 0.600192129611969\n",
      "Epoch: 1, Step: 478, Loss: 0.32492339611053467\n",
      "Epoch: 1, Step: 479, Loss: 0.38224199414253235\n",
      "Epoch: 1, Step: 480, Loss: 0.5561769008636475\n",
      "Epoch: 1, Step: 481, Loss: 0.586513876914978\n",
      "Epoch: 1, Step: 482, Loss: 0.20694482326507568\n",
      "Epoch: 1, Step: 483, Loss: 0.5361855626106262\n",
      "Epoch: 1, Step: 484, Loss: 0.4656299352645874\n",
      "Epoch: 1, Step: 485, Loss: 0.38267233967781067\n",
      "Epoch: 1, Step: 486, Loss: 0.3965115547180176\n",
      "Epoch: 1, Step: 487, Loss: 0.5403035283088684\n",
      "Epoch: 1, Step: 488, Loss: 0.22113941609859467\n",
      "Epoch: 1, Step: 489, Loss: 0.4617370367050171\n",
      "Epoch: 1, Step: 490, Loss: 0.3068135380744934\n",
      "Epoch: 1, Step: 491, Loss: 0.24110829830169678\n",
      "Epoch: 1, Step: 492, Loss: 0.23031973838806152\n",
      "Epoch: 1, Step: 493, Loss: 0.3617262840270996\n",
      "Epoch: 1, Step: 494, Loss: 0.5931891202926636\n",
      "Epoch: 1, Step: 495, Loss: 0.5163486003875732\n",
      "Epoch: 1, Step: 496, Loss: 0.25036856532096863\n",
      "Epoch: 1, Step: 497, Loss: 0.35271790623664856\n",
      "Epoch: 1, Step: 498, Loss: 0.6932984590530396\n",
      "Epoch: 1, Step: 499, Loss: 0.219874769449234\n",
      "Epoch: 1, Step: 500, Loss: 0.38798338174819946\n",
      "Epoch: 1, Step: 501, Loss: 0.5997753143310547\n",
      "Epoch: 1, Step: 502, Loss: 0.6427419781684875\n",
      "Epoch: 1, Step: 503, Loss: 0.24577784538269043\n",
      "Epoch: 2, Step: 0, Loss: 0.47827813029289246\n",
      "Epoch: 2, Step: 1, Loss: 0.4259952902793884\n",
      "Epoch: 2, Step: 2, Loss: 0.5570103526115417\n",
      "Epoch: 2, Step: 3, Loss: 0.5742100477218628\n",
      "Epoch: 2, Step: 4, Loss: 0.35953131318092346\n",
      "Epoch: 2, Step: 5, Loss: 0.39843320846557617\n",
      "Epoch: 2, Step: 6, Loss: 0.40553733706474304\n",
      "Epoch: 2, Step: 7, Loss: 0.4132574200630188\n",
      "Epoch: 2, Step: 8, Loss: 0.31172245740890503\n",
      "Epoch: 2, Step: 9, Loss: 0.36183086037635803\n",
      "Epoch: 2, Step: 10, Loss: 0.6434701681137085\n",
      "Epoch: 2, Step: 11, Loss: 0.18500679731369019\n",
      "Epoch: 2, Step: 12, Loss: 0.2957463264465332\n",
      "Epoch: 2, Step: 13, Loss: 0.3575412631034851\n",
      "Epoch: 2, Step: 14, Loss: 0.5255402326583862\n",
      "Epoch: 2, Step: 15, Loss: 0.4630805253982544\n",
      "Epoch: 2, Step: 16, Loss: 0.40302711725234985\n",
      "Epoch: 2, Step: 17, Loss: 0.3494340777397156\n",
      "Epoch: 2, Step: 18, Loss: 0.33183062076568604\n",
      "Epoch: 2, Step: 19, Loss: 0.6014281511306763\n",
      "Epoch: 2, Step: 20, Loss: 0.2358209788799286\n",
      "Epoch: 2, Step: 21, Loss: 0.23707716166973114\n",
      "Epoch: 2, Step: 22, Loss: 0.4543570280075073\n",
      "Epoch: 2, Step: 23, Loss: 0.8030521869659424\n",
      "Epoch: 2, Step: 24, Loss: 0.29528361558914185\n",
      "Epoch: 2, Step: 25, Loss: 0.3996991217136383\n",
      "Epoch: 2, Step: 26, Loss: 0.555526852607727\n",
      "Epoch: 2, Step: 27, Loss: 0.3699202537536621\n",
      "Epoch: 2, Step: 28, Loss: 0.1582718938589096\n",
      "Epoch: 2, Step: 29, Loss: 0.2586917281150818\n",
      "Epoch: 2, Step: 30, Loss: 0.3471739888191223\n",
      "Epoch: 2, Step: 31, Loss: 0.5097777843475342\n",
      "Epoch: 2, Step: 32, Loss: 0.27264532446861267\n",
      "Epoch: 2, Step: 33, Loss: 0.41455990076065063\n",
      "Epoch: 2, Step: 34, Loss: 0.4541778564453125\n",
      "Epoch: 2, Step: 35, Loss: 0.3019143342971802\n",
      "Epoch: 2, Step: 36, Loss: 0.25760000944137573\n",
      "Epoch: 2, Step: 37, Loss: 0.299213707447052\n",
      "Epoch: 2, Step: 38, Loss: 0.31761103868484497\n",
      "Epoch: 2, Step: 39, Loss: 0.38251009583473206\n",
      "Epoch: 2, Step: 40, Loss: 0.19663402438163757\n",
      "Epoch: 2, Step: 41, Loss: 0.4586392641067505\n",
      "Epoch: 2, Step: 42, Loss: 0.4516744613647461\n",
      "Epoch: 2, Step: 43, Loss: 0.5495742559432983\n",
      "Epoch: 2, Step: 44, Loss: 0.5427378416061401\n",
      "Epoch: 2, Step: 45, Loss: 0.3955799341201782\n",
      "Epoch: 2, Step: 46, Loss: 0.29778623580932617\n",
      "Epoch: 2, Step: 47, Loss: 0.23808994889259338\n",
      "Epoch: 2, Step: 48, Loss: 0.3088579773902893\n",
      "Epoch: 2, Step: 49, Loss: 0.37683719396591187\n",
      "Epoch: 2, Step: 50, Loss: 0.20806549489498138\n",
      "Epoch: 2, Step: 51, Loss: 0.3012164235115051\n",
      "Epoch: 2, Step: 52, Loss: 0.18262749910354614\n",
      "Epoch: 2, Step: 53, Loss: 0.17393428087234497\n",
      "Epoch: 2, Step: 54, Loss: 0.22492732107639313\n",
      "Epoch: 2, Step: 55, Loss: 0.6048725843429565\n",
      "Epoch: 2, Step: 56, Loss: 0.37883269786834717\n",
      "Epoch: 2, Step: 57, Loss: 0.2015514373779297\n",
      "Epoch: 2, Step: 58, Loss: 0.32972264289855957\n",
      "Epoch: 2, Step: 59, Loss: 0.27054375410079956\n",
      "Epoch: 2, Step: 60, Loss: 0.30749696493148804\n",
      "Epoch: 2, Step: 61, Loss: 0.18608358502388\n",
      "Epoch: 2, Step: 62, Loss: 0.25285953283309937\n",
      "Epoch: 2, Step: 63, Loss: 0.4561176300048828\n",
      "Epoch: 2, Step: 64, Loss: 0.5273296236991882\n",
      "Epoch: 2, Step: 65, Loss: 0.5320227146148682\n",
      "Epoch: 2, Step: 66, Loss: 0.505030632019043\n",
      "Epoch: 2, Step: 67, Loss: 0.30547118186950684\n",
      "Epoch: 2, Step: 68, Loss: 0.5028340816497803\n",
      "Epoch: 2, Step: 69, Loss: 0.39586520195007324\n",
      "Epoch: 2, Step: 70, Loss: 0.2684931457042694\n",
      "Epoch: 2, Step: 71, Loss: 0.2406700998544693\n",
      "Epoch: 2, Step: 72, Loss: 0.19620253145694733\n",
      "Epoch: 2, Step: 73, Loss: 0.5017272233963013\n",
      "Epoch: 2, Step: 74, Loss: 0.29081887006759644\n",
      "Epoch: 2, Step: 75, Loss: 0.17774716019630432\n",
      "Epoch: 2, Step: 76, Loss: 0.322881281375885\n",
      "Epoch: 2, Step: 77, Loss: 0.5055541396141052\n",
      "Epoch: 2, Step: 78, Loss: 0.33419182896614075\n",
      "Epoch: 2, Step: 79, Loss: 0.17540419101715088\n",
      "Epoch: 2, Step: 80, Loss: 0.4790184795856476\n",
      "Epoch: 2, Step: 81, Loss: 0.2971811294555664\n",
      "Epoch: 2, Step: 82, Loss: 0.3268088400363922\n",
      "Epoch: 2, Step: 83, Loss: 0.4586532413959503\n",
      "Epoch: 2, Step: 84, Loss: 0.31721001863479614\n",
      "Epoch: 2, Step: 85, Loss: 0.318017840385437\n",
      "Epoch: 2, Step: 86, Loss: 0.1674577295780182\n",
      "Epoch: 2, Step: 87, Loss: 0.33419060707092285\n",
      "Epoch: 2, Step: 88, Loss: 0.30831125378608704\n",
      "Epoch: 2, Step: 89, Loss: 0.164820596575737\n",
      "Epoch: 2, Step: 90, Loss: 0.26189595460891724\n",
      "Epoch: 2, Step: 91, Loss: 0.22026531398296356\n",
      "Epoch: 2, Step: 92, Loss: 0.29464399814605713\n",
      "Epoch: 2, Step: 93, Loss: 0.33110249042510986\n",
      "Epoch: 2, Step: 94, Loss: 0.399183452129364\n",
      "Epoch: 2, Step: 95, Loss: 0.4520722031593323\n",
      "Epoch: 2, Step: 96, Loss: 0.31089869141578674\n",
      "Epoch: 2, Step: 97, Loss: 0.33917349576950073\n",
      "Epoch: 2, Step: 98, Loss: 0.3010393977165222\n",
      "Epoch: 2, Step: 99, Loss: 0.32700565457344055\n",
      "Epoch: 2, Step: 100, Loss: 0.6055204272270203\n",
      "Epoch: 2, Step: 101, Loss: 0.2665831446647644\n",
      "Epoch: 2, Step: 102, Loss: 0.3285101652145386\n",
      "Epoch: 2, Step: 103, Loss: 0.3782613277435303\n",
      "Epoch: 2, Step: 104, Loss: 0.2598363757133484\n",
      "Epoch: 2, Step: 105, Loss: 0.2154502272605896\n",
      "Epoch: 2, Step: 106, Loss: 0.2050173133611679\n",
      "Epoch: 2, Step: 107, Loss: 0.318398118019104\n",
      "Epoch: 2, Step: 108, Loss: 0.2738370895385742\n",
      "Epoch: 2, Step: 109, Loss: 0.27412158250808716\n",
      "Epoch: 2, Step: 110, Loss: 0.396829754114151\n",
      "Epoch: 2, Step: 111, Loss: 0.12757742404937744\n",
      "Epoch: 2, Step: 112, Loss: 0.3974723219871521\n",
      "Epoch: 2, Step: 113, Loss: 0.1647891104221344\n",
      "Epoch: 2, Step: 114, Loss: 0.27348828315734863\n",
      "Epoch: 2, Step: 115, Loss: 0.2515229284763336\n",
      "Epoch: 2, Step: 116, Loss: 0.34744030237197876\n",
      "Epoch: 2, Step: 117, Loss: 0.39835551381111145\n",
      "Epoch: 2, Step: 118, Loss: 0.20532692968845367\n",
      "Epoch: 2, Step: 119, Loss: 0.39342984557151794\n",
      "Epoch: 2, Step: 120, Loss: 0.20908048748970032\n",
      "Epoch: 2, Step: 121, Loss: 0.3675342798233032\n",
      "Epoch: 2, Step: 122, Loss: 0.225589320063591\n",
      "Epoch: 2, Step: 123, Loss: 0.25125613808631897\n",
      "Epoch: 2, Step: 124, Loss: 0.523017406463623\n",
      "Epoch: 2, Step: 125, Loss: 0.2747228145599365\n",
      "Epoch: 2, Step: 126, Loss: 0.24386796355247498\n",
      "Epoch: 2, Step: 127, Loss: 0.2367728054523468\n",
      "Epoch: 2, Step: 128, Loss: 0.3937298655509949\n",
      "Epoch: 2, Step: 129, Loss: 0.21890106797218323\n",
      "Epoch: 2, Step: 130, Loss: 0.2415662556886673\n",
      "Epoch: 2, Step: 131, Loss: 0.17227113246917725\n",
      "Epoch: 2, Step: 132, Loss: 0.15863460302352905\n",
      "Epoch: 2, Step: 133, Loss: 0.3091772198677063\n",
      "Epoch: 2, Step: 134, Loss: 0.15101681649684906\n",
      "Epoch: 2, Step: 135, Loss: 0.23662135004997253\n",
      "Epoch: 2, Step: 136, Loss: 0.3102719485759735\n",
      "Epoch: 2, Step: 137, Loss: 0.2513209879398346\n",
      "Epoch: 2, Step: 138, Loss: 0.2342539131641388\n",
      "Epoch: 2, Step: 139, Loss: 0.3708271384239197\n",
      "Epoch: 2, Step: 140, Loss: 0.20020970702171326\n",
      "Epoch: 2, Step: 141, Loss: 0.24412065744400024\n",
      "Epoch: 2, Step: 142, Loss: 0.37688007950782776\n",
      "Epoch: 2, Step: 143, Loss: 0.29029911756515503\n",
      "Epoch: 2, Step: 144, Loss: 0.2550128698348999\n",
      "Epoch: 2, Step: 145, Loss: 0.4103356599807739\n",
      "Epoch: 2, Step: 146, Loss: 0.2444888949394226\n",
      "Epoch: 2, Step: 147, Loss: 0.44567161798477173\n",
      "Epoch: 2, Step: 148, Loss: 0.3574846386909485\n",
      "Epoch: 2, Step: 149, Loss: 0.38406872749328613\n",
      "Epoch: 2, Step: 150, Loss: 0.27116742730140686\n",
      "Epoch: 2, Step: 151, Loss: 0.26162979006767273\n",
      "Epoch: 2, Step: 152, Loss: 0.12388723343610764\n",
      "Epoch: 2, Step: 153, Loss: 0.08019986748695374\n",
      "Epoch: 2, Step: 154, Loss: 0.1766166090965271\n",
      "Epoch: 2, Step: 155, Loss: 0.25621968507766724\n",
      "Epoch: 2, Step: 156, Loss: 0.22239667177200317\n",
      "Epoch: 2, Step: 157, Loss: 0.2590111196041107\n",
      "Epoch: 2, Step: 158, Loss: 0.41463276743888855\n",
      "Epoch: 2, Step: 159, Loss: 0.15155893564224243\n",
      "Epoch: 2, Step: 160, Loss: 0.19646796584129333\n",
      "Epoch: 2, Step: 161, Loss: 0.3202251195907593\n",
      "Epoch: 2, Step: 162, Loss: 0.3315558433532715\n",
      "Epoch: 2, Step: 163, Loss: 0.46497422456741333\n",
      "Epoch: 2, Step: 164, Loss: 0.19990038871765137\n",
      "Epoch: 2, Step: 165, Loss: 0.37956660985946655\n",
      "Epoch: 2, Step: 166, Loss: 0.146924689412117\n",
      "Epoch: 2, Step: 167, Loss: 0.16170579195022583\n",
      "Epoch: 2, Step: 168, Loss: 0.241645947098732\n",
      "Epoch: 2, Step: 169, Loss: 0.395341157913208\n",
      "Epoch: 2, Step: 170, Loss: 0.3576447367668152\n",
      "Epoch: 2, Step: 171, Loss: 0.28521299362182617\n",
      "Epoch: 2, Step: 172, Loss: 0.2037246823310852\n",
      "Epoch: 2, Step: 173, Loss: 0.25368648767471313\n",
      "Epoch: 2, Step: 174, Loss: 0.3273715376853943\n",
      "Epoch: 2, Step: 175, Loss: 0.14524401724338531\n",
      "Epoch: 2, Step: 176, Loss: 0.18248823285102844\n",
      "Epoch: 2, Step: 177, Loss: 0.29517263174057007\n",
      "Epoch: 2, Step: 178, Loss: 0.42209747433662415\n",
      "Epoch: 2, Step: 179, Loss: 0.4809666872024536\n",
      "Epoch: 2, Step: 180, Loss: 0.2424226701259613\n",
      "Epoch: 2, Step: 181, Loss: 0.218647301197052\n",
      "Epoch: 2, Step: 182, Loss: 0.294954776763916\n",
      "Epoch: 2, Step: 183, Loss: 0.17775197327136993\n",
      "Epoch: 2, Step: 184, Loss: 0.24546851217746735\n",
      "Epoch: 2, Step: 185, Loss: 0.45969444513320923\n",
      "Epoch: 2, Step: 186, Loss: 0.2347235232591629\n",
      "Epoch: 2, Step: 187, Loss: 0.2590102255344391\n",
      "Epoch: 2, Step: 188, Loss: 0.17634032666683197\n",
      "Epoch: 2, Step: 189, Loss: 0.22003883123397827\n",
      "Epoch: 2, Step: 190, Loss: 0.35147735476493835\n",
      "Epoch: 2, Step: 191, Loss: 0.5116246938705444\n",
      "Epoch: 2, Step: 192, Loss: 0.162562295794487\n",
      "Epoch: 2, Step: 193, Loss: 0.4191402792930603\n",
      "Epoch: 2, Step: 194, Loss: 0.17318320274353027\n",
      "Epoch: 2, Step: 195, Loss: 0.29030293226242065\n",
      "Epoch: 2, Step: 196, Loss: 0.25695621967315674\n",
      "Epoch: 2, Step: 197, Loss: 0.261383056640625\n",
      "Epoch: 2, Step: 198, Loss: 0.23113764822483063\n",
      "Epoch: 2, Step: 199, Loss: 0.374274343252182\n",
      "Epoch: 2, Step: 200, Loss: 0.2088693231344223\n",
      "Epoch: 2, Step: 201, Loss: 0.22999711334705353\n",
      "Epoch: 2, Step: 202, Loss: 0.3091506063938141\n",
      "Epoch: 2, Step: 203, Loss: 0.13426731526851654\n",
      "Epoch: 2, Step: 204, Loss: 0.2629773020744324\n",
      "Epoch: 2, Step: 205, Loss: 0.1644686758518219\n",
      "Epoch: 2, Step: 206, Loss: 0.5473988056182861\n",
      "Epoch: 2, Step: 207, Loss: 0.1326557993888855\n",
      "Epoch: 2, Step: 208, Loss: 0.3223341107368469\n",
      "Epoch: 2, Step: 209, Loss: 0.3165552020072937\n",
      "Epoch: 2, Step: 210, Loss: 0.2114448845386505\n",
      "Epoch: 2, Step: 211, Loss: 0.1587434709072113\n",
      "Epoch: 2, Step: 212, Loss: 0.36186766624450684\n",
      "Epoch: 2, Step: 213, Loss: 0.26178932189941406\n",
      "Epoch: 2, Step: 214, Loss: 0.08604034036397934\n",
      "Epoch: 2, Step: 215, Loss: 0.3448077440261841\n",
      "Epoch: 2, Step: 216, Loss: 0.2598024606704712\n",
      "Epoch: 2, Step: 217, Loss: 0.19332613050937653\n",
      "Epoch: 2, Step: 218, Loss: 0.21994400024414062\n",
      "Epoch: 2, Step: 219, Loss: 0.5142965316772461\n",
      "Epoch: 2, Step: 220, Loss: 0.20456422865390778\n",
      "Epoch: 2, Step: 221, Loss: 0.43719208240509033\n",
      "Epoch: 2, Step: 222, Loss: 0.2594134509563446\n",
      "Epoch: 2, Step: 223, Loss: 0.19467829167842865\n",
      "Epoch: 2, Step: 224, Loss: 0.34686288237571716\n",
      "Epoch: 2, Step: 225, Loss: 0.23842446506023407\n",
      "Epoch: 2, Step: 226, Loss: 0.2995113432407379\n",
      "Epoch: 2, Step: 227, Loss: 0.26249435544013977\n",
      "Epoch: 2, Step: 228, Loss: 0.22279705107212067\n",
      "Epoch: 2, Step: 229, Loss: 0.20121899247169495\n",
      "Epoch: 2, Step: 230, Loss: 0.3621184825897217\n",
      "Epoch: 2, Step: 231, Loss: 0.2490570992231369\n",
      "Epoch: 2, Step: 232, Loss: 0.4463764429092407\n",
      "Epoch: 2, Step: 233, Loss: 0.2672617435455322\n",
      "Epoch: 2, Step: 234, Loss: 0.25973567366600037\n",
      "Epoch: 2, Step: 235, Loss: 0.3054591715335846\n",
      "Epoch: 2, Step: 236, Loss: 0.290166437625885\n",
      "Epoch: 2, Step: 237, Loss: 0.3888961374759674\n",
      "Epoch: 2, Step: 238, Loss: 0.24821992218494415\n",
      "Epoch: 2, Step: 239, Loss: 0.2866608202457428\n",
      "Epoch: 2, Step: 240, Loss: 0.1892547756433487\n",
      "Epoch: 2, Step: 241, Loss: 0.23437172174453735\n",
      "Epoch: 2, Step: 242, Loss: 0.2801632881164551\n",
      "Epoch: 2, Step: 243, Loss: 0.32866036891937256\n",
      "Epoch: 2, Step: 244, Loss: 0.2650492787361145\n",
      "Epoch: 2, Step: 245, Loss: 0.4140505790710449\n",
      "Epoch: 2, Step: 246, Loss: 0.17177504301071167\n",
      "Epoch: 2, Step: 247, Loss: 0.3420533835887909\n",
      "Epoch: 2, Step: 248, Loss: 0.3774273991584778\n",
      "Epoch: 2, Step: 249, Loss: 0.1694483757019043\n",
      "Epoch: 2, Step: 250, Loss: 0.45172548294067383\n",
      "Epoch: 2, Step: 251, Loss: 0.13653847575187683\n",
      "Epoch: 2, Step: 252, Loss: 0.29691606760025024\n",
      "Epoch: 2, Step: 253, Loss: 0.18050292134284973\n",
      "Epoch: 2, Step: 254, Loss: 0.16405843198299408\n",
      "Epoch: 2, Step: 255, Loss: 0.17837586998939514\n",
      "Epoch: 2, Step: 256, Loss: 0.23648926615715027\n",
      "Epoch: 2, Step: 257, Loss: 0.20358094573020935\n",
      "Epoch: 2, Step: 258, Loss: 0.10101846605539322\n",
      "Epoch: 2, Step: 259, Loss: 0.3178222179412842\n",
      "Epoch: 2, Step: 260, Loss: 0.2324838638305664\n",
      "Epoch: 2, Step: 261, Loss: 0.29817771911621094\n",
      "Epoch: 2, Step: 262, Loss: 0.1910453736782074\n",
      "Epoch: 2, Step: 263, Loss: 0.25706544518470764\n",
      "Epoch: 2, Step: 264, Loss: 0.2939194440841675\n",
      "Epoch: 2, Step: 265, Loss: 0.7390679717063904\n",
      "Epoch: 2, Step: 266, Loss: 0.30222323536872864\n",
      "Epoch: 2, Step: 267, Loss: 0.11350800096988678\n",
      "Epoch: 2, Step: 268, Loss: 0.21088777482509613\n",
      "Epoch: 2, Step: 269, Loss: 0.18062840402126312\n",
      "Epoch: 2, Step: 270, Loss: 0.2034795731306076\n",
      "Epoch: 2, Step: 271, Loss: 0.33692291378974915\n",
      "Epoch: 2, Step: 272, Loss: 0.35797739028930664\n",
      "Epoch: 2, Step: 273, Loss: 0.18572311103343964\n",
      "Epoch: 2, Step: 274, Loss: 0.22710824012756348\n",
      "Epoch: 2, Step: 275, Loss: 0.22378984093666077\n",
      "Epoch: 2, Step: 276, Loss: 0.39787766337394714\n",
      "Epoch: 2, Step: 277, Loss: 0.17902997136116028\n",
      "Epoch: 2, Step: 278, Loss: 0.30815452337265015\n",
      "Epoch: 2, Step: 279, Loss: 0.42095378041267395\n",
      "Epoch: 2, Step: 280, Loss: 0.3799486756324768\n",
      "Epoch: 2, Step: 281, Loss: 0.3660126328468323\n",
      "Epoch: 2, Step: 282, Loss: 0.1578141748905182\n",
      "Epoch: 2, Step: 283, Loss: 0.348705917596817\n",
      "Epoch: 2, Step: 284, Loss: 0.18846452236175537\n",
      "Epoch: 2, Step: 285, Loss: 0.27434948086738586\n",
      "Epoch: 2, Step: 286, Loss: 0.3117945194244385\n",
      "Epoch: 2, Step: 287, Loss: 0.2706848382949829\n",
      "Epoch: 2, Step: 288, Loss: 0.2153756320476532\n",
      "Epoch: 2, Step: 289, Loss: 0.2064308375120163\n",
      "Epoch: 2, Step: 290, Loss: 0.22935892641544342\n",
      "Epoch: 2, Step: 291, Loss: 0.44321611523628235\n",
      "Epoch: 2, Step: 292, Loss: 0.23523616790771484\n",
      "Epoch: 2, Step: 293, Loss: 0.24945057928562164\n",
      "Epoch: 2, Step: 294, Loss: 0.17617011070251465\n",
      "Epoch: 2, Step: 295, Loss: 0.299888551235199\n",
      "Epoch: 2, Step: 296, Loss: 0.09226203709840775\n",
      "Epoch: 2, Step: 297, Loss: 0.24907511472702026\n",
      "Epoch: 2, Step: 298, Loss: 0.17664995789527893\n",
      "Epoch: 2, Step: 299, Loss: 0.27568602561950684\n",
      "Epoch: 2, Step: 300, Loss: 0.2736581265926361\n",
      "Epoch: 2, Step: 301, Loss: 0.23671084642410278\n",
      "Epoch: 2, Step: 302, Loss: 0.3023907542228699\n",
      "Epoch: 2, Step: 303, Loss: 0.15013188123703003\n",
      "Epoch: 2, Step: 304, Loss: 0.3170931935310364\n",
      "Epoch: 2, Step: 305, Loss: 0.2442050278186798\n",
      "Epoch: 2, Step: 306, Loss: 0.5045833587646484\n",
      "Epoch: 2, Step: 307, Loss: 0.19196492433547974\n",
      "Epoch: 2, Step: 308, Loss: 0.20135453343391418\n",
      "Epoch: 2, Step: 309, Loss: 0.271651029586792\n",
      "Epoch: 2, Step: 310, Loss: 0.29512253403663635\n",
      "Epoch: 2, Step: 311, Loss: 0.3028501868247986\n",
      "Epoch: 2, Step: 312, Loss: 0.3211182951927185\n",
      "Epoch: 2, Step: 313, Loss: 0.18885448575019836\n",
      "Epoch: 2, Step: 314, Loss: 0.1981024444103241\n",
      "Epoch: 2, Step: 315, Loss: 0.2245483547449112\n",
      "Epoch: 2, Step: 316, Loss: 0.2889006733894348\n",
      "Epoch: 2, Step: 317, Loss: 0.1886850744485855\n",
      "Epoch: 2, Step: 318, Loss: 0.19156122207641602\n",
      "Epoch: 2, Step: 319, Loss: 0.19005835056304932\n",
      "Epoch: 2, Step: 320, Loss: 0.2817930579185486\n",
      "Epoch: 2, Step: 321, Loss: 0.17698770761489868\n",
      "Epoch: 2, Step: 322, Loss: 0.20036599040031433\n",
      "Epoch: 2, Step: 323, Loss: 0.25472357869148254\n",
      "Epoch: 2, Step: 324, Loss: 0.22941158711910248\n",
      "Epoch: 2, Step: 325, Loss: 0.14849413931369781\n",
      "Epoch: 2, Step: 326, Loss: 0.28081971406936646\n",
      "Epoch: 2, Step: 327, Loss: 0.23181232810020447\n",
      "Epoch: 2, Step: 328, Loss: 0.07324172556400299\n",
      "Epoch: 2, Step: 329, Loss: 0.14368626475334167\n",
      "Epoch: 2, Step: 330, Loss: 0.1680515706539154\n",
      "Epoch: 2, Step: 331, Loss: 0.4005957245826721\n",
      "Epoch: 2, Step: 332, Loss: 0.29150381684303284\n",
      "Epoch: 2, Step: 333, Loss: 0.29198306798934937\n",
      "Epoch: 2, Step: 334, Loss: 0.4732457995414734\n",
      "Epoch: 2, Step: 335, Loss: 0.1646382063627243\n",
      "Epoch: 2, Step: 336, Loss: 0.21651718020439148\n",
      "Epoch: 2, Step: 337, Loss: 0.2643594741821289\n",
      "Epoch: 2, Step: 338, Loss: 0.2565126419067383\n",
      "Epoch: 2, Step: 339, Loss: 0.3035011291503906\n",
      "Epoch: 2, Step: 340, Loss: 0.29185187816619873\n",
      "Epoch: 2, Step: 341, Loss: 0.28274327516555786\n",
      "Epoch: 2, Step: 342, Loss: 0.2732735276222229\n",
      "Epoch: 2, Step: 343, Loss: 0.2882657051086426\n",
      "Epoch: 2, Step: 344, Loss: 0.30225545167922974\n",
      "Epoch: 2, Step: 345, Loss: 0.4729492962360382\n",
      "Epoch: 2, Step: 346, Loss: 0.38835692405700684\n",
      "Epoch: 2, Step: 347, Loss: 0.1315327286720276\n",
      "Epoch: 2, Step: 348, Loss: 0.20726436376571655\n",
      "Epoch: 2, Step: 349, Loss: 0.15112589299678802\n",
      "Epoch: 2, Step: 350, Loss: 0.1480293869972229\n",
      "Epoch: 2, Step: 351, Loss: 0.12448558211326599\n",
      "Epoch: 2, Step: 352, Loss: 0.2524792551994324\n",
      "Epoch: 2, Step: 353, Loss: 0.1562381088733673\n",
      "Epoch: 2, Step: 354, Loss: 0.10434914380311966\n",
      "Epoch: 2, Step: 355, Loss: 0.17067067325115204\n",
      "Epoch: 2, Step: 356, Loss: 0.23988084495067596\n",
      "Epoch: 2, Step: 357, Loss: 0.34131455421447754\n",
      "Epoch: 2, Step: 358, Loss: 0.25047406554222107\n",
      "Epoch: 2, Step: 359, Loss: 0.2538323402404785\n",
      "Epoch: 2, Step: 360, Loss: 0.3316570520401001\n",
      "Epoch: 2, Step: 361, Loss: 0.1824285387992859\n",
      "Epoch: 2, Step: 362, Loss: 0.15888285636901855\n",
      "Epoch: 2, Step: 363, Loss: 0.40037333965301514\n",
      "Epoch: 2, Step: 364, Loss: 0.2368321418762207\n",
      "Epoch: 2, Step: 365, Loss: 0.18098163604736328\n",
      "Epoch: 2, Step: 366, Loss: 0.3992483615875244\n",
      "Epoch: 2, Step: 367, Loss: 0.11823577433824539\n",
      "Epoch: 2, Step: 368, Loss: 0.412546843290329\n",
      "Epoch: 2, Step: 369, Loss: 0.2170545607805252\n",
      "Epoch: 2, Step: 370, Loss: 0.2791990041732788\n",
      "Epoch: 2, Step: 371, Loss: 0.24859210848808289\n",
      "Epoch: 2, Step: 372, Loss: 0.17288553714752197\n",
      "Epoch: 2, Step: 373, Loss: 0.13239282369613647\n",
      "Epoch: 2, Step: 374, Loss: 0.22264017164707184\n",
      "Epoch: 2, Step: 375, Loss: 0.17711110413074493\n",
      "Epoch: 2, Step: 376, Loss: 0.20775359869003296\n",
      "Epoch: 2, Step: 377, Loss: 0.1639145016670227\n",
      "Epoch: 2, Step: 378, Loss: 0.2091304510831833\n",
      "Epoch: 2, Step: 379, Loss: 0.41926509141921997\n",
      "Epoch: 2, Step: 380, Loss: 0.10344180464744568\n",
      "Epoch: 2, Step: 381, Loss: 0.18661805987358093\n",
      "Epoch: 2, Step: 382, Loss: 0.33977076411247253\n",
      "Epoch: 2, Step: 383, Loss: 0.3613959550857544\n",
      "Epoch: 2, Step: 384, Loss: 0.22227579355239868\n",
      "Epoch: 2, Step: 385, Loss: 0.3340803384780884\n",
      "Epoch: 2, Step: 386, Loss: 0.4267059564590454\n",
      "Epoch: 2, Step: 387, Loss: 0.10520310699939728\n",
      "Epoch: 2, Step: 388, Loss: 0.14742040634155273\n",
      "Epoch: 2, Step: 389, Loss: 0.24593529105186462\n",
      "Epoch: 2, Step: 390, Loss: 0.3409489691257477\n",
      "Epoch: 2, Step: 391, Loss: 0.3001439571380615\n",
      "Epoch: 2, Step: 392, Loss: 0.2611948549747467\n",
      "Epoch: 2, Step: 393, Loss: 0.14591190218925476\n",
      "Epoch: 2, Step: 394, Loss: 0.10102330893278122\n",
      "Epoch: 2, Step: 395, Loss: 0.33794400095939636\n",
      "Epoch: 2, Step: 396, Loss: 0.47127676010131836\n",
      "Epoch: 2, Step: 397, Loss: 0.1721099317073822\n",
      "Epoch: 2, Step: 398, Loss: 0.2047693133354187\n",
      "Epoch: 2, Step: 399, Loss: 0.21356934309005737\n",
      "Epoch: 2, Step: 400, Loss: 0.1983063519001007\n",
      "Epoch: 2, Step: 401, Loss: 0.22397774457931519\n",
      "Epoch: 2, Step: 402, Loss: 0.0807902067899704\n",
      "Epoch: 2, Step: 403, Loss: 0.14875638484954834\n",
      "Epoch: 2, Step: 404, Loss: 0.25472813844680786\n",
      "Epoch: 2, Step: 405, Loss: 0.17669586837291718\n",
      "Epoch: 2, Step: 406, Loss: 0.1381005346775055\n",
      "Epoch: 2, Step: 407, Loss: 0.25482189655303955\n",
      "Epoch: 2, Step: 408, Loss: 0.32300662994384766\n",
      "Epoch: 2, Step: 409, Loss: 0.18083414435386658\n",
      "Epoch: 2, Step: 410, Loss: 0.19067928194999695\n",
      "Epoch: 2, Step: 411, Loss: 0.17632520198822021\n",
      "Epoch: 2, Step: 412, Loss: 0.14561893045902252\n",
      "Epoch: 2, Step: 413, Loss: 0.16291846334934235\n",
      "Epoch: 2, Step: 414, Loss: 0.3658856749534607\n",
      "Epoch: 2, Step: 415, Loss: 0.30772486329078674\n",
      "Epoch: 2, Step: 416, Loss: 0.17773646116256714\n",
      "Epoch: 2, Step: 417, Loss: 0.25586241483688354\n",
      "Epoch: 2, Step: 418, Loss: 0.15419407188892365\n",
      "Epoch: 2, Step: 419, Loss: 0.21972741186618805\n",
      "Epoch: 2, Step: 420, Loss: 0.4185791015625\n",
      "Epoch: 2, Step: 421, Loss: 0.32536381483078003\n",
      "Epoch: 2, Step: 422, Loss: 0.14760079979896545\n",
      "Epoch: 2, Step: 423, Loss: 0.29904791712760925\n",
      "Epoch: 2, Step: 424, Loss: 0.2741631865501404\n",
      "Epoch: 2, Step: 425, Loss: 0.4282921552658081\n",
      "Epoch: 2, Step: 426, Loss: 0.1990567296743393\n",
      "Epoch: 2, Step: 427, Loss: 0.3022489547729492\n",
      "Epoch: 2, Step: 428, Loss: 0.15082398056983948\n",
      "Epoch: 2, Step: 429, Loss: 0.15450802445411682\n",
      "Epoch: 2, Step: 430, Loss: 0.25382107496261597\n",
      "Epoch: 2, Step: 431, Loss: 0.16657641530036926\n",
      "Epoch: 2, Step: 432, Loss: 0.22682486474514008\n",
      "Epoch: 2, Step: 433, Loss: 0.22479696571826935\n",
      "Epoch: 2, Step: 434, Loss: 0.17953793704509735\n",
      "Epoch: 2, Step: 435, Loss: 0.17358705401420593\n",
      "Epoch: 2, Step: 436, Loss: 0.27620917558670044\n",
      "Epoch: 2, Step: 437, Loss: 0.1834126114845276\n",
      "Epoch: 2, Step: 438, Loss: 0.20909512042999268\n",
      "Epoch: 2, Step: 439, Loss: 0.2623077630996704\n",
      "Epoch: 2, Step: 440, Loss: 0.20515422523021698\n",
      "Epoch: 2, Step: 441, Loss: 0.17790499329566956\n",
      "Epoch: 2, Step: 442, Loss: 0.16276666522026062\n",
      "Epoch: 2, Step: 443, Loss: 0.22736239433288574\n",
      "Epoch: 2, Step: 444, Loss: 0.16701367497444153\n",
      "Epoch: 2, Step: 445, Loss: 0.17633455991744995\n",
      "Epoch: 2, Step: 446, Loss: 0.2887367606163025\n",
      "Epoch: 2, Step: 447, Loss: 0.11037729680538177\n",
      "Epoch: 2, Step: 448, Loss: 0.32226675748825073\n",
      "Epoch: 2, Step: 449, Loss: 0.1601744294166565\n",
      "Epoch: 2, Step: 450, Loss: 0.29835814237594604\n",
      "Epoch: 2, Step: 451, Loss: 0.30016475915908813\n",
      "Epoch: 2, Step: 452, Loss: 0.22462144494056702\n",
      "Epoch: 2, Step: 453, Loss: 0.2055388242006302\n",
      "Epoch: 2, Step: 454, Loss: 0.18538036942481995\n",
      "Epoch: 2, Step: 455, Loss: 0.1429755538702011\n",
      "Epoch: 2, Step: 456, Loss: 0.24804654717445374\n",
      "Epoch: 2, Step: 457, Loss: 0.12257426232099533\n",
      "Epoch: 2, Step: 458, Loss: 0.09358087182044983\n",
      "Epoch: 2, Step: 459, Loss: 0.21628552675247192\n",
      "Epoch: 2, Step: 460, Loss: 0.24657991528511047\n",
      "Epoch: 2, Step: 461, Loss: 0.2634131610393524\n",
      "Epoch: 2, Step: 462, Loss: 0.08834836632013321\n",
      "Epoch: 2, Step: 463, Loss: 0.18562954664230347\n",
      "Epoch: 2, Step: 464, Loss: 0.16114985942840576\n",
      "Epoch: 2, Step: 465, Loss: 0.2871820330619812\n",
      "Epoch: 2, Step: 466, Loss: 0.1998264193534851\n",
      "Epoch: 2, Step: 467, Loss: 0.12541095912456512\n",
      "Epoch: 2, Step: 468, Loss: 0.1851748526096344\n",
      "Epoch: 2, Step: 469, Loss: 0.12368621677160263\n",
      "Epoch: 2, Step: 470, Loss: 0.12455324828624725\n",
      "Epoch: 2, Step: 471, Loss: 0.11766353994607925\n",
      "Epoch: 2, Step: 472, Loss: 0.12489458918571472\n",
      "Epoch: 2, Step: 473, Loss: 0.19846254587173462\n",
      "Epoch: 2, Step: 474, Loss: 0.30942416191101074\n",
      "Epoch: 2, Step: 475, Loss: 0.14200477302074432\n",
      "Epoch: 2, Step: 476, Loss: 0.18700477480888367\n",
      "Epoch: 2, Step: 477, Loss: 0.26023364067077637\n",
      "Epoch: 2, Step: 478, Loss: 0.24362298846244812\n",
      "Epoch: 2, Step: 479, Loss: 0.20065468549728394\n",
      "Epoch: 2, Step: 480, Loss: 0.22295808792114258\n",
      "Epoch: 2, Step: 481, Loss: 0.33638566732406616\n",
      "Epoch: 2, Step: 482, Loss: 0.2924949526786804\n",
      "Epoch: 2, Step: 483, Loss: 0.2047003209590912\n",
      "Epoch: 2, Step: 484, Loss: 0.1466573178768158\n",
      "Epoch: 2, Step: 485, Loss: 0.13861407339572906\n",
      "Epoch: 2, Step: 486, Loss: 0.3350948691368103\n",
      "Epoch: 2, Step: 487, Loss: 0.2560691237449646\n",
      "Epoch: 2, Step: 488, Loss: 0.15177568793296814\n",
      "Epoch: 2, Step: 489, Loss: 0.1576957106590271\n",
      "Epoch: 2, Step: 490, Loss: 0.1563563048839569\n",
      "Epoch: 2, Step: 491, Loss: 0.1696147322654724\n",
      "Epoch: 2, Step: 492, Loss: 0.12365896999835968\n",
      "Epoch: 2, Step: 493, Loss: 0.18644416332244873\n",
      "Epoch: 2, Step: 494, Loss: 0.17983470857143402\n",
      "Epoch: 2, Step: 495, Loss: 0.1261385828256607\n",
      "Epoch: 2, Step: 496, Loss: 0.35239624977111816\n",
      "Epoch: 2, Step: 497, Loss: 0.3817605674266815\n",
      "Epoch: 2, Step: 498, Loss: 0.10768409073352814\n",
      "Epoch: 2, Step: 499, Loss: 0.256890207529068\n",
      "Epoch: 2, Step: 500, Loss: 0.0825130045413971\n",
      "Epoch: 2, Step: 501, Loss: 0.2066194862127304\n",
      "Epoch: 2, Step: 502, Loss: 0.3509410321712494\n",
      "Epoch: 2, Step: 503, Loss: 0.4255501627922058\n",
      "Epoch: 3, Step: 0, Loss: 0.16279056668281555\n",
      "Epoch: 3, Step: 1, Loss: 0.1431407779455185\n",
      "Epoch: 3, Step: 2, Loss: 0.21773257851600647\n",
      "Epoch: 3, Step: 3, Loss: 0.09996338933706284\n",
      "Epoch: 3, Step: 4, Loss: 0.23808547854423523\n",
      "Epoch: 3, Step: 5, Loss: 0.24751238524913788\n",
      "Epoch: 3, Step: 6, Loss: 0.12030833959579468\n",
      "Epoch: 3, Step: 7, Loss: 0.24493372440338135\n",
      "Epoch: 3, Step: 8, Loss: 0.15721629559993744\n",
      "Epoch: 3, Step: 9, Loss: 0.26698094606399536\n",
      "Epoch: 3, Step: 10, Loss: 0.23401984572410583\n",
      "Epoch: 3, Step: 11, Loss: 0.12063610553741455\n",
      "Epoch: 3, Step: 12, Loss: 0.12226320803165436\n",
      "Epoch: 3, Step: 13, Loss: 0.42938682436943054\n",
      "Epoch: 3, Step: 14, Loss: 0.2822972238063812\n",
      "Epoch: 3, Step: 15, Loss: 0.11670876294374466\n",
      "Epoch: 3, Step: 16, Loss: 0.21221107244491577\n",
      "Epoch: 3, Step: 17, Loss: 0.06365160644054413\n",
      "Epoch: 3, Step: 18, Loss: 0.16538681089878082\n",
      "Epoch: 3, Step: 19, Loss: 0.1295323371887207\n",
      "Epoch: 3, Step: 20, Loss: 0.28032684326171875\n",
      "Epoch: 3, Step: 21, Loss: 0.13611793518066406\n",
      "Epoch: 3, Step: 22, Loss: 0.18611299991607666\n",
      "Epoch: 3, Step: 23, Loss: 0.2517959773540497\n",
      "Epoch: 3, Step: 24, Loss: 0.2741708755493164\n",
      "Epoch: 3, Step: 25, Loss: 0.3004547655582428\n",
      "Epoch: 3, Step: 26, Loss: 0.20219987630844116\n",
      "Epoch: 3, Step: 27, Loss: 0.14103193581104279\n",
      "Epoch: 3, Step: 28, Loss: 0.1226394847035408\n",
      "Epoch: 3, Step: 29, Loss: 0.15792828798294067\n",
      "Epoch: 3, Step: 30, Loss: 0.12113107740879059\n",
      "Epoch: 3, Step: 31, Loss: 0.15834344923496246\n",
      "Epoch: 3, Step: 32, Loss: 0.07661570608615875\n",
      "Epoch: 3, Step: 33, Loss: 0.21531230211257935\n",
      "Epoch: 3, Step: 34, Loss: 0.33076876401901245\n",
      "Epoch: 3, Step: 35, Loss: 0.12914513051509857\n",
      "Epoch: 3, Step: 36, Loss: 0.1335456222295761\n",
      "Epoch: 3, Step: 37, Loss: 0.10780850052833557\n",
      "Epoch: 3, Step: 38, Loss: 0.12482565641403198\n",
      "Epoch: 3, Step: 39, Loss: 0.22504492104053497\n",
      "Epoch: 3, Step: 40, Loss: 0.12880754470825195\n",
      "Epoch: 3, Step: 41, Loss: 0.15130695700645447\n",
      "Epoch: 3, Step: 42, Loss: 0.28254565596580505\n",
      "Epoch: 3, Step: 43, Loss: 0.10458564758300781\n",
      "Epoch: 3, Step: 44, Loss: 0.1833253651857376\n",
      "Epoch: 3, Step: 45, Loss: 0.16384373605251312\n",
      "Epoch: 3, Step: 46, Loss: 0.3091195523738861\n",
      "Epoch: 3, Step: 47, Loss: 0.06008221209049225\n",
      "Epoch: 3, Step: 48, Loss: 0.09857800602912903\n",
      "Epoch: 3, Step: 49, Loss: 0.10424818098545074\n",
      "Epoch: 3, Step: 50, Loss: 0.2012072503566742\n",
      "Epoch: 3, Step: 51, Loss: 0.14540955424308777\n",
      "Epoch: 3, Step: 52, Loss: 0.09620413929224014\n",
      "Epoch: 3, Step: 53, Loss: 0.2579820156097412\n",
      "Epoch: 3, Step: 54, Loss: 0.1225837841629982\n",
      "Epoch: 3, Step: 55, Loss: 0.24561016261577606\n",
      "Epoch: 3, Step: 56, Loss: 0.36156511306762695\n",
      "Epoch: 3, Step: 57, Loss: 0.17625239491462708\n",
      "Epoch: 3, Step: 58, Loss: 0.17740878462791443\n",
      "Epoch: 3, Step: 59, Loss: 0.243840754032135\n",
      "Epoch: 3, Step: 60, Loss: 0.1668437421321869\n",
      "Epoch: 3, Step: 61, Loss: 0.09463343024253845\n",
      "Epoch: 3, Step: 62, Loss: 0.13276192545890808\n",
      "Epoch: 3, Step: 63, Loss: 0.2610987424850464\n",
      "Epoch: 3, Step: 64, Loss: 0.06909704208374023\n",
      "Epoch: 3, Step: 65, Loss: 0.06437443196773529\n",
      "Epoch: 3, Step: 66, Loss: 0.27806147933006287\n",
      "Epoch: 3, Step: 67, Loss: 0.12526670098304749\n",
      "Epoch: 3, Step: 68, Loss: 0.25047218799591064\n",
      "Epoch: 3, Step: 69, Loss: 0.2219850718975067\n",
      "Epoch: 3, Step: 70, Loss: 0.1670142412185669\n",
      "Epoch: 3, Step: 71, Loss: 0.2367939054965973\n",
      "Epoch: 3, Step: 72, Loss: 0.1187523901462555\n",
      "Epoch: 3, Step: 73, Loss: 0.044718630611896515\n",
      "Epoch: 3, Step: 74, Loss: 0.21347372233867645\n",
      "Epoch: 3, Step: 75, Loss: 0.2321663200855255\n",
      "Epoch: 3, Step: 76, Loss: 0.1737254559993744\n",
      "Epoch: 3, Step: 77, Loss: 0.11177296936511993\n",
      "Epoch: 3, Step: 78, Loss: 0.21303550899028778\n",
      "Epoch: 3, Step: 79, Loss: 0.08857846260070801\n",
      "Epoch: 3, Step: 80, Loss: 0.15832239389419556\n",
      "Epoch: 3, Step: 81, Loss: 0.13803139328956604\n",
      "Epoch: 3, Step: 82, Loss: 0.13618525862693787\n",
      "Epoch: 3, Step: 83, Loss: 0.08982042968273163\n",
      "Epoch: 3, Step: 84, Loss: 0.11795917898416519\n",
      "Epoch: 3, Step: 85, Loss: 0.21286307275295258\n",
      "Epoch: 3, Step: 86, Loss: 0.14400699734687805\n",
      "Epoch: 3, Step: 87, Loss: 0.08418212085962296\n",
      "Epoch: 3, Step: 88, Loss: 0.07684821635484695\n",
      "Epoch: 3, Step: 89, Loss: 0.292582631111145\n",
      "Epoch: 3, Step: 90, Loss: 0.10892817378044128\n",
      "Epoch: 3, Step: 91, Loss: 0.0494319424033165\n",
      "Epoch: 3, Step: 92, Loss: 0.11346933990716934\n",
      "Epoch: 3, Step: 93, Loss: 0.3525010943412781\n",
      "Epoch: 3, Step: 94, Loss: 0.1705576777458191\n",
      "Epoch: 3, Step: 95, Loss: 0.1784859299659729\n",
      "Epoch: 3, Step: 96, Loss: 0.25288867950439453\n",
      "Epoch: 3, Step: 97, Loss: 0.13417702913284302\n",
      "Epoch: 3, Step: 98, Loss: 0.16976070404052734\n",
      "Epoch: 3, Step: 99, Loss: 0.11213836818933487\n",
      "Epoch: 3, Step: 100, Loss: 0.14664286375045776\n",
      "Epoch: 3, Step: 101, Loss: 0.12387382239103317\n",
      "Epoch: 3, Step: 102, Loss: 0.13475564122200012\n",
      "Epoch: 3, Step: 103, Loss: 0.1474914848804474\n",
      "Epoch: 3, Step: 104, Loss: 0.19814306497573853\n",
      "Epoch: 3, Step: 105, Loss: 0.08538267016410828\n",
      "Epoch: 3, Step: 106, Loss: 0.2243110090494156\n",
      "Epoch: 3, Step: 107, Loss: 0.08288046717643738\n",
      "Epoch: 3, Step: 108, Loss: 0.3374108672142029\n",
      "Epoch: 3, Step: 109, Loss: 0.18729618191719055\n",
      "Epoch: 3, Step: 110, Loss: 0.14051613211631775\n",
      "Epoch: 3, Step: 111, Loss: 0.22177016735076904\n",
      "Epoch: 3, Step: 112, Loss: 0.20587526261806488\n",
      "Epoch: 3, Step: 113, Loss: 0.17559823393821716\n",
      "Epoch: 3, Step: 114, Loss: 0.07176635414361954\n",
      "Epoch: 3, Step: 115, Loss: 0.20392227172851562\n",
      "Epoch: 3, Step: 116, Loss: 0.11553453654050827\n",
      "Epoch: 3, Step: 117, Loss: 0.24194103479385376\n",
      "Epoch: 3, Step: 118, Loss: 0.2199779450893402\n",
      "Epoch: 3, Step: 119, Loss: 0.11521880328655243\n",
      "Epoch: 3, Step: 120, Loss: 0.3007318377494812\n",
      "Epoch: 3, Step: 121, Loss: 0.19299665093421936\n",
      "Epoch: 3, Step: 122, Loss: 0.07101046293973923\n",
      "Epoch: 3, Step: 123, Loss: 0.24094834923744202\n",
      "Epoch: 3, Step: 124, Loss: 0.2790634036064148\n",
      "Epoch: 3, Step: 125, Loss: 0.12778696417808533\n",
      "Epoch: 3, Step: 126, Loss: 0.120216503739357\n",
      "Epoch: 3, Step: 127, Loss: 0.3037932813167572\n",
      "Epoch: 3, Step: 128, Loss: 0.19944673776626587\n",
      "Epoch: 3, Step: 129, Loss: 0.23501314222812653\n",
      "Epoch: 3, Step: 130, Loss: 0.11420018970966339\n",
      "Epoch: 3, Step: 131, Loss: 0.20991283655166626\n",
      "Epoch: 3, Step: 132, Loss: 0.15319140255451202\n",
      "Epoch: 3, Step: 133, Loss: 0.14368978142738342\n",
      "Epoch: 3, Step: 134, Loss: 0.16012760996818542\n",
      "Epoch: 3, Step: 135, Loss: 0.23343996703624725\n",
      "Epoch: 3, Step: 136, Loss: 0.12380030751228333\n",
      "Epoch: 3, Step: 137, Loss: 0.31227725744247437\n",
      "Epoch: 3, Step: 138, Loss: 0.2620197832584381\n",
      "Epoch: 3, Step: 139, Loss: 0.11032496392726898\n",
      "Epoch: 3, Step: 140, Loss: 0.13249269127845764\n",
      "Epoch: 3, Step: 141, Loss: 0.15880340337753296\n",
      "Epoch: 3, Step: 142, Loss: 0.10174744576215744\n",
      "Epoch: 3, Step: 143, Loss: 0.1850753128528595\n",
      "Epoch: 3, Step: 144, Loss: 0.25642094016075134\n",
      "Epoch: 3, Step: 145, Loss: 0.44279593229293823\n",
      "Epoch: 3, Step: 146, Loss: 0.09875796735286713\n",
      "Epoch: 3, Step: 147, Loss: 0.12404455244541168\n",
      "Epoch: 3, Step: 148, Loss: 0.07693307101726532\n",
      "Epoch: 3, Step: 149, Loss: 0.12707942724227905\n",
      "Epoch: 3, Step: 150, Loss: 0.10139773786067963\n",
      "Epoch: 3, Step: 151, Loss: 0.1997743844985962\n",
      "Epoch: 3, Step: 152, Loss: 0.20309767127037048\n",
      "Epoch: 3, Step: 153, Loss: 0.07759075611829758\n",
      "Epoch: 3, Step: 154, Loss: 0.11755339801311493\n",
      "Epoch: 3, Step: 155, Loss: 0.21200861036777496\n",
      "Epoch: 3, Step: 156, Loss: 0.13403311371803284\n",
      "Epoch: 3, Step: 157, Loss: 0.09484389424324036\n",
      "Epoch: 3, Step: 158, Loss: 0.20296232402324677\n",
      "Epoch: 3, Step: 159, Loss: 0.16916966438293457\n",
      "Epoch: 3, Step: 160, Loss: 0.09677407145500183\n",
      "Epoch: 3, Step: 161, Loss: 0.28971585631370544\n",
      "Epoch: 3, Step: 162, Loss: 0.17049279808998108\n",
      "Epoch: 3, Step: 163, Loss: 0.14927023649215698\n",
      "Epoch: 3, Step: 164, Loss: 0.272769033908844\n",
      "Epoch: 3, Step: 165, Loss: 0.13877084851264954\n",
      "Epoch: 3, Step: 166, Loss: 0.14443513751029968\n",
      "Epoch: 3, Step: 167, Loss: 0.07185880839824677\n",
      "Epoch: 3, Step: 168, Loss: 0.20503203570842743\n",
      "Epoch: 3, Step: 169, Loss: 0.08802051097154617\n",
      "Epoch: 3, Step: 170, Loss: 0.16875004768371582\n",
      "Epoch: 3, Step: 171, Loss: 0.14703068137168884\n",
      "Epoch: 3, Step: 172, Loss: 0.15664759278297424\n",
      "Epoch: 3, Step: 173, Loss: 0.18088093400001526\n",
      "Epoch: 3, Step: 174, Loss: 0.23316684365272522\n",
      "Epoch: 3, Step: 175, Loss: 0.19449061155319214\n",
      "Epoch: 3, Step: 176, Loss: 0.1594984382390976\n",
      "Epoch: 3, Step: 177, Loss: 0.14446964859962463\n",
      "Epoch: 3, Step: 178, Loss: 0.3673062026500702\n",
      "Epoch: 3, Step: 179, Loss: 0.20118515193462372\n",
      "Epoch: 3, Step: 180, Loss: 0.1245143860578537\n",
      "Epoch: 3, Step: 181, Loss: 0.17028257250785828\n",
      "Epoch: 3, Step: 182, Loss: 0.16951607167720795\n",
      "Epoch: 3, Step: 183, Loss: 0.08450651168823242\n",
      "Epoch: 3, Step: 184, Loss: 0.20591230690479279\n",
      "Epoch: 3, Step: 185, Loss: 0.13026311993598938\n",
      "Epoch: 3, Step: 186, Loss: 0.14361079037189484\n",
      "Epoch: 3, Step: 187, Loss: 0.154866561293602\n",
      "Epoch: 3, Step: 188, Loss: 0.16456793248653412\n",
      "Epoch: 3, Step: 189, Loss: 0.24477480351924896\n",
      "Epoch: 3, Step: 190, Loss: 0.06317685544490814\n",
      "Epoch: 3, Step: 191, Loss: 0.11835818737745285\n",
      "Epoch: 3, Step: 192, Loss: 0.07744678854942322\n",
      "Epoch: 3, Step: 193, Loss: 0.13472896814346313\n",
      "Epoch: 3, Step: 194, Loss: 0.13298749923706055\n",
      "Epoch: 3, Step: 195, Loss: 0.1282493770122528\n",
      "Epoch: 3, Step: 196, Loss: 0.09335990250110626\n",
      "Epoch: 3, Step: 197, Loss: 0.13228638470172882\n",
      "Epoch: 3, Step: 198, Loss: 0.12896959483623505\n",
      "Epoch: 3, Step: 199, Loss: 0.15287169814109802\n",
      "Epoch: 3, Step: 200, Loss: 0.12103249132633209\n",
      "Epoch: 3, Step: 201, Loss: 0.1565321981906891\n",
      "Epoch: 3, Step: 202, Loss: 0.06815396994352341\n",
      "Epoch: 3, Step: 203, Loss: 0.0721951350569725\n",
      "Epoch: 3, Step: 204, Loss: 0.30647292733192444\n",
      "Epoch: 3, Step: 205, Loss: 0.08355841040611267\n",
      "Epoch: 3, Step: 206, Loss: 0.21376246213912964\n",
      "Epoch: 3, Step: 207, Loss: 0.11758439242839813\n",
      "Epoch: 3, Step: 208, Loss: 0.16912364959716797\n",
      "Epoch: 3, Step: 209, Loss: 0.057314276695251465\n",
      "Epoch: 3, Step: 210, Loss: 0.18452312052249908\n",
      "Epoch: 3, Step: 211, Loss: 0.14875823259353638\n",
      "Epoch: 3, Step: 212, Loss: 0.12684130668640137\n",
      "Epoch: 3, Step: 213, Loss: 0.13004305958747864\n",
      "Epoch: 3, Step: 214, Loss: 0.0906122475862503\n",
      "Epoch: 3, Step: 215, Loss: 0.20362089574337006\n",
      "Epoch: 3, Step: 216, Loss: 0.07433982193470001\n",
      "Epoch: 3, Step: 217, Loss: 0.20740017294883728\n",
      "Epoch: 3, Step: 218, Loss: 0.16755923628807068\n",
      "Epoch: 3, Step: 219, Loss: 0.0893433541059494\n",
      "Epoch: 3, Step: 220, Loss: 0.1646028459072113\n",
      "Epoch: 3, Step: 221, Loss: 0.12157317250967026\n",
      "Epoch: 3, Step: 222, Loss: 0.048948414623737335\n",
      "Epoch: 3, Step: 223, Loss: 0.08181672543287277\n",
      "Epoch: 3, Step: 224, Loss: 0.2511592507362366\n",
      "Epoch: 3, Step: 225, Loss: 0.1255154013633728\n",
      "Epoch: 3, Step: 226, Loss: 0.12916335463523865\n",
      "Epoch: 3, Step: 227, Loss: 0.1308279037475586\n",
      "Epoch: 3, Step: 228, Loss: 0.1991288959980011\n",
      "Epoch: 3, Step: 229, Loss: 0.09405642747879028\n",
      "Epoch: 3, Step: 230, Loss: 0.20478709042072296\n",
      "Epoch: 3, Step: 231, Loss: 0.1940692514181137\n",
      "Epoch: 3, Step: 232, Loss: 0.17355599999427795\n",
      "Epoch: 3, Step: 233, Loss: 0.12475837767124176\n",
      "Epoch: 3, Step: 234, Loss: 0.2118629366159439\n",
      "Epoch: 3, Step: 235, Loss: 0.15654751658439636\n",
      "Epoch: 3, Step: 236, Loss: 0.06561237573623657\n",
      "Epoch: 3, Step: 237, Loss: 0.10343784838914871\n",
      "Epoch: 3, Step: 238, Loss: 0.18555906414985657\n",
      "Epoch: 3, Step: 239, Loss: 0.10676144063472748\n",
      "Epoch: 3, Step: 240, Loss: 0.08840033411979675\n",
      "Epoch: 3, Step: 241, Loss: 0.23247483372688293\n",
      "Epoch: 3, Step: 242, Loss: 0.04892291873693466\n",
      "Epoch: 3, Step: 243, Loss: 0.09170565009117126\n",
      "Epoch: 3, Step: 244, Loss: 0.21508586406707764\n",
      "Epoch: 3, Step: 245, Loss: 0.12294414639472961\n",
      "Epoch: 3, Step: 246, Loss: 0.10204831510782242\n",
      "Epoch: 3, Step: 247, Loss: 0.21358437836170197\n",
      "Epoch: 3, Step: 248, Loss: 0.2751559615135193\n",
      "Epoch: 3, Step: 249, Loss: 0.15408281981945038\n",
      "Epoch: 3, Step: 250, Loss: 0.16981720924377441\n",
      "Epoch: 3, Step: 251, Loss: 0.09034904837608337\n",
      "Epoch: 3, Step: 252, Loss: 0.04163593053817749\n",
      "Epoch: 3, Step: 253, Loss: 0.13297170400619507\n",
      "Epoch: 3, Step: 254, Loss: 0.1025175228714943\n",
      "Epoch: 3, Step: 255, Loss: 0.07910805940628052\n",
      "Epoch: 3, Step: 256, Loss: 0.1646016538143158\n",
      "Epoch: 3, Step: 257, Loss: 0.11002708971500397\n",
      "Epoch: 3, Step: 258, Loss: 0.08813844621181488\n",
      "Epoch: 3, Step: 259, Loss: 0.16846239566802979\n",
      "Epoch: 3, Step: 260, Loss: 0.08993534743785858\n",
      "Epoch: 3, Step: 261, Loss: 0.09615615755319595\n",
      "Epoch: 3, Step: 262, Loss: 0.2303217649459839\n",
      "Epoch: 3, Step: 263, Loss: 0.19095566868782043\n",
      "Epoch: 3, Step: 264, Loss: 0.1673344075679779\n",
      "Epoch: 3, Step: 265, Loss: 0.17283469438552856\n",
      "Epoch: 3, Step: 266, Loss: 0.1808280348777771\n",
      "Epoch: 3, Step: 267, Loss: 0.12240322679281235\n",
      "Epoch: 3, Step: 268, Loss: 0.08248011767864227\n",
      "Epoch: 3, Step: 269, Loss: 0.2382274866104126\n",
      "Epoch: 3, Step: 270, Loss: 0.14907820522785187\n",
      "Epoch: 3, Step: 271, Loss: 0.1307639181613922\n",
      "Epoch: 3, Step: 272, Loss: 0.17981307208538055\n",
      "Epoch: 3, Step: 273, Loss: 0.2253597378730774\n",
      "Epoch: 3, Step: 274, Loss: 0.08515599370002747\n",
      "Epoch: 3, Step: 275, Loss: 0.11803209036588669\n",
      "Epoch: 3, Step: 276, Loss: 0.24249140918254852\n",
      "Epoch: 3, Step: 277, Loss: 0.09613460302352905\n",
      "Epoch: 3, Step: 278, Loss: 0.15536785125732422\n",
      "Epoch: 3, Step: 279, Loss: 0.06897372752428055\n",
      "Epoch: 3, Step: 280, Loss: 0.25326007604599\n",
      "Epoch: 3, Step: 281, Loss: 0.15040257573127747\n",
      "Epoch: 3, Step: 282, Loss: 0.13094305992126465\n",
      "Epoch: 3, Step: 283, Loss: 0.22206789255142212\n",
      "Epoch: 3, Step: 284, Loss: 0.04342822730541229\n",
      "Epoch: 3, Step: 285, Loss: 0.12209807336330414\n",
      "Epoch: 3, Step: 286, Loss: 0.26042670011520386\n",
      "Epoch: 3, Step: 287, Loss: 0.2342997044324875\n",
      "Epoch: 3, Step: 288, Loss: 0.15851092338562012\n",
      "Epoch: 3, Step: 289, Loss: 0.20787695050239563\n",
      "Epoch: 3, Step: 290, Loss: 0.13211959600448608\n",
      "Epoch: 3, Step: 291, Loss: 0.25054317712783813\n",
      "Epoch: 3, Step: 292, Loss: 0.08388516306877136\n",
      "Epoch: 3, Step: 293, Loss: 0.1650630086660385\n",
      "Epoch: 3, Step: 294, Loss: 0.1287001371383667\n",
      "Epoch: 3, Step: 295, Loss: 0.08943210542201996\n",
      "Epoch: 3, Step: 296, Loss: 0.1664307415485382\n",
      "Epoch: 3, Step: 297, Loss: 0.15253493189811707\n",
      "Epoch: 3, Step: 298, Loss: 0.15991783142089844\n",
      "Epoch: 3, Step: 299, Loss: 0.14568480849266052\n",
      "Epoch: 3, Step: 300, Loss: 0.10520941019058228\n",
      "Epoch: 3, Step: 301, Loss: 0.08307245373725891\n",
      "Epoch: 3, Step: 302, Loss: 0.13808929920196533\n",
      "Epoch: 3, Step: 303, Loss: 0.17478567361831665\n",
      "Epoch: 3, Step: 304, Loss: 0.1327926218509674\n",
      "Epoch: 3, Step: 305, Loss: 0.13496103882789612\n",
      "Epoch: 3, Step: 306, Loss: 0.12704868614673615\n",
      "Epoch: 3, Step: 307, Loss: 0.4847654700279236\n",
      "Epoch: 3, Step: 308, Loss: 0.14572247862815857\n",
      "Epoch: 3, Step: 309, Loss: 0.17236313223838806\n",
      "Epoch: 3, Step: 310, Loss: 0.12113325297832489\n",
      "Epoch: 3, Step: 311, Loss: 0.21840710937976837\n",
      "Epoch: 3, Step: 312, Loss: 0.054002828896045685\n",
      "Epoch: 3, Step: 313, Loss: 0.05582433193922043\n",
      "Epoch: 3, Step: 314, Loss: 0.24157747626304626\n",
      "Epoch: 3, Step: 315, Loss: 0.09285390377044678\n",
      "Epoch: 3, Step: 316, Loss: 0.08251391351222992\n",
      "Epoch: 3, Step: 317, Loss: 0.16072219610214233\n",
      "Epoch: 3, Step: 318, Loss: 0.08708393573760986\n",
      "Epoch: 3, Step: 319, Loss: 0.07916222512722015\n",
      "Epoch: 3, Step: 320, Loss: 0.12901894748210907\n",
      "Epoch: 3, Step: 321, Loss: 0.2241659313440323\n",
      "Epoch: 3, Step: 322, Loss: 0.08379393815994263\n",
      "Epoch: 3, Step: 323, Loss: 0.0809132531285286\n",
      "Epoch: 3, Step: 324, Loss: 0.2534923255443573\n",
      "Epoch: 3, Step: 325, Loss: 0.41316625475883484\n",
      "Epoch: 3, Step: 326, Loss: 0.19006991386413574\n",
      "Epoch: 3, Step: 327, Loss: 0.12559616565704346\n",
      "Epoch: 3, Step: 328, Loss: 0.16636931896209717\n",
      "Epoch: 3, Step: 329, Loss: 0.12322132289409637\n",
      "Epoch: 3, Step: 330, Loss: 0.11064347624778748\n",
      "Epoch: 3, Step: 331, Loss: 0.1790580153465271\n",
      "Epoch: 3, Step: 332, Loss: 0.17068952322006226\n",
      "Epoch: 3, Step: 333, Loss: 0.11698346585035324\n",
      "Epoch: 3, Step: 334, Loss: 0.08721111714839935\n",
      "Epoch: 3, Step: 335, Loss: 0.12944528460502625\n",
      "Epoch: 3, Step: 336, Loss: 0.12704414129257202\n",
      "Epoch: 3, Step: 337, Loss: 0.18889422714710236\n",
      "Epoch: 3, Step: 338, Loss: 0.07673671841621399\n",
      "Epoch: 3, Step: 339, Loss: 0.05046611651778221\n",
      "Epoch: 3, Step: 340, Loss: 0.08452111482620239\n",
      "Epoch: 3, Step: 341, Loss: 0.08005094528198242\n",
      "Epoch: 3, Step: 342, Loss: 0.091408871114254\n",
      "Epoch: 3, Step: 343, Loss: 0.11261682212352753\n",
      "Epoch: 3, Step: 344, Loss: 0.08572585880756378\n",
      "Epoch: 3, Step: 345, Loss: 0.15496116876602173\n",
      "Epoch: 3, Step: 346, Loss: 0.2005741447210312\n",
      "Epoch: 3, Step: 347, Loss: 0.1105145812034607\n",
      "Epoch: 3, Step: 348, Loss: 0.2056536078453064\n",
      "Epoch: 3, Step: 349, Loss: 0.09474256634712219\n",
      "Epoch: 3, Step: 350, Loss: 0.21058118343353271\n",
      "Epoch: 3, Step: 351, Loss: 0.22228077054023743\n",
      "Epoch: 3, Step: 352, Loss: 0.12609262764453888\n",
      "Epoch: 3, Step: 353, Loss: 0.07870899140834808\n",
      "Epoch: 3, Step: 354, Loss: 0.17699608206748962\n",
      "Epoch: 3, Step: 355, Loss: 0.07278981804847717\n",
      "Epoch: 3, Step: 356, Loss: 0.10270901024341583\n",
      "Epoch: 3, Step: 357, Loss: 0.09202754497528076\n",
      "Epoch: 3, Step: 358, Loss: 0.13317112624645233\n",
      "Epoch: 3, Step: 359, Loss: 0.1300961673259735\n",
      "Epoch: 3, Step: 360, Loss: 0.11606340110301971\n",
      "Epoch: 3, Step: 361, Loss: 0.08551803231239319\n",
      "Epoch: 3, Step: 362, Loss: 0.0940578281879425\n",
      "Epoch: 3, Step: 363, Loss: 0.12509191036224365\n",
      "Epoch: 3, Step: 364, Loss: 0.12973153591156006\n",
      "Epoch: 3, Step: 365, Loss: 0.1699795126914978\n",
      "Epoch: 3, Step: 366, Loss: 0.15740588307380676\n",
      "Epoch: 3, Step: 367, Loss: 0.13661348819732666\n",
      "Epoch: 3, Step: 368, Loss: 0.257038950920105\n",
      "Epoch: 3, Step: 369, Loss: 0.15276367962360382\n",
      "Epoch: 3, Step: 370, Loss: 0.14809884130954742\n",
      "Epoch: 3, Step: 371, Loss: 0.0701109915971756\n",
      "Epoch: 3, Step: 372, Loss: 0.15371401607990265\n",
      "Epoch: 3, Step: 373, Loss: 0.14377570152282715\n",
      "Epoch: 3, Step: 374, Loss: 0.11616745591163635\n",
      "Epoch: 3, Step: 375, Loss: 0.14372481405735016\n",
      "Epoch: 3, Step: 376, Loss: 0.09968655556440353\n",
      "Epoch: 3, Step: 377, Loss: 0.1416473090648651\n",
      "Epoch: 3, Step: 378, Loss: 0.3113466501235962\n",
      "Epoch: 3, Step: 379, Loss: 0.0846400260925293\n",
      "Epoch: 3, Step: 380, Loss: 0.1474890559911728\n",
      "Epoch: 3, Step: 381, Loss: 0.07613510638475418\n",
      "Epoch: 3, Step: 382, Loss: 0.07787032425403595\n",
      "Epoch: 3, Step: 383, Loss: 0.05186643823981285\n",
      "Epoch: 3, Step: 384, Loss: 0.16090533137321472\n",
      "Epoch: 3, Step: 385, Loss: 0.3217536211013794\n",
      "Epoch: 3, Step: 386, Loss: 0.13360825181007385\n",
      "Epoch: 3, Step: 387, Loss: 0.13618099689483643\n",
      "Epoch: 3, Step: 388, Loss: 0.11093965172767639\n",
      "Epoch: 3, Step: 389, Loss: 0.1339201033115387\n",
      "Epoch: 3, Step: 390, Loss: 0.3245466649532318\n",
      "Epoch: 3, Step: 391, Loss: 0.05774834007024765\n",
      "Epoch: 3, Step: 392, Loss: 0.08710785210132599\n",
      "Epoch: 3, Step: 393, Loss: 0.12681804597377777\n",
      "Epoch: 3, Step: 394, Loss: 0.15694960951805115\n",
      "Epoch: 3, Step: 395, Loss: 0.08257156610488892\n",
      "Epoch: 3, Step: 396, Loss: 0.09049264341592789\n",
      "Epoch: 3, Step: 397, Loss: 0.17050395905971527\n",
      "Epoch: 3, Step: 398, Loss: 0.11842045187950134\n",
      "Epoch: 3, Step: 399, Loss: 0.14714625477790833\n",
      "Epoch: 3, Step: 400, Loss: 0.050947658717632294\n",
      "Epoch: 3, Step: 401, Loss: 0.1128615140914917\n",
      "Epoch: 3, Step: 402, Loss: 0.16856028139591217\n",
      "Epoch: 3, Step: 403, Loss: 0.10743913799524307\n",
      "Epoch: 3, Step: 404, Loss: 0.08091650903224945\n",
      "Epoch: 3, Step: 405, Loss: 0.08586674928665161\n",
      "Epoch: 3, Step: 406, Loss: 0.2954266369342804\n",
      "Epoch: 3, Step: 407, Loss: 0.12961025536060333\n",
      "Epoch: 3, Step: 408, Loss: 0.20384933054447174\n",
      "Epoch: 3, Step: 409, Loss: 0.1756204515695572\n",
      "Epoch: 3, Step: 410, Loss: 0.10245255380868912\n",
      "Epoch: 3, Step: 411, Loss: 0.20328915119171143\n",
      "Epoch: 3, Step: 412, Loss: 0.16978119313716888\n",
      "Epoch: 3, Step: 413, Loss: 0.15421536564826965\n",
      "Epoch: 3, Step: 414, Loss: 0.2774824798107147\n",
      "Epoch: 3, Step: 415, Loss: 0.13173706829547882\n",
      "Epoch: 3, Step: 416, Loss: 0.18086481094360352\n",
      "Epoch: 3, Step: 417, Loss: 0.05650227516889572\n",
      "Epoch: 3, Step: 418, Loss: 0.20628055930137634\n",
      "Epoch: 3, Step: 419, Loss: 0.10623759031295776\n",
      "Epoch: 3, Step: 420, Loss: 0.08763426542282104\n",
      "Epoch: 3, Step: 421, Loss: 0.22102288901805878\n",
      "Epoch: 3, Step: 422, Loss: 0.08528706431388855\n",
      "Epoch: 3, Step: 423, Loss: 0.10928337275981903\n",
      "Epoch: 3, Step: 424, Loss: 0.15526820719242096\n",
      "Epoch: 3, Step: 425, Loss: 0.14755618572235107\n",
      "Epoch: 3, Step: 426, Loss: 0.08139154314994812\n",
      "Epoch: 3, Step: 427, Loss: 0.10493676364421844\n",
      "Epoch: 3, Step: 428, Loss: 0.1712946742773056\n",
      "Epoch: 3, Step: 429, Loss: 0.0941632091999054\n",
      "Epoch: 3, Step: 430, Loss: 0.13436803221702576\n",
      "Epoch: 3, Step: 431, Loss: 0.05513747036457062\n",
      "Epoch: 3, Step: 432, Loss: 0.10699057579040527\n",
      "Epoch: 3, Step: 433, Loss: 0.10961171984672546\n",
      "Epoch: 3, Step: 434, Loss: 0.14448773860931396\n",
      "Epoch: 3, Step: 435, Loss: 0.05120008811354637\n",
      "Epoch: 3, Step: 436, Loss: 0.2172822654247284\n",
      "Epoch: 3, Step: 437, Loss: 0.13943065702915192\n",
      "Epoch: 3, Step: 438, Loss: 0.10946768522262573\n",
      "Epoch: 3, Step: 439, Loss: 0.1519399732351303\n",
      "Epoch: 3, Step: 440, Loss: 0.11297252774238586\n",
      "Epoch: 3, Step: 441, Loss: 0.1561306118965149\n",
      "Epoch: 3, Step: 442, Loss: 0.03873467817902565\n",
      "Epoch: 3, Step: 443, Loss: 0.18873289227485657\n",
      "Epoch: 3, Step: 444, Loss: 0.0805705189704895\n",
      "Epoch: 3, Step: 445, Loss: 0.10301029682159424\n",
      "Epoch: 3, Step: 446, Loss: 0.11764994263648987\n",
      "Epoch: 3, Step: 447, Loss: 0.06958133727312088\n",
      "Epoch: 3, Step: 448, Loss: 0.08615925908088684\n",
      "Epoch: 3, Step: 449, Loss: 0.18325550854206085\n",
      "Epoch: 3, Step: 450, Loss: 0.16685111820697784\n",
      "Epoch: 3, Step: 451, Loss: 0.1356806606054306\n",
      "Epoch: 3, Step: 452, Loss: 0.20659798383712769\n",
      "Epoch: 3, Step: 453, Loss: 0.24063901603221893\n",
      "Epoch: 3, Step: 454, Loss: 0.11535059660673141\n",
      "Epoch: 3, Step: 455, Loss: 0.07240007817745209\n",
      "Epoch: 3, Step: 456, Loss: 0.16581693291664124\n",
      "Epoch: 3, Step: 457, Loss: 0.14856824278831482\n",
      "Epoch: 3, Step: 458, Loss: 0.0818868950009346\n",
      "Epoch: 3, Step: 459, Loss: 0.14503629505634308\n",
      "Epoch: 3, Step: 460, Loss: 0.11347249895334244\n",
      "Epoch: 3, Step: 461, Loss: 0.12240863591432571\n",
      "Epoch: 3, Step: 462, Loss: 0.05279991775751114\n",
      "Epoch: 3, Step: 463, Loss: 0.21466611325740814\n",
      "Epoch: 3, Step: 464, Loss: 0.2896919846534729\n",
      "Epoch: 3, Step: 465, Loss: 0.14547032117843628\n",
      "Epoch: 3, Step: 466, Loss: 0.09389844536781311\n",
      "Epoch: 3, Step: 467, Loss: 0.30670034885406494\n",
      "Epoch: 3, Step: 468, Loss: 0.15522180497646332\n",
      "Epoch: 3, Step: 469, Loss: 0.09630045294761658\n",
      "Epoch: 3, Step: 470, Loss: 0.10636671632528305\n",
      "Epoch: 3, Step: 471, Loss: 0.0682203620672226\n",
      "Epoch: 3, Step: 472, Loss: 0.11359233409166336\n",
      "Epoch: 3, Step: 473, Loss: 0.22735506296157837\n",
      "Epoch: 3, Step: 474, Loss: 0.08550634980201721\n",
      "Epoch: 3, Step: 475, Loss: 0.15088137984275818\n",
      "Epoch: 3, Step: 476, Loss: 0.058837030082941055\n",
      "Epoch: 3, Step: 477, Loss: 0.10377722978591919\n",
      "Epoch: 3, Step: 478, Loss: 0.049152251332998276\n",
      "Epoch: 3, Step: 479, Loss: 0.07750891149044037\n",
      "Epoch: 3, Step: 480, Loss: 0.10775972902774811\n",
      "Epoch: 3, Step: 481, Loss: 0.08606413006782532\n",
      "Epoch: 3, Step: 482, Loss: 0.162974014878273\n",
      "Epoch: 3, Step: 483, Loss: 0.2446458637714386\n",
      "Epoch: 3, Step: 484, Loss: 0.1358424425125122\n",
      "Epoch: 3, Step: 485, Loss: 0.06624989211559296\n",
      "Epoch: 3, Step: 486, Loss: 0.029009822756052017\n",
      "Epoch: 3, Step: 487, Loss: 0.29050198197364807\n",
      "Epoch: 3, Step: 488, Loss: 0.12650981545448303\n",
      "Epoch: 3, Step: 489, Loss: 0.14194992184638977\n",
      "Epoch: 3, Step: 490, Loss: 0.06759063154459\n",
      "Epoch: 3, Step: 491, Loss: 0.10708555579185486\n",
      "Epoch: 3, Step: 492, Loss: 0.08734951168298721\n",
      "Epoch: 3, Step: 493, Loss: 0.04970095306634903\n",
      "Epoch: 3, Step: 494, Loss: 0.07172401994466782\n",
      "Epoch: 3, Step: 495, Loss: 0.2613833546638489\n",
      "Epoch: 3, Step: 496, Loss: 0.13478226959705353\n",
      "Epoch: 3, Step: 497, Loss: 0.11431114375591278\n",
      "Epoch: 3, Step: 498, Loss: 0.07538110762834549\n",
      "Epoch: 3, Step: 499, Loss: 0.11653628945350647\n",
      "Epoch: 3, Step: 500, Loss: 0.11811871826648712\n",
      "Epoch: 3, Step: 501, Loss: 0.1511363387107849\n",
      "Epoch: 3, Step: 502, Loss: 0.13065755367279053\n",
      "Epoch: 3, Step: 503, Loss: 0.27222296595573425\n",
      "Epoch: 4, Step: 0, Loss: 0.18450498580932617\n",
      "Epoch: 4, Step: 1, Loss: 0.13210853934288025\n",
      "Epoch: 4, Step: 2, Loss: 0.04464946687221527\n",
      "Epoch: 4, Step: 3, Loss: 0.12939995527267456\n",
      "Epoch: 4, Step: 4, Loss: 0.14681345224380493\n",
      "Epoch: 4, Step: 5, Loss: 0.060885656625032425\n",
      "Epoch: 4, Step: 6, Loss: 0.08192739635705948\n",
      "Epoch: 4, Step: 7, Loss: 0.11515603214502335\n",
      "Epoch: 4, Step: 8, Loss: 0.08110036700963974\n",
      "Epoch: 4, Step: 9, Loss: 0.16052326560020447\n",
      "Epoch: 4, Step: 10, Loss: 0.15122249722480774\n",
      "Epoch: 4, Step: 11, Loss: 0.08983398973941803\n",
      "Epoch: 4, Step: 12, Loss: 0.21542757749557495\n",
      "Epoch: 4, Step: 13, Loss: 0.07156874239444733\n",
      "Epoch: 4, Step: 14, Loss: 0.13330276310443878\n",
      "Epoch: 4, Step: 15, Loss: 0.04667450487613678\n",
      "Epoch: 4, Step: 16, Loss: 0.1612817943096161\n",
      "Epoch: 4, Step: 17, Loss: 0.10727114975452423\n",
      "Epoch: 4, Step: 18, Loss: 0.08257712423801422\n",
      "Epoch: 4, Step: 19, Loss: 0.19156885147094727\n",
      "Epoch: 4, Step: 20, Loss: 0.1567120999097824\n",
      "Epoch: 4, Step: 21, Loss: 0.08344141393899918\n",
      "Epoch: 4, Step: 22, Loss: 0.16941039264202118\n",
      "Epoch: 4, Step: 23, Loss: 0.14856502413749695\n",
      "Epoch: 4, Step: 24, Loss: 0.07522332668304443\n",
      "Epoch: 4, Step: 25, Loss: 0.14473822712898254\n",
      "Epoch: 4, Step: 26, Loss: 0.06724334508180618\n",
      "Epoch: 4, Step: 27, Loss: 0.1394944190979004\n",
      "Epoch: 4, Step: 28, Loss: 0.1692027449607849\n",
      "Epoch: 4, Step: 29, Loss: 0.10101435333490372\n",
      "Epoch: 4, Step: 30, Loss: 0.19495558738708496\n",
      "Epoch: 4, Step: 31, Loss: 0.14632439613342285\n",
      "Epoch: 4, Step: 32, Loss: 0.07366945594549179\n",
      "Epoch: 4, Step: 33, Loss: 0.09173819422721863\n",
      "Epoch: 4, Step: 34, Loss: 0.08879227936267853\n",
      "Epoch: 4, Step: 35, Loss: 0.1515534669160843\n",
      "Epoch: 4, Step: 36, Loss: 0.07943551242351532\n",
      "Epoch: 4, Step: 37, Loss: 0.09509854763746262\n",
      "Epoch: 4, Step: 38, Loss: 0.1592346578836441\n",
      "Epoch: 4, Step: 39, Loss: 0.11644984781742096\n",
      "Epoch: 4, Step: 40, Loss: 0.09960585832595825\n",
      "Epoch: 4, Step: 41, Loss: 0.10577356070280075\n",
      "Epoch: 4, Step: 42, Loss: 0.1223088800907135\n",
      "Epoch: 4, Step: 43, Loss: 0.1994411200284958\n",
      "Epoch: 4, Step: 44, Loss: 0.1861652433872223\n",
      "Epoch: 4, Step: 45, Loss: 0.06737230718135834\n",
      "Epoch: 4, Step: 46, Loss: 0.05324438214302063\n",
      "Epoch: 4, Step: 47, Loss: 0.051161788403987885\n",
      "Epoch: 4, Step: 48, Loss: 0.03275057673454285\n",
      "Epoch: 4, Step: 49, Loss: 0.16405385732650757\n",
      "Epoch: 4, Step: 50, Loss: 0.08014154434204102\n",
      "Epoch: 4, Step: 51, Loss: 0.15610618889331818\n",
      "Epoch: 4, Step: 52, Loss: 0.10495643317699432\n",
      "Epoch: 4, Step: 53, Loss: 0.1070430725812912\n",
      "Epoch: 4, Step: 54, Loss: 0.08602894842624664\n",
      "Epoch: 4, Step: 55, Loss: 0.16804881393909454\n",
      "Epoch: 4, Step: 56, Loss: 0.10117107629776001\n",
      "Epoch: 4, Step: 57, Loss: 0.06867031753063202\n",
      "Epoch: 4, Step: 58, Loss: 0.09589947760105133\n",
      "Epoch: 4, Step: 59, Loss: 0.05575357750058174\n",
      "Epoch: 4, Step: 60, Loss: 0.1705106496810913\n",
      "Epoch: 4, Step: 61, Loss: 0.08899246156215668\n",
      "Epoch: 4, Step: 62, Loss: 0.04766412079334259\n",
      "Epoch: 4, Step: 63, Loss: 0.0762195885181427\n",
      "Epoch: 4, Step: 64, Loss: 0.10919879376888275\n",
      "Epoch: 4, Step: 65, Loss: 0.10972192883491516\n",
      "Epoch: 4, Step: 66, Loss: 0.09594641625881195\n",
      "Epoch: 4, Step: 67, Loss: 0.058866724371910095\n",
      "Epoch: 4, Step: 68, Loss: 0.07796000689268112\n",
      "Epoch: 4, Step: 69, Loss: 0.039598602801561356\n",
      "Epoch: 4, Step: 70, Loss: 0.10592500865459442\n",
      "Epoch: 4, Step: 71, Loss: 0.20180341601371765\n",
      "Epoch: 4, Step: 72, Loss: 0.11588503420352936\n",
      "Epoch: 4, Step: 73, Loss: 0.07318884134292603\n",
      "Epoch: 4, Step: 74, Loss: 0.08133235573768616\n",
      "Epoch: 4, Step: 75, Loss: 0.16543617844581604\n",
      "Epoch: 4, Step: 76, Loss: 0.1162896603345871\n",
      "Epoch: 4, Step: 77, Loss: 0.08970556408166885\n",
      "Epoch: 4, Step: 78, Loss: 0.0833660140633583\n",
      "Epoch: 4, Step: 79, Loss: 0.05331999063491821\n",
      "Epoch: 4, Step: 80, Loss: 0.09371136128902435\n",
      "Epoch: 4, Step: 81, Loss: 0.0934450551867485\n",
      "Epoch: 4, Step: 82, Loss: 0.2749491333961487\n",
      "Epoch: 4, Step: 83, Loss: 0.07972422242164612\n",
      "Epoch: 4, Step: 84, Loss: 0.09734025597572327\n",
      "Epoch: 4, Step: 85, Loss: 0.18853303790092468\n",
      "Epoch: 4, Step: 86, Loss: 0.11066189408302307\n",
      "Epoch: 4, Step: 87, Loss: 0.10136651992797852\n",
      "Epoch: 4, Step: 88, Loss: 0.08311578631401062\n",
      "Epoch: 4, Step: 89, Loss: 0.23259705305099487\n",
      "Epoch: 4, Step: 90, Loss: 0.09702169895172119\n",
      "Epoch: 4, Step: 91, Loss: 0.08542218804359436\n",
      "Epoch: 4, Step: 92, Loss: 0.07323266565799713\n",
      "Epoch: 4, Step: 93, Loss: 0.14812834560871124\n",
      "Epoch: 4, Step: 94, Loss: 0.1226351335644722\n",
      "Epoch: 4, Step: 95, Loss: 0.14703814685344696\n",
      "Epoch: 4, Step: 96, Loss: 0.06245626509189606\n",
      "Epoch: 4, Step: 97, Loss: 0.1426086723804474\n",
      "Epoch: 4, Step: 98, Loss: 0.10753074288368225\n",
      "Epoch: 4, Step: 99, Loss: 0.0850365087389946\n",
      "Epoch: 4, Step: 100, Loss: 0.0822579637169838\n",
      "Epoch: 4, Step: 101, Loss: 0.08272925019264221\n",
      "Epoch: 4, Step: 102, Loss: 0.07173241674900055\n",
      "Epoch: 4, Step: 103, Loss: 0.23380059003829956\n",
      "Epoch: 4, Step: 104, Loss: 0.14652827382087708\n",
      "Epoch: 4, Step: 105, Loss: 0.1466534286737442\n",
      "Epoch: 4, Step: 106, Loss: 0.14057773351669312\n",
      "Epoch: 4, Step: 107, Loss: 0.04844554513692856\n",
      "Epoch: 4, Step: 108, Loss: 0.10926739871501923\n",
      "Epoch: 4, Step: 109, Loss: 0.08946368843317032\n",
      "Epoch: 4, Step: 110, Loss: 0.09656248986721039\n",
      "Epoch: 4, Step: 111, Loss: 0.1112765520811081\n",
      "Epoch: 4, Step: 112, Loss: 0.1681036651134491\n",
      "Epoch: 4, Step: 113, Loss: 0.0996544361114502\n",
      "Epoch: 4, Step: 114, Loss: 0.04845070093870163\n",
      "Epoch: 4, Step: 115, Loss: 0.16736316680908203\n",
      "Epoch: 4, Step: 116, Loss: 0.11167430132627487\n",
      "Epoch: 4, Step: 117, Loss: 0.168379545211792\n",
      "Epoch: 4, Step: 118, Loss: 0.11583128571510315\n",
      "Epoch: 4, Step: 119, Loss: 0.07389207184314728\n",
      "Epoch: 4, Step: 120, Loss: 0.17615944147109985\n",
      "Epoch: 4, Step: 121, Loss: 0.06493021547794342\n",
      "Epoch: 4, Step: 122, Loss: 0.06731215864419937\n",
      "Epoch: 4, Step: 123, Loss: 0.12206345796585083\n",
      "Epoch: 4, Step: 124, Loss: 0.09089303016662598\n",
      "Epoch: 4, Step: 125, Loss: 0.15246117115020752\n",
      "Epoch: 4, Step: 126, Loss: 0.22684435546398163\n",
      "Epoch: 4, Step: 127, Loss: 0.21901823580265045\n",
      "Epoch: 4, Step: 128, Loss: 0.048804815858602524\n",
      "Epoch: 4, Step: 129, Loss: 0.07414267957210541\n",
      "Epoch: 4, Step: 130, Loss: 0.07056120783090591\n",
      "Epoch: 4, Step: 131, Loss: 0.0851629227399826\n",
      "Epoch: 4, Step: 132, Loss: 0.08329145610332489\n",
      "Epoch: 4, Step: 133, Loss: 0.15243174135684967\n",
      "Epoch: 4, Step: 134, Loss: 0.08999998867511749\n",
      "Epoch: 4, Step: 135, Loss: 0.03424571454524994\n",
      "Epoch: 4, Step: 136, Loss: 0.13377243280410767\n",
      "Epoch: 4, Step: 137, Loss: 0.12737873196601868\n",
      "Epoch: 4, Step: 138, Loss: 0.0614180862903595\n",
      "Epoch: 4, Step: 139, Loss: 0.14990615844726562\n",
      "Epoch: 4, Step: 140, Loss: 0.09663820266723633\n",
      "Epoch: 4, Step: 141, Loss: 0.2262682020664215\n",
      "Epoch: 4, Step: 142, Loss: 0.13904723525047302\n",
      "Epoch: 4, Step: 143, Loss: 0.16725534200668335\n",
      "Epoch: 4, Step: 144, Loss: 0.19691601395606995\n",
      "Epoch: 4, Step: 145, Loss: 0.04243739694356918\n",
      "Epoch: 4, Step: 146, Loss: 0.0844930037856102\n",
      "Epoch: 4, Step: 147, Loss: 0.05635114386677742\n",
      "Epoch: 4, Step: 148, Loss: 0.06313037127256393\n",
      "Epoch: 4, Step: 149, Loss: 0.0872000902891159\n",
      "Epoch: 4, Step: 150, Loss: 0.06900839507579803\n",
      "Epoch: 4, Step: 151, Loss: 0.07716028392314911\n",
      "Epoch: 4, Step: 152, Loss: 0.11584953963756561\n",
      "Epoch: 4, Step: 153, Loss: 0.026425059884786606\n",
      "Epoch: 4, Step: 154, Loss: 0.13814154267311096\n",
      "Epoch: 4, Step: 155, Loss: 0.09166976064443588\n",
      "Epoch: 4, Step: 156, Loss: 0.1510697305202484\n",
      "Epoch: 4, Step: 157, Loss: 0.08047114312648773\n",
      "Epoch: 4, Step: 158, Loss: 0.15272639691829681\n",
      "Epoch: 4, Step: 159, Loss: 0.17692925035953522\n",
      "Epoch: 4, Step: 160, Loss: 0.049244195222854614\n",
      "Epoch: 4, Step: 161, Loss: 0.08304540812969208\n",
      "Epoch: 4, Step: 162, Loss: 0.06933745741844177\n",
      "Epoch: 4, Step: 163, Loss: 0.15353059768676758\n",
      "Epoch: 4, Step: 164, Loss: 0.061927471309900284\n",
      "Epoch: 4, Step: 165, Loss: 0.06247817724943161\n",
      "Epoch: 4, Step: 166, Loss: 0.14792810380458832\n",
      "Epoch: 4, Step: 167, Loss: 0.06690208613872528\n",
      "Epoch: 4, Step: 168, Loss: 0.15511764585971832\n",
      "Epoch: 4, Step: 169, Loss: 0.10087913274765015\n",
      "Epoch: 4, Step: 170, Loss: 0.08411191403865814\n",
      "Epoch: 4, Step: 171, Loss: 0.13145899772644043\n",
      "Epoch: 4, Step: 172, Loss: 0.08331194519996643\n",
      "Epoch: 4, Step: 173, Loss: 0.10212310403585434\n",
      "Epoch: 4, Step: 174, Loss: 0.08184224367141724\n",
      "Epoch: 4, Step: 175, Loss: 0.047795556485652924\n",
      "Epoch: 4, Step: 176, Loss: 0.1540077179670334\n",
      "Epoch: 4, Step: 177, Loss: 0.10945972800254822\n",
      "Epoch: 4, Step: 178, Loss: 0.15399183332920074\n",
      "Epoch: 4, Step: 179, Loss: 0.1524362862110138\n",
      "Epoch: 4, Step: 180, Loss: 0.03676002472639084\n",
      "Epoch: 4, Step: 181, Loss: 0.10610969364643097\n",
      "Epoch: 4, Step: 182, Loss: 0.05953700467944145\n",
      "Epoch: 4, Step: 183, Loss: 0.07584068179130554\n",
      "Epoch: 4, Step: 184, Loss: 0.06843677163124084\n",
      "Epoch: 4, Step: 185, Loss: 0.12535031139850616\n",
      "Epoch: 4, Step: 186, Loss: 0.07255640625953674\n",
      "Epoch: 4, Step: 187, Loss: 0.06946556270122528\n",
      "Epoch: 4, Step: 188, Loss: 0.1161465048789978\n",
      "Epoch: 4, Step: 189, Loss: 0.047560662031173706\n",
      "Epoch: 4, Step: 190, Loss: 0.09904009848833084\n",
      "Epoch: 4, Step: 191, Loss: 0.09431549906730652\n",
      "Epoch: 4, Step: 192, Loss: 0.05741541087627411\n",
      "Epoch: 4, Step: 193, Loss: 0.04764091596007347\n",
      "Epoch: 4, Step: 194, Loss: 0.05365414544939995\n",
      "Epoch: 4, Step: 195, Loss: 0.177447110414505\n",
      "Epoch: 4, Step: 196, Loss: 0.10498231649398804\n",
      "Epoch: 4, Step: 197, Loss: 0.21897666156291962\n",
      "Epoch: 4, Step: 198, Loss: 0.08534405380487442\n",
      "Epoch: 4, Step: 199, Loss: 0.06531135737895966\n",
      "Epoch: 4, Step: 200, Loss: 0.17579148709774017\n",
      "Epoch: 4, Step: 201, Loss: 0.08483107388019562\n",
      "Epoch: 4, Step: 202, Loss: 0.06647790968418121\n",
      "Epoch: 4, Step: 203, Loss: 0.05239665508270264\n",
      "Epoch: 4, Step: 204, Loss: 0.11688168346881866\n",
      "Epoch: 4, Step: 205, Loss: 0.14014406502246857\n",
      "Epoch: 4, Step: 206, Loss: 0.08137620985507965\n",
      "Epoch: 4, Step: 207, Loss: 0.13946464657783508\n",
      "Epoch: 4, Step: 208, Loss: 0.10658876597881317\n",
      "Epoch: 4, Step: 209, Loss: 0.07348896563053131\n",
      "Epoch: 4, Step: 210, Loss: 0.13559070229530334\n",
      "Epoch: 4, Step: 211, Loss: 0.045709267258644104\n",
      "Epoch: 4, Step: 212, Loss: 0.0399836003780365\n",
      "Epoch: 4, Step: 213, Loss: 0.07884412258863449\n",
      "Epoch: 4, Step: 214, Loss: 0.08970168232917786\n",
      "Epoch: 4, Step: 215, Loss: 0.03619852662086487\n",
      "Epoch: 4, Step: 216, Loss: 0.07451377809047699\n",
      "Epoch: 4, Step: 217, Loss: 0.04724602401256561\n",
      "Epoch: 4, Step: 218, Loss: 0.16751673817634583\n",
      "Epoch: 4, Step: 219, Loss: 0.0657389760017395\n",
      "Epoch: 4, Step: 220, Loss: 0.11621792614459991\n",
      "Epoch: 4, Step: 221, Loss: 0.048906054347753525\n",
      "Epoch: 4, Step: 222, Loss: 0.09458809345960617\n",
      "Epoch: 4, Step: 223, Loss: 0.08771159499883652\n",
      "Epoch: 4, Step: 224, Loss: 0.20429366827011108\n",
      "Epoch: 4, Step: 225, Loss: 0.06543853133916855\n",
      "Epoch: 4, Step: 226, Loss: 0.0584167018532753\n",
      "Epoch: 4, Step: 227, Loss: 0.06497320532798767\n",
      "Epoch: 4, Step: 228, Loss: 0.1548650562763214\n",
      "Epoch: 4, Step: 229, Loss: 0.13255232572555542\n",
      "Epoch: 4, Step: 230, Loss: 0.1277768611907959\n",
      "Epoch: 4, Step: 231, Loss: 0.05636686459183693\n",
      "Epoch: 4, Step: 232, Loss: 0.04429764300584793\n",
      "Epoch: 4, Step: 233, Loss: 0.10924167931079865\n",
      "Epoch: 4, Step: 234, Loss: 0.06987979263067245\n",
      "Epoch: 4, Step: 235, Loss: 0.07626903057098389\n",
      "Epoch: 4, Step: 236, Loss: 0.08798030018806458\n",
      "Epoch: 4, Step: 237, Loss: 0.13303837180137634\n",
      "Epoch: 4, Step: 238, Loss: 0.085710309445858\n",
      "Epoch: 4, Step: 239, Loss: 0.17493440210819244\n",
      "Epoch: 4, Step: 240, Loss: 0.21230429410934448\n",
      "Epoch: 4, Step: 241, Loss: 0.1288590282201767\n",
      "Epoch: 4, Step: 242, Loss: 0.13393676280975342\n",
      "Epoch: 4, Step: 243, Loss: 0.08743615448474884\n",
      "Epoch: 4, Step: 244, Loss: 0.08428089320659637\n",
      "Epoch: 4, Step: 245, Loss: 0.17029550671577454\n",
      "Epoch: 4, Step: 246, Loss: 0.06796128302812576\n",
      "Epoch: 4, Step: 247, Loss: 0.08278893679380417\n",
      "Epoch: 4, Step: 248, Loss: 0.14100509881973267\n",
      "Epoch: 4, Step: 249, Loss: 0.07224497944116592\n",
      "Epoch: 4, Step: 250, Loss: 0.06805181503295898\n",
      "Epoch: 4, Step: 251, Loss: 0.06962752342224121\n",
      "Epoch: 4, Step: 252, Loss: 0.07934018969535828\n",
      "Epoch: 4, Step: 253, Loss: 0.039022304117679596\n",
      "Epoch: 4, Step: 254, Loss: 0.11873827874660492\n",
      "Epoch: 4, Step: 255, Loss: 0.05035117641091347\n",
      "Epoch: 4, Step: 256, Loss: 0.11885706335306168\n",
      "Epoch: 4, Step: 257, Loss: 0.08540566265583038\n",
      "Epoch: 4, Step: 258, Loss: 0.09059074521064758\n",
      "Epoch: 4, Step: 259, Loss: 0.12826713919639587\n",
      "Epoch: 4, Step: 260, Loss: 0.061842117458581924\n",
      "Epoch: 4, Step: 261, Loss: 0.09376314282417297\n",
      "Epoch: 4, Step: 262, Loss: 0.07174817472696304\n",
      "Epoch: 4, Step: 263, Loss: 0.17915837466716766\n",
      "Epoch: 4, Step: 264, Loss: 0.10648472607135773\n",
      "Epoch: 4, Step: 265, Loss: 0.057405274361371994\n",
      "Epoch: 4, Step: 266, Loss: 0.1409704089164734\n",
      "Epoch: 4, Step: 267, Loss: 0.07447391748428345\n",
      "Epoch: 4, Step: 268, Loss: 0.14379382133483887\n",
      "Epoch: 4, Step: 269, Loss: 0.07835324853658676\n",
      "Epoch: 4, Step: 270, Loss: 0.07034705579280853\n",
      "Epoch: 4, Step: 271, Loss: 0.059977952390909195\n",
      "Epoch: 4, Step: 272, Loss: 0.08721216022968292\n",
      "Epoch: 4, Step: 273, Loss: 0.07279360294342041\n",
      "Epoch: 4, Step: 274, Loss: 0.08525803685188293\n",
      "Epoch: 4, Step: 275, Loss: 0.0684242695569992\n",
      "Epoch: 4, Step: 276, Loss: 0.05529225245118141\n",
      "Epoch: 4, Step: 277, Loss: 0.05439925193786621\n",
      "Epoch: 4, Step: 278, Loss: 0.13359904289245605\n",
      "Epoch: 4, Step: 279, Loss: 0.06925804913043976\n",
      "Epoch: 4, Step: 280, Loss: 0.05539010465145111\n",
      "Epoch: 4, Step: 281, Loss: 0.10477303713560104\n",
      "Epoch: 4, Step: 282, Loss: 0.05486060306429863\n",
      "Epoch: 4, Step: 283, Loss: 0.08452104032039642\n",
      "Epoch: 4, Step: 284, Loss: 0.1169346421957016\n",
      "Epoch: 4, Step: 285, Loss: 0.2160596251487732\n",
      "Epoch: 4, Step: 286, Loss: 0.10751830786466599\n",
      "Epoch: 4, Step: 287, Loss: 0.06588856875896454\n",
      "Epoch: 4, Step: 288, Loss: 0.06152527034282684\n",
      "Epoch: 4, Step: 289, Loss: 0.15848691761493683\n",
      "Epoch: 4, Step: 290, Loss: 0.11971934884786606\n",
      "Epoch: 4, Step: 291, Loss: 0.09241980314254761\n",
      "Epoch: 4, Step: 292, Loss: 0.21456849575042725\n",
      "Epoch: 4, Step: 293, Loss: 0.17440620064735413\n",
      "Epoch: 4, Step: 294, Loss: 0.033590611070394516\n",
      "Epoch: 4, Step: 295, Loss: 0.10553646832704544\n",
      "Epoch: 4, Step: 296, Loss: 0.06497351825237274\n",
      "Epoch: 4, Step: 297, Loss: 0.07217483222484589\n",
      "Epoch: 4, Step: 298, Loss: 0.049266643822193146\n",
      "Epoch: 4, Step: 299, Loss: 0.09094234555959702\n",
      "Epoch: 4, Step: 300, Loss: 0.09023517370223999\n",
      "Epoch: 4, Step: 301, Loss: 0.135378897190094\n",
      "Epoch: 4, Step: 302, Loss: 0.14609625935554504\n",
      "Epoch: 4, Step: 303, Loss: 0.09694086015224457\n",
      "Epoch: 4, Step: 304, Loss: 0.06595379114151001\n",
      "Epoch: 4, Step: 305, Loss: 0.1769663691520691\n",
      "Epoch: 4, Step: 306, Loss: 0.18010437488555908\n",
      "Epoch: 4, Step: 307, Loss: 0.13863927125930786\n",
      "Epoch: 4, Step: 308, Loss: 0.11338035017251968\n",
      "Epoch: 4, Step: 309, Loss: 0.09400410950183868\n",
      "Epoch: 4, Step: 310, Loss: 0.11854520440101624\n",
      "Epoch: 4, Step: 311, Loss: 0.11768084764480591\n",
      "Epoch: 4, Step: 312, Loss: 0.136253222823143\n",
      "Epoch: 4, Step: 313, Loss: 0.09800317883491516\n",
      "Epoch: 4, Step: 314, Loss: 0.056131623685359955\n",
      "Epoch: 4, Step: 315, Loss: 0.14989203214645386\n",
      "Epoch: 4, Step: 316, Loss: 0.05184797942638397\n",
      "Epoch: 4, Step: 317, Loss: 0.04216665402054787\n",
      "Epoch: 4, Step: 318, Loss: 0.06686830520629883\n",
      "Epoch: 4, Step: 319, Loss: 0.046068064868450165\n",
      "Epoch: 4, Step: 320, Loss: 0.07655908167362213\n",
      "Epoch: 4, Step: 321, Loss: 0.048061028122901917\n",
      "Epoch: 4, Step: 322, Loss: 0.1466836929321289\n",
      "Epoch: 4, Step: 323, Loss: 0.055527783930301666\n",
      "Epoch: 4, Step: 324, Loss: 0.11591827869415283\n",
      "Epoch: 4, Step: 325, Loss: 0.08891001343727112\n",
      "Epoch: 4, Step: 326, Loss: 0.07179945707321167\n",
      "Epoch: 4, Step: 327, Loss: 0.1130695641040802\n",
      "Epoch: 4, Step: 328, Loss: 0.064813993871212\n",
      "Epoch: 4, Step: 329, Loss: 0.10797566175460815\n",
      "Epoch: 4, Step: 330, Loss: 0.11486546695232391\n",
      "Epoch: 4, Step: 331, Loss: 0.1015738695859909\n",
      "Epoch: 4, Step: 332, Loss: 0.1013571247458458\n",
      "Epoch: 4, Step: 333, Loss: 0.12295310199260712\n",
      "Epoch: 4, Step: 334, Loss: 0.13689014315605164\n",
      "Epoch: 4, Step: 335, Loss: 0.11751215159893036\n",
      "Epoch: 4, Step: 336, Loss: 0.07161901891231537\n",
      "Epoch: 4, Step: 337, Loss: 0.0884837806224823\n",
      "Epoch: 4, Step: 338, Loss: 0.06353402137756348\n",
      "Epoch: 4, Step: 339, Loss: 0.09769110381603241\n",
      "Epoch: 4, Step: 340, Loss: 0.15778493881225586\n",
      "Epoch: 4, Step: 341, Loss: 0.04800255224108696\n",
      "Epoch: 4, Step: 342, Loss: 0.036329373717308044\n",
      "Epoch: 4, Step: 343, Loss: 0.13388751447200775\n",
      "Epoch: 4, Step: 344, Loss: 0.13303424417972565\n",
      "Epoch: 4, Step: 345, Loss: 0.09208066761493683\n",
      "Epoch: 4, Step: 346, Loss: 0.04700344800949097\n",
      "Epoch: 4, Step: 347, Loss: 0.10622468590736389\n",
      "Epoch: 4, Step: 348, Loss: 0.14644639194011688\n",
      "Epoch: 4, Step: 349, Loss: 0.13174214959144592\n",
      "Epoch: 4, Step: 350, Loss: 0.10868766158819199\n",
      "Epoch: 4, Step: 351, Loss: 0.08786790072917938\n",
      "Epoch: 4, Step: 352, Loss: 0.09421621263027191\n",
      "Epoch: 4, Step: 353, Loss: 0.03921512886881828\n",
      "Epoch: 4, Step: 354, Loss: 0.10767368972301483\n",
      "Epoch: 4, Step: 355, Loss: 0.0790124237537384\n",
      "Epoch: 4, Step: 356, Loss: 0.173796609044075\n",
      "Epoch: 4, Step: 357, Loss: 0.030794277787208557\n",
      "Epoch: 4, Step: 358, Loss: 0.2875465452671051\n",
      "Epoch: 4, Step: 359, Loss: 0.07593558728694916\n",
      "Epoch: 4, Step: 360, Loss: 0.184361070394516\n",
      "Epoch: 4, Step: 361, Loss: 0.11748524755239487\n",
      "Epoch: 4, Step: 362, Loss: 0.06857659667730331\n",
      "Epoch: 4, Step: 363, Loss: 0.17532743513584137\n",
      "Epoch: 4, Step: 364, Loss: 0.12033145129680634\n",
      "Epoch: 4, Step: 365, Loss: 0.08645196259021759\n",
      "Epoch: 4, Step: 366, Loss: 0.06154819577932358\n",
      "Epoch: 4, Step: 367, Loss: 0.049652136862277985\n",
      "Epoch: 4, Step: 368, Loss: 0.08198150992393494\n",
      "Epoch: 4, Step: 369, Loss: 0.04957659915089607\n",
      "Epoch: 4, Step: 370, Loss: 0.07520440220832825\n",
      "Epoch: 4, Step: 371, Loss: 0.0705764889717102\n",
      "Epoch: 4, Step: 372, Loss: 0.14913171529769897\n",
      "Epoch: 4, Step: 373, Loss: 0.09275729954242706\n",
      "Epoch: 4, Step: 374, Loss: 0.09739484637975693\n",
      "Epoch: 4, Step: 375, Loss: 0.10486429929733276\n",
      "Epoch: 4, Step: 376, Loss: 0.0788343995809555\n",
      "Epoch: 4, Step: 377, Loss: 0.10869556665420532\n",
      "Epoch: 4, Step: 378, Loss: 0.05890423059463501\n",
      "Epoch: 4, Step: 379, Loss: 0.07032708823680878\n",
      "Epoch: 4, Step: 380, Loss: 0.05078539252281189\n",
      "Epoch: 4, Step: 381, Loss: 0.08048398792743683\n",
      "Epoch: 4, Step: 382, Loss: 0.05175634101033211\n",
      "Epoch: 4, Step: 383, Loss: 0.05510865896940231\n",
      "Epoch: 4, Step: 384, Loss: 0.048522986471652985\n",
      "Epoch: 4, Step: 385, Loss: 0.0479106567800045\n",
      "Epoch: 4, Step: 386, Loss: 0.09223312139511108\n",
      "Epoch: 4, Step: 387, Loss: 0.09184548258781433\n",
      "Epoch: 4, Step: 388, Loss: 0.04788651317358017\n",
      "Epoch: 4, Step: 389, Loss: 0.10798929631710052\n",
      "Epoch: 4, Step: 390, Loss: 0.07800593972206116\n",
      "Epoch: 4, Step: 391, Loss: 0.0746883749961853\n",
      "Epoch: 4, Step: 392, Loss: 0.06521911174058914\n",
      "Epoch: 4, Step: 393, Loss: 0.07652471214532852\n",
      "Epoch: 4, Step: 394, Loss: 0.04848386347293854\n",
      "Epoch: 4, Step: 395, Loss: 0.1443774700164795\n",
      "Epoch: 4, Step: 396, Loss: 0.07978947460651398\n",
      "Epoch: 4, Step: 397, Loss: 0.07033993303775787\n",
      "Epoch: 4, Step: 398, Loss: 0.14022785425186157\n",
      "Epoch: 4, Step: 399, Loss: 0.07668769359588623\n",
      "Epoch: 4, Step: 400, Loss: 0.043053045868873596\n",
      "Epoch: 4, Step: 401, Loss: 0.15994179248809814\n",
      "Epoch: 4, Step: 402, Loss: 0.15849986672401428\n",
      "Epoch: 4, Step: 403, Loss: 0.06414109468460083\n",
      "Epoch: 4, Step: 404, Loss: 0.09964761137962341\n",
      "Epoch: 4, Step: 405, Loss: 0.07293571531772614\n",
      "Epoch: 4, Step: 406, Loss: 0.06778652966022491\n",
      "Epoch: 4, Step: 407, Loss: 0.03262495994567871\n",
      "Epoch: 4, Step: 408, Loss: 0.050537705421447754\n",
      "Epoch: 4, Step: 409, Loss: 0.059766072779893875\n",
      "Epoch: 4, Step: 410, Loss: 0.09880328178405762\n",
      "Epoch: 4, Step: 411, Loss: 0.10083633661270142\n",
      "Epoch: 4, Step: 412, Loss: 0.05903419479727745\n",
      "Epoch: 4, Step: 413, Loss: 0.06007031351327896\n",
      "Epoch: 4, Step: 414, Loss: 0.0823904275894165\n",
      "Epoch: 4, Step: 415, Loss: 0.05764537304639816\n",
      "Epoch: 4, Step: 416, Loss: 0.10829606652259827\n",
      "Epoch: 4, Step: 417, Loss: 0.10658861696720123\n",
      "Epoch: 4, Step: 418, Loss: 0.07721047848463058\n",
      "Epoch: 4, Step: 419, Loss: 0.08719240128993988\n",
      "Epoch: 4, Step: 420, Loss: 0.027290333062410355\n",
      "Epoch: 4, Step: 421, Loss: 0.09027349948883057\n",
      "Epoch: 4, Step: 422, Loss: 0.10475152730941772\n",
      "Epoch: 4, Step: 423, Loss: 0.09478064626455307\n",
      "Epoch: 4, Step: 424, Loss: 0.02685541659593582\n",
      "Epoch: 4, Step: 425, Loss: 0.10347558557987213\n",
      "Epoch: 4, Step: 426, Loss: 0.053166382014751434\n",
      "Epoch: 4, Step: 427, Loss: 0.06172391399741173\n",
      "Epoch: 4, Step: 428, Loss: 0.06273718178272247\n",
      "Epoch: 4, Step: 429, Loss: 0.10544797778129578\n",
      "Epoch: 4, Step: 430, Loss: 0.055048033595085144\n",
      "Epoch: 4, Step: 431, Loss: 0.056597404181957245\n",
      "Epoch: 4, Step: 432, Loss: 0.02886604703962803\n",
      "Epoch: 4, Step: 433, Loss: 0.07887019962072372\n",
      "Epoch: 4, Step: 434, Loss: 0.08577463030815125\n",
      "Epoch: 4, Step: 435, Loss: 0.14920295774936676\n",
      "Epoch: 4, Step: 436, Loss: 0.09785544872283936\n",
      "Epoch: 4, Step: 437, Loss: 0.04391670227050781\n",
      "Epoch: 4, Step: 438, Loss: 0.1303369551897049\n",
      "Epoch: 4, Step: 439, Loss: 0.09681692719459534\n",
      "Epoch: 4, Step: 440, Loss: 0.0529843345284462\n",
      "Epoch: 4, Step: 441, Loss: 0.11492852866649628\n",
      "Epoch: 4, Step: 442, Loss: 0.1353866159915924\n",
      "Epoch: 4, Step: 443, Loss: 0.05103359371423721\n",
      "Epoch: 4, Step: 444, Loss: 0.04745060205459595\n",
      "Epoch: 4, Step: 445, Loss: 0.06821893900632858\n",
      "Epoch: 4, Step: 446, Loss: 0.024022292345762253\n",
      "Epoch: 4, Step: 447, Loss: 0.35026490688323975\n",
      "Epoch: 4, Step: 448, Loss: 0.16222485899925232\n",
      "Epoch: 4, Step: 449, Loss: 0.08610621839761734\n",
      "Epoch: 4, Step: 450, Loss: 0.059684690088033676\n",
      "Epoch: 4, Step: 451, Loss: 0.08301308751106262\n",
      "Epoch: 4, Step: 452, Loss: 0.04002713784575462\n",
      "Epoch: 4, Step: 453, Loss: 0.06649083644151688\n",
      "Epoch: 4, Step: 454, Loss: 0.06711874157190323\n",
      "Epoch: 4, Step: 455, Loss: 0.11829446256160736\n",
      "Epoch: 4, Step: 456, Loss: 0.025494562461972237\n",
      "Epoch: 4, Step: 457, Loss: 0.11609760671854019\n",
      "Epoch: 4, Step: 458, Loss: 0.052424803376197815\n",
      "Epoch: 4, Step: 459, Loss: 0.04959160462021828\n",
      "Epoch: 4, Step: 460, Loss: 0.06647852063179016\n",
      "Epoch: 4, Step: 461, Loss: 0.07730437070131302\n",
      "Epoch: 4, Step: 462, Loss: 0.052942875772714615\n",
      "Epoch: 4, Step: 463, Loss: 0.07660780102014542\n",
      "Epoch: 4, Step: 464, Loss: 0.058382146060466766\n",
      "Epoch: 4, Step: 465, Loss: 0.06897220015525818\n",
      "Epoch: 4, Step: 466, Loss: 0.03475219011306763\n",
      "Epoch: 4, Step: 467, Loss: 0.03447549790143967\n",
      "Epoch: 4, Step: 468, Loss: 0.02327083796262741\n",
      "Epoch: 4, Step: 469, Loss: 0.09883501380681992\n",
      "Epoch: 4, Step: 470, Loss: 0.16020430624485016\n",
      "Epoch: 4, Step: 471, Loss: 0.12458973377943039\n",
      "Epoch: 4, Step: 472, Loss: 0.09161867201328278\n",
      "Epoch: 4, Step: 473, Loss: 0.08035562932491302\n",
      "Epoch: 4, Step: 474, Loss: 0.08721011877059937\n",
      "Epoch: 4, Step: 475, Loss: 0.0925583764910698\n",
      "Epoch: 4, Step: 476, Loss: 0.0791674554347992\n",
      "Epoch: 4, Step: 477, Loss: 0.04280222952365875\n",
      "Epoch: 4, Step: 478, Loss: 0.1676168143749237\n",
      "Epoch: 4, Step: 479, Loss: 0.029621707275509834\n",
      "Epoch: 4, Step: 480, Loss: 0.09310948103666306\n",
      "Epoch: 4, Step: 481, Loss: 0.03780755400657654\n",
      "Epoch: 4, Step: 482, Loss: 0.11318832635879517\n",
      "Epoch: 4, Step: 483, Loss: 0.062310151755809784\n",
      "Epoch: 4, Step: 484, Loss: 0.11828360706567764\n",
      "Epoch: 4, Step: 485, Loss: 0.05795499309897423\n",
      "Epoch: 4, Step: 486, Loss: 0.04972710832953453\n",
      "Epoch: 4, Step: 487, Loss: 0.1370304524898529\n",
      "Epoch: 4, Step: 488, Loss: 0.06120757758617401\n",
      "Epoch: 4, Step: 489, Loss: 0.10153446346521378\n",
      "Epoch: 4, Step: 490, Loss: 0.03698781877756119\n",
      "Epoch: 4, Step: 491, Loss: 0.11542210727930069\n",
      "Epoch: 4, Step: 492, Loss: 0.09946828335523605\n",
      "Epoch: 4, Step: 493, Loss: 0.0729917660355568\n",
      "Epoch: 4, Step: 494, Loss: 0.1435311734676361\n",
      "Epoch: 4, Step: 495, Loss: 0.05319976806640625\n",
      "Epoch: 4, Step: 496, Loss: 0.10806751251220703\n",
      "Epoch: 4, Step: 497, Loss: 0.06466494500637054\n",
      "Epoch: 4, Step: 498, Loss: 0.06419793516397476\n",
      "Epoch: 4, Step: 499, Loss: 0.08858800679445267\n",
      "Epoch: 4, Step: 500, Loss: 0.0854371190071106\n",
      "Epoch: 4, Step: 501, Loss: 0.060065582394599915\n",
      "Epoch: 4, Step: 502, Loss: 0.025586139410734177\n",
      "Epoch: 4, Step: 503, Loss: 0.05828797444701195\n"
     ]
    }
   ],
   "source": [
    "# 初始化BERT模型和Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "model = BertModel.from_pretrained('bert-base-chinese')\n",
    "\n",
    "# 定义解码器\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_size, vocab_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# 定义数据集\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, tokens, tokenizer):\n",
    "        self.tokens = tokens\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokens)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tokens = self.tokens[idx]\n",
    "        encoded = self.tokenizer(tokens, is_split_into_words=True, return_tensors='pt', padding='max_length', truncation=True, max_length=512)\n",
    "        return {key: val.squeeze(0) for key, val in encoded.items()}\n",
    "\n",
    "# 初始化BERT模型和Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "model = BertModel.from_pretrained('bert-base-chinese')\n",
    "decoder = Decoder(hidden_size=768, vocab_size=tokenizer.vocab_size)\n",
    "\n",
    "model.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "# 定义优化器和混合精度缩放器\n",
    "optimizer = torch.optim.AdamW(list(model.parameters()) + list(decoder.parameters()), lr=5e-5)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# 数据加载\n",
    "train_dataset = TextDataset(tokens, tokenizer)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)  # 较小的批量大小\n",
    "\n",
    "# 训练循环\n",
    "accumulation_steps = 4  # 梯度累积步数\n",
    "model.train()\n",
    "decoder.train()\n",
    "optimizer.zero_grad()\n",
    "for epoch in range(5):  # 训练多个epoch\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}  # 将数据移动到设备\n",
    "        with autocast():\n",
    "            outputs = model(**batch)\n",
    "            last_hidden_states = outputs.last_hidden_state\n",
    "            reconstructed = decoder(last_hidden_states)\n",
    "            loss = F.cross_entropy(reconstructed.view(-1, reconstructed.size(-1)), batch['input_ids'].view(-1))\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (step + 1) % accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "        print(f\"Epoch: {epoch}, Step: {step}, Loss: {loss.item()}\")\n",
    "\n",
    "    # 清理缓存\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# 保存模型和解码器状态字典\n",
    "torch.save(model.state_dict(), '../Data/Model/bert_model_mps.pth')\n",
    "torch.save(decoder.state_dict(), '../Data/Model/decoder_mps.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forDeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
